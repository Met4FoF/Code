# CircleCI 2.1 configuration file
#
# Check https://circleci.com/docs/2.0/language-python/ for more details
#
version: 2.1

executors:
  tester:
    working_directory: ~/repo
    docker:
      - image: cimg/python:3.8
        auth:
          username: $DOCKERHUB_USER
          password: $DOCKERHUB_PASSWORD
  publisher:
    working_directory: ~/repo
    docker:
      - image: cimg/python:3.8
        auth:
          username: $DOCKERHUB_USER
          password: $DOCKERHUB_PASSWORD
  gh_releaser:
    working_directory: ~/repo
    docker:
      - image: cimg/base:2021.04
        auth:
          username: $DOCKERHUB_USER
          password: $DOCKERHUB_PASSWORD

workflows:

  pull_subtrees_and_recompile_deps:
    triggers:
      - schedule:
          cron: "0 0 1 * *"
          filters:
            branches:
              only: /main/
    jobs:
      - pull_subtrees:
          new_branch: most_recent_subtree_pulls
          context:
            - Docker pulls

  check_for_upgraded_deps:
    jobs:
      - recompile_deps:
          filters:
            branches:
              only: most_recent_subtree_pulls
          context:
            - Docker pulls
      - commit_push_open_pr:
          requires:
            - recompile_deps
          context:
            - Docker pulls
            - GitHub pushes to BjoernLudwigPTB's public_repos

  nightly_test:
    triggers:
      - schedule:
          cron: "0 0 8,15,22 * *"
          filters:
            branches:
              only: /main/
    jobs:
      - build_and_test_conda_env:
          context:
            - Docker pulls
      - build_and_test_venv_env:
          context:
            - Docker pulls
      - test_against_conda:
          name: test_agentMET4FOF_ml_against_conda
          subtree: tutorials/agentMET4FOF_ml
          context:
            - Docker pulls
      - test_against_conda:
          name: test_agentMET4FOF_anomaly_detection_against_conda
          subtree: tutorials/agentMET4FOF_anomaly_detection
          context:
            - Docker pulls
      - test_against_conda:
          name: test_time-series-buffer_against_conda
          subtree: time-series-buffer
          context:
            - Docker pulls
      - test_against_conda:
          name: test_time-series-metadata_against_conda
          subtree: time-series-metadata
          context:
            - Docker pulls
      - test_against_conda:
          name: test_agentMET4FOF_sensors_against_conda
          subtree: tutorials/agentMET4FOF_sensors
          context:
            - Docker pulls
      - test_against_conda:
          name: test_agentMET4FOF_against_conda
          subtree: agentMET4FOF
          context:
            - Docker pulls
      - test_against_conda:
          name: test_Met4FoF-redundancy_against_conda
          subtree: Met4FoF-redundancy
          context:
            - Docker pulls
      - test_against_venv:
          name: test_agentMET4FOF_ml_against_venv
          subtree: tutorials/agentMET4FOF_ml
          context:
            - Docker pulls
      - test_against_venv:
          name: test_agentMET4FOF_anomaly_detection_against_venv
          subtree: tutorials/agentMET4FOF_anomaly_detection
          context:
            - Docker pulls
      - test_against_venv:
          name: test_time-series-buffer_against_venv
          subtree: time-series-buffer
          context:
            - Docker pulls
      - test_against_venv:
          name: test_time-series-metadata_against_venv
          subtree: time-series-metadata
          context:
            - Docker pulls
      - test_against_venv:
          name: test_agentMET4FOF_sensors_against_venv
          subtree: tutorials/agentMET4FOF_sensors
          context:
            - Docker pulls
      - test_against_venv:
          name: test_agentMET4FOF_against_venv
          subtree: agentMET4FOF
          context:
            - Docker pulls
      - test_against_venv:
          name: test_Met4FoF-redundancy_against_venv
          subtree: Met4FoF-redundancy
          context:
            - Docker pulls
      - test_PyDynamic:
          context:
            - Docker pulls
      - test_agentMET4FOF:
          context:
            - Docker pulls
      - test_agentMET4FOF_ml:
          context:
            - Docker pulls
      - test_agentMET4FOF_anomaly_detection:
          context:
            - Docker pulls
      - test_time-series-buffer:
          context:
            - Docker pulls
      - test_time-series-metadata:
          context:
            - Docker pulls
      - test_agentMET4FOF_sensors:
          context:
            - Docker pulls
      - test_Met4FoF-redundancy:
          context:
            - Docker pulls

  build_and_test_virtual_environments:
    jobs:
      - build_and_test_conda_env:
          context:
            - Docker pulls
      - build_and_test_venv_env:
          context:
            - Docker pulls
      - test_against_conda:
          name: test_agentMET4FOF_ml_against_conda
          subtree: tutorials/agentMET4FOF_ml
          context:
            - Docker pulls
      - test_against_conda:
          name: test_agentMET4FOF_anomaly_detection_against_conda
          subtree: tutorials/agentMET4FOF_anomaly_detection
          context:
            - Docker pulls
      - test_against_conda:
          name: test_time-series-buffer_against_conda
          subtree: time-series-buffer
          context:
            - Docker pulls
      - test_against_conda:
          name: test_time-series-metadata_against_conda
          subtree: time-series-metadata
          context:
            - Docker pulls
      - test_against_conda:
          name: test_agentMET4FOF_sensors_against_conda
          subtree: tutorials/agentMET4FOF_sensors
          context:
            - Docker pulls
      - test_against_conda:
          name: test_agentMET4FOF_against_conda
          subtree: agentMET4FOF
          context:
            - Docker pulls
      - test_against_conda:
          name: test_Met4FoF-redundancy_against_conda
          subtree: Met4FoF-redundancy
          context:
            - Docker pulls
      - test_against_venv:
          name: test_agentMET4FOF_ml_against_venv
          subtree: tutorials/agentMET4FOF_ml
          context:
            - Docker pulls
      - test_against_venv:
          name: test_agentMET4FOF_anomaly_detection_against_venv
          subtree: tutorials/agentMET4FOF_anomaly_detection
          context:
            - Docker pulls
      - test_against_venv:
          name: test_time-series-buffer_against_venv
          subtree: time-series-buffer
          context:
            - Docker pulls
      - test_against_venv:
          name: test_time-series-metadata_against_venv
          subtree: time-series-metadata
          context:
            - Docker pulls
      - test_against_venv:
          name: test_agentMET4FOF_sensors_against_venv
          subtree: tutorials/agentMET4FOF_sensors
          context:
            - Docker pulls
      - test_against_venv:
          name: test_agentMET4FOF_against_venv
          subtree: agentMET4FOF
          context:
            - Docker pulls
      - test_against_venv:
          name: test_Met4FoF-redundancy_against_venv
          subtree: Met4FoF-redundancy
          context:
            - Docker pulls
      - test_PyDynamic:
          context:
            - Docker pulls
      - test_agentMET4FOF:
          context:
            - Docker pulls
      - test_agentMET4FOF_ml:
          context:
            - Docker pulls
      - test_agentMET4FOF_anomaly_detection:
          context:
            - Docker pulls
      - test_time-series-buffer:
          context:
            - Docker pulls
      - test_time-series-metadata:
          context:
            - Docker pulls
      - test_agentMET4FOF_sensors:
          context:
            - Docker pulls
      - test_Met4FoF-redundancy:
          context:
            - Docker pulls
      - preview_release:
          # Test the 'release' job to avoid trouble when Pull Requests get merged and
          # to preview publishing actions and the new changelog.
          requires:
              - build_and_test_conda_env
              - build_and_test_venv_env
              - test_agentMET4FOF_ml_against_conda
              - test_agentMET4FOF_ml_against_venv
              - test_agentMET4FOF_anomaly_detection_against_conda
              - test_agentMET4FOF_anomaly_detection_against_venv
              - test_time-series-buffer_against_conda
              - test_time-series-buffer_against_venv
              - test_time-series-metadata_against_conda
              - test_time-series-metadata_against_venv
              - test_agentMET4FOF_sensors_against_conda
              - test_agentMET4FOF_sensors_against_venv
              - test_agentMET4FOF_against_conda
              - test_agentMET4FOF_against_venv
              - test_Met4FoF-redundancy_against_conda
              - test_Met4FoF-redundancy_against_venv
              - test_PyDynamic
              - test_agentMET4FOF
              - test_agentMET4FOF_ml
              - test_agentMET4FOF_anomaly_detection
              - test_time-series-buffer
              - test_time-series-metadata
              - test_agentMET4FOF_sensors
              - test_Met4FoF-redundancy
      - confirm_previewed_release_actions:
          # This job allows for checking that the release we will create in the
          # next step actually is the desired release, by observing the result of
          # preview_release.
          type: approval
          requires:
            - preview_release
          filters:
            branches:
              # This assures the job only being triggered on branch main.
              only: /main/
      - release:
          # Job to potentially create a release based on python-semantic-release's
          # decision and publish it on GitHub and Zenodo. This requires manual
          # approval in the previous step, which is only triggered on branch main,
          # thus this job here is triggered only on main as well.
          context:
            - GitHub pushes to BjoernLudwigPTB's public_repos
          requires:
            - confirm_previewed_release_actions


commands:
  # Reusable command to prepare the environment for testing.
  install_and_cache_venv_dependencies:
    description: "Install pip dependencies of all packages."
    steps:
    # Download and cache dependencies.
    - restore_cache:
        keys:
          # Specify the unique identifier for the cache.
          - v1-venv-dependencies-{{ checksum "requirements.txt" }}
          # Fallback to using the latest cache if no exact match is found.
          - v1-venv-dependencies-

    # Install dependencies.
    - run:
        name: Install dependencies
        command: |
          python3 -m venv venv
          source venv/bin/activate
          pip install --upgrade pip pip-tools
          pip install --upgrade numpy scipy uncertainties
          pip-sync requirements.txt

    - save_cache:
        paths:
          - ./venv
        key: >-
          v1-venv-dependencies-{{ checksum "requirements.txt" }}



  # Reusable command to prepare the environment for testing.
  install_and_cache_conda_dependencies:
    description: "Install Miniconda and conda dependencies of all packages."
    steps:
    - run:
        name: Install Miniconda
        command: |
          wget "https://repo.anaconda.com/miniconda/\
          Miniconda3-latest-Linux-x86_64.sh" -O $HOME/miniconda.sh
          mkdir -p $HOME/.conda
          bash $HOME/miniconda.sh -b -p /home/circleci/conda
          source $HOME/conda/etc/profile.d/conda.sh
          hash -r
          conda config --set always_yes yes --set changeps1 no
          conda update -q conda
          echo 'export PATH=$HOME/conda/bin:$PATH' >> $BASH_ENV

    # Download and cache dependencies.
    - restore_cache:
        keys:
          # Specify the unique identifier for the cache.
          - v1-conda-dependencies-{{ checksum "environment.yml" }}-{{ checksum "requirements.txt" }}
          # Fallback to using the latest cache if no exact match is found.
          - v1-conda-dependencies-

    # Create environment.
    - run:
        name: Create or update environment
        command: |
          if [ -d "$HOME/conda/envs/" ]; then
              conda env update --prune --file environment.yml
          else
              conda env create -f environment.yml
          fi

    - save_cache:
        paths:
          - /home/circleci/conda/envs/
        key: >-
          v1-conda-dependencies-{{ checksum "environment.yml" }}-{{ checksum "requirements.txt" }}

  create_result_folder:
    description: "Create test-result folder."
    parameters:
      subfolder:
        type: string
        default: ""
    steps:
    # Create test-result folder.
    - run:
        name: Create test result folder
        command: |
          mkdir -p test-results/<< parameters.subfolder >>

  run_conda_tests:
    description: "Run and store test results."
    parameters:
      subtree:
        type: string
        default: ""
    steps:
    # Run tests! We use pytest's test-runner.
    - run:
        name: Run tests
        command: |
          source $HOME/conda/etc/profile.d/conda.sh
          conda activate Met4FoF_Code
          pytest -v --junitxml=test-results/junit.xml \
          << parameters.subtree >> | tee test-results/pytest.log

    - store_test_artifacts_and_results:
        subtree: << parameters.subtree >>

  run_venv_tests:
    description: "Run and store test results."
    parameters:
      subtree:
        type: string
        default: ""
    steps:
    - run:
        name: Run tests
        command: |
          source venv/bin/activate
          pytest -v --junitxml=test-results/junit.xml \
          << parameters.subtree >> | tee test-results/pytest.log

    - store_test_artifacts_and_results:
        subtree: << parameters.subtree >>

  store_test_artifacts_and_results:
    description: "Store test results."
    parameters:
      subtree:
        type: string
        default: ""
    steps:
    # Store test results.
    - store_artifacts:
        path: test-results
        destination: test-results/<< parameters.subtree >>

    - store_test_results:
        path: test-results

  subtree_pull:
    description: "Check for any changes."
    parameters:
      subtree:
        type: string
        default: ""
      upstream_url:
        type: string
        default: ""
      branch:
        type: string
        default: ""
    steps:
    - run:
        command: |
          git subtree pull -q --prefix << parameters.subtree >> \
            << parameters.upstream_url >> << parameters.branch >> \
            -m "Update $(echo << parameters.subtree >> | sed -e "s|tutorials/||") 
            to most recent version"

  check_for_new_deps_compilation:
    description: "Check for any changes."
    steps:
    - run:
        name: Abort if no new deps were compiled
        command: |
          git add .
          set +e
          git status | grep modified
          if [ $? -ne 0 ]; then
              set -e
              echo "No updated subtrees or deps. Nothing to test and commit. We are all 
                good."
              circleci-agent step halt
          fi

  set_git_user_name_and_email:
    description: "Configure git to be commit-ready."
    steps:
    - run:
        name: Set Git user.name and user.email
        command: |
            echo 'git config user.name "Bjoern Ludwig (via CircleCI)"' >> $BASH_ENV
            echo 'git config --global user.email "bjoern.ludwig@ptb.de"' >> $BASH_ENV

jobs:

  pull_subtrees:
    parameters:
      new_branch:
        type: string
    executor:
      name: gh_releaser

    steps:
      - add_ssh_keys:
          fingerprints:
            - "0f:4e:bb:cb:6a:fc:0a:23:db:5b:de:7a:3e:34:80:80"
      - checkout
      - set_git_user_name_and_email
      - run: git checkout -b << parameters.new_branch >>
      - subtree_pull:
          subtree: agentMET4FOF
          upstream_url: git@github.com:Met4FoF/agentMET4FOF.git
          branch: develop
      - subtree_pull:
          subtree: datareceiver
          upstream_url: git@github.com:Met4FoF/datareceiver.git
          branch: master
      - subtree_pull:
          subtree: Met4FoF-redundancy
          upstream_url: git@github.com:Met4FoF/Met4FoF-redundancy.git
          branch: master
      - subtree_pull:
          subtree: Met4FoF-SmartUpUnit
          upstream_url: git@github.com:Met4FoF/Met4FoF-SmartUpUnit.git
          branch: SSU_V3
      - subtree_pull:
          subtree: PyDynamic
          upstream_url: git@github.com:PTB-M4D/PyDynamic.git
          branch: master
      - subtree_pull:
          subtree: PySensorNetwork
          upstream_url: git@github.com:Met4FoF/PySensorNetwork.git
          branch: master
      - subtree_pull:
          subtree: time-series-buffer
          upstream_url: git@github.com:PTB-M4D/time-series-buffer.git
          branch: master
      - subtree_pull:
          subtree: time-series-metadata
          upstream_url: git@github.com:PTB-M4D/time-series-metadata.git
          branch: main
      - subtree_pull:
          subtree: tutorials/agentMET4FOF_anomaly_detection
          upstream_url: git@github.com:Met4FoF/agentMET4FOF_anomaly_detection.git
          branch: master
      - subtree_pull:
          subtree: tutorials/agentMET4FOF_bayesian_neural_network_ZeMA
          upstream_url: git@github.com:Met4FoF/agentMET4FOF_bayesian_neural_network_ZeMA.git
          branch: master
      - subtree_pull:
          subtree: tutorials/agentMET4FOF_ml
          upstream_url: git@github.com:Met4FoF/agentMET4FOF_ml.git
          branch: master
      - subtree_pull:
          subtree: tutorials/agentMET4FOF_sensors
          upstream_url: git@github.com:Met4FoF/agentMET4FOF_sensors.git
          branch: master
      - subtree_pull:
          subtree: tutorials/agentMET4FOF_ZeMA_emc
          upstream_url: git@github.com:Met4FoF/agentMET4FOF_ZeMA_emc.git
          branch: master
      - subtree_pull:
          subtree: tutorials/connect-agentMET4FOF-smartupunit
          upstream_url: git@github.com:Met4FoF/connect-agentMET4FOF-smartupunit.git
          branch: master
      - subtree_pull:
          subtree: tutorials/PyDynamic_tutorials
          upstream_url: git@github.com:PTB-M4D/PyDynamic_tutorials.git
          branch: main
      - subtree_pull:
          subtree: tutorials/Strathcylde_AFRC_machine_learning_tutorials
          upstream_url: git@github.com:harislulic/Strathcylde_AFRC_machine_learning_tutorials.git
          branch: master
      - subtree_pull:
          subtree: tutorials/ZeMA-machine-learning-tutorials
          upstream_url: git@github.com:harislulic/ZeMA-machine-learning-tutorials.git
          branch: master
      - subtree_pull:
          subtree: ZeMA_testbed_Bayesian_machine_learning
          upstream_url: git@github.com:Met4FoF/ZeMA_testbed_Bayesian_machine_learning.git
          branch: master
      - run:
          name: Abort if no new commit was added
          command: |
            if [ $(git rev-parse HEAD) == ${CIRCLE_SHA1}]; then
                circleci-agent step halt
            fi
      - run: git push -fu origin << parameters.new_branch >>

  recompile_deps:
    executor:
      name: tester
    steps:
      - checkout
      - create_result_folder
      - run:
          name: Recompile and sync deps
          command: |
            pip install --upgrade pip pip-tools numpy uncertainties
            python -m piptools compile --upgrade
            python -m piptools compile --upgrade dev-requirements.in
            sed -i "s/torch==/#torch==/" requirements.txt
            python -m piptools sync requirements.txt dev-requirements.txt
      - check_for_new_deps_compilation
      - persist_to_workspace:
          root: .
          paths:
            - requirements.txt
            - dev-requirements.txt

  commit_push_open_pr:
    executor:
      name: gh_releaser

    steps:
      - add_ssh_keys:
          fingerprints:
            - "0f:4e:bb:cb:6a:fc:0a:23:db:5b:de:7a:3e:34:80:80"
      - checkout
      - attach_workspace:
          at: .
      - check_for_new_deps_compilation
      - set_git_user_name_and_email
      - run: echo 'export NEW_BRANCH=recompile_deps' >> $BASH_ENV
      - run:
          name: Commit and push changes
          command: |
            git checkout -b ${NEW_BRANCH}
            git commit -am "build(deps): recompile Python (dev) deps on $(date)"
            git push -fu origin  ${NEW_BRANCH}
      - run:
          name: Install GitHub CLI
          command: |
            curl -fsSL \
              https://cli.github.com/packages/githubcli-archive-keyring.gpg |\
              sudo dd of=/etc/apt/trusted.gpg.d/githubcli-archive-keyring.gpg
            echo "deb [arch=$(dpkg --print-architecture) \
              signed-by=/etc/apt/trusted.gpg.d/githubcli-archive-keyring.gpg]\
              https://cli.github.com/packages stable main" | \
              sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null
            sudo apt update
            sudo apt install gh
      - run:
          name: Check for an existing PR or create one
          command: |
            set +e
            gh pr list --head=$NEW_BRANCH | grep $NEW_BRANCH
            if [ $? -eq 1 ]; then
                set -e
                gh pr create --base=main --title "Update deps" \
                  --body "This PR provides recompiled deps for all outdated \
                  package versions. It was opened after all subtrees were \
                  successfully updated and afterwards the deps \
                  were succesfully compiled. If all tests pass with the \
                  new versions, it should be merged as soon as possible to \
                  avoid any security issues due to outdated dependencies."
            else
                set -e
                echo "There already was a PR opened earlier. The 
                  current changes were used to update the existing branch."
            fi

  # Define one 'test' job with parameters to deal with all subtrees and let them
  # run their test suites against the installed dependencies from the environment.yml.
  test_against_conda:
    # The parameter subtree is mandatory and requires the relative path of the
    # subtree under test from the repository root.
    parameters:
      subtree:
        type: string
    # The parameter uninstalls is needed, whenever there is a package
    # installed in the requirements, which is provided by the subtree under test
    # itself.
      uninstalls:
        type: string
        default: ""

    executor: tester

    steps:
      - checkout
      - create_result_folder:
          subfolder: << parameters.subtree >>
      - install_and_cache_conda_dependencies

      # Uninstall packages.
      - when:
          condition:
            not:
              equal: [ "", << parameters.uninstalls >> ]
          steps:
            - run:
                name: Uninstall packages
                command: |
                  source $HOME/conda/etc/profile.d/conda.sh
                  conda activate Met4FoF_Code
                  pip uninstall --yes << parameters.uninstalls >>

      # Run tests! We use pytest's test-runner.
      - run_conda_tests:
          subtree: << parameters.subtree >>

  # Define one 'test' job with parameters to deal with all subtrees and let them
  # run their test suites against the installed dependencies from the requirements
  # files.
  test_against_venv:
    parameters:
    # The parameter subtree is mandatory and requires the relative path of the
    # subtree under test from the repository root.
      subtree:
        type: string
    # The parameter uninstalls is needed, whenever there is a package
    # installed in the requirements, which is provided by the subtree under test
    # itself.
      uninstalls:
        type: string
        default: ""

    executor: tester

    steps:
      - checkout
      - create_result_folder:
          subfolder: << parameters.subtree >>
      - install_and_cache_venv_dependencies

      # Uninstall packages.
      - when:
          condition:
            not:
              equal: [ "", << parameters.uninstalls >> ]
          steps:
            - run:
                name: Uninstall packages
                command: |
                  source venv/bin/activate
                  pip uninstall --yes << parameters.uninstalls >>

      # Run tests! We use pytest's test-runner.
      - run_venv_tests:
          subtree: << parameters.subtree >>


  build_and_test_conda_env:
    executor: tester

    steps:
      - checkout
      - install_and_cache_conda_dependencies


  build_and_test_venv_env:
    executor: tester

    steps:
      - checkout
      - install_and_cache_venv_dependencies


  test_PyDynamic:
    executor: tester

    parallelism: 16

    # Specify the steps to execute during this test jobs.
    steps:
      - checkout
      - create_result_folder

      # Download and cache dependencies.
      - restore_cache:
          keys:
            # Specify the unique identifier for the cache.
            - PyDynamic-v3-{{ checksum "PyDynamic/requirements/requirements-py38.txt" }}-{{ checksum "PyDynamic/requirements/dev-requirements-py38.txt" }}
            # Fallback to using the latest cache if no exact match is found.
            - PyDynamic-v3

      # Install dependencies and Codecov reporter if necessary.
      - run:
          name: Install dependencies
          command: |
            python3 -m venv venv
            source venv/bin/activate
            pip install --upgrade pip pip-tools
            pip-sync PyDynamic/requirements/requirements-py38.txt \
                PyDynamic/requirements/dev-requirements-py38.txt
            pip install ./PyDynamic

      - save_cache:
          paths:
            - ./venv
          key: >-
            PyDynamic-v3-{{ checksum "PyDynamic/requirements/requirements-py38.txt" }}-{{ checksum "PyDynamic/requirements/dev-requirements-py38.txt" }}

      # Run tests! We use pytest's test-runner.
      - run:
          name: Run tests
          no_output_timeout: 60m
          command: |
            source venv/bin/activate
            cd PyDynamic
            TEST_FILES=$(circleci tests glob "test/**/test_*.py" | \
              circleci tests split --split-by=timings)
            pytest -v --junitxml=$CIRCLE_WORKING_DIRECTORY/test-results/junit.xml \
              $TEST_FILES

      - store_artifacts:
          path: test-results
          destination: test-results

      - store_test_results:
          path: test-results

  test_agentMET4FOF:
    executor: tester

    steps:
      - checkout
      - create_result_folder:
          subfolder: agentMET4FOF

      # Download and cache dependencies.
      - restore_cache:
          keys:
            # Specify the unique identifier for the cache.
            - agentMET4FOF-v3-{{ checksum "agentMET4FOF/requirements.txt" }}-{{ checksum "agentMET4FOF/dev-requirements.txt" }}
            # Fallback to using the latest cache if no exact match is found.
            - agentMET4FOF-v3

      # Install dependencies and Codecov reporter if necessary.
      - run:
         name: Install dependencies
         command: |
           python3 -m venv venv
           source venv/bin/activate
           pip install --upgrade pip -r agentMET4FOF/requirements.txt -r agentMET4FOF/dev-requirements.txt

      - save_cache:
          paths:
            - ./venv
          key: >-
            agentMET4FOF-v3-{{ checksum "agentMET4FOF/requirements.txt" }}-{{ checksum "agentMET4FOF/dev-requirements.txt" }}

      # Run tests! We use pytest's test-runner.
      - run_venv_tests:
          subtree: agentMET4FOF

  test_agentMET4FOF_anomaly_detection:
    executor: tester

    steps:
      - checkout
      - create_result_folder:
          subfolder: tutorials/agentMET4FOF_anomaly_detection

      # Download and cache dependencies.
      - restore_cache:
          keys:
            # Specify the unique identifier for the cache.
            - agentMET4FOF_anomaly_detection-v2-{{ checksum "tutorials/agentMET4FOF_anomaly_detection/requirements.txt" }}
            # Fallback to using the latest cache if no exact match is found.
            - agentMET4FOF_anomaly_detection-v2

      # Install dependencies and Codecov reporter if necessary.
      - run:
         name: Install dependencies
         command: |
           python3 -m venv venv
           source venv/bin/activate
           pip install --upgrade pip setuptools pip-tools numpy
           pip-sync tutorials/agentMET4FOF_anomaly_detection/dev-requirements.txt tutorials/agentMET4FOF_anomaly_detection/requirements.txt


      - save_cache:
          paths:
            - ./venv
          key: >-
            agentMET4FOF_anomaly_detection-v2-{{ checksum "tutorials/agentMET4FOF_anomaly_detection/requirements.txt" }}

      # Run tests! We use pytest's test-runner.
      - run_venv_tests:
          subtree: tutorials/agentMET4FOF_anomaly_detection

  test_agentMET4FOF_sensors:
    executor: tester

    steps:
      - checkout
      - create_result_folder:
          subfolder: tutorials/agentMET4FOF_sensors

      # Download and cache dependencies.
      - restore_cache:
          keys:
            # Specify the unique identifier for the cache.
            - agentMET4FOF_sensors-v2-{{ checksum "tutorials/agentMET4FOF_sensors/requirements.txt" }}
            # Fallback to using the latest cache if no exact match is found.
            - agentMET4FOF_sensors-v2

      # Install dependencies. Suddenly since 2021-08-27 we observed an error with
      # previously successful configurations. That is why we introduced the gcc flag
      # as proposed by https://forum.manjaro.org/t/pip-install-rpi-gpio-fail/25788.
      # The error can be viewed here:
      # https://app.circleci.com/pipelines/github/Met4FoF/Code/455/workflows/81c97c42-a5a6-464e-9347-bee5bae44d9a/jobs/3662
      - run:
         name: Install dependencies
         command: |
           python3 -m venv venv
           source venv/bin/activate
           pip install --upgrade pip pip-tools
           CFLAGS="-fcommon" pip-sync tutorials/agentMET4FOF_sensors/requirements.txt
           pip install --upgrade pytest


      - save_cache:
          paths:
            - ./venv
          key: >-
            agentMET4FOF_sensors-v2-{{ checksum "tutorials/agentMET4FOF_sensors/requirements.txt" }}

      # Run tests! We use pytest's test-runner.
      - run_venv_tests:
          subtree: tutorials/agentMET4FOF_sensors

  test_agentMET4FOF_ml:
    executor: tester

    steps:
      - checkout
      - create_result_folder:
          subfolder: tutorials/agentMET4FOF_ml

      # Create folder for test results.
      - run:
          name: Create test result folder
          command: |
            mkdir test-reports

      # Download and cache dependencies.
      - restore_cache:
          keys:
            # Specify the unique identifier for the cache.
            - agentMET4FOF_ml-v3-{{ checksum "tutorials/agentMET4FOF_ml/requirements.txt" }}
            # Fallback to using the latest cache if no exact match is found.
            - agentMET4FOF_ml-v3

      # Install dependencies and Codecov reporter if necessary.
      - run:
         name: Install dependencies
         command: |
           python3 -m venv venv
           source venv/bin/activate
           pip install --upgrade pip numpy pytest
           pip install -r tutorials/agentMET4FOF_ml/requirements.txt


      - save_cache:
          paths:
            - ./venv
          key: >-
            agentMET4FOF_ml-v3-{{ checksum "tutorials/agentMET4FOF_ml/requirements.txt" }}

      # Run tests! We use pytest's test-runner.
      - run_venv_tests:
          subtree: tutorials/agentMET4FOF_ml

  test_time-series-buffer:
    executor: tester

    steps:
      - checkout
      - create_result_folder:
          subfolder: time-series-buffer

      # Create folder for test results.
      - run:
          name: Create test result folder
          command: |
            mkdir test-reports

      # Download and cache dependencies.
      - restore_cache:
          keys:
            # Specify the unique identifier for the cache.
            - time-series-buffer-v2-{{ checksum "time-series-buffer/requirements.txt" }}
            # Fallback to using the latest cache if no exact match is found.
            - time-series-buffer-v2

      # Install dependencies and Codecov reporter if necessary.
      - run:
         name: Install dependencies
         command: |
           python3 -m venv venv
           source venv/bin/activate
           pip install --upgrade pip pytest
           pip install -r time-series-buffer/requirements.txt


      - save_cache:
          paths:
            - ./venv
          key: >-
            time-series-buffer-v2-{{ checksum "time-series-buffer/requirements.txt" }}

      # Run tests! We use pytest's test-runner.
      - run_venv_tests:
          subtree: time-series-buffer

  test_time-series-metadata:
    executor: tester

    steps:
      - checkout
      - create_result_folder:
          subfolder: time-series-metadata

      # Create folder for test results.
      - run:
          name: Create test result folder
          command: |
            mkdir test-reports

      # Download and cache dependencies.
      - restore_cache:
          keys:
            # Specify the unique identifier for the cache.
            - time-series-metadata-v2-{{ checksum "time-series-metadata/requirements/dev-requirements-py38.txt" }}
            # Fallback to using the latest cache if no exact match is found.
            - time-series-metadata-v2

      # Install dependencies and Codecov reporter if necessary.
      - run:
         name: Install dependencies
         command: |
           python3 -m venv venv
           source venv/bin/activate
           pip install --upgrade pip pip-tools
           pip install time-series-metadata/.
           pip-sync time-series-metadata/requirements/dev-requirements-py38.txt


      - save_cache:
          paths:
            - ./venv
          key: >-
            time-series-metadata-v2-{{ checksum "time-series-metadata/requirements/dev-requirements-py38.txt" }}

      # Run tests! We use pytest's test-runner.
      - run_venv_tests:
          subtree: time-series-metadata

  test_Met4FoF-redundancy:
    executor: tester

    steps:
      - checkout
      - create_result_folder:
          subfolder: Met4FoF-redundancy

      # Download and cache dependencies.
      - restore_cache:
          keys:
            # Specify the unique identifier for the cache.
            - Met4FoF-redundancy-v3-{{ checksum "Met4FoF-redundancy/requirements/requirements.txt" }}-{{ checksum "Met4FoF-redundancy/requirements/dev-requirements.txt" }}
            # Fallback to using the latest cache if no exact match is found.
            - Met4FoF-redundancy-v3

      # Install dependencies and Codecov reporter if necessary.
      - run:
         name: Install dependencies
         command: |
           python3 -m venv venv
           source venv/bin/activate
           pip install --upgrade pip -r Met4FoF-redundancy/requirements/requirements.txt -r Met4FoF-redundancy/requirements/dev-requirements.txt

      - save_cache:
          paths:
            - ./venv
          key: >-
            Met4FoF-redundancy-v3-{{ checksum "Met4FoF-redundancy/requirements/requirements.txt" }}-{{ checksum "Met4FoF-redundancy/requirements/dev-requirements.txt" }}

      # Run tests! We use pytest's test-runner.
      - run_venv_tests:
          subtree: Met4FoF-redundancy

  release:
    executor: publisher

    steps:
      # Checkout code.
      - checkout

      # Download and cache dependencies.
      - restore_cache:
          keys:
            # Specify the unique identifier for the cache.
            - publisher-dependencies-{{ checksum "dev-requirements.txt" }}

      # Install dependencies.
      - run:
          name: Install dependencies
          command: |
            python3 -m venv venv
            source venv/bin/activate
            pip install --upgrade pip pip-tools
            pip-sync dev-requirements.txt

      - save_cache:
          paths:
            - ./venv
          key: >-
            publisher-dependencies-{{ checksum "dev-requirements.txt" }}

      # Publish it, if there is anything to publish!
      - run:
          name: Run semantic-release publish
          command: |
            source venv/bin/activate
            git config --global user.name "semantic-release (via CircleCI)"
            git config --global user.email "bjoern.ludwig@ptb.de"
            semantic-release publish


  preview_release:
    executor: publisher

    steps:
      # Checkout code.
      - checkout

      # Download and cache dependencies.
      - restore_cache:
          keys:
            # Specify the unique identifier for the cache.
            - publisher-dependencies-{{ checksum "dev-requirements.txt" }}

      # Install dependencies.
      - run:
          name: Install dependencies
          command: |
            python3 -m venv venv
            source venv/bin/activate
            pip install --upgrade pip pip-tools
            pip-sync dev-requirements.txt

      - save_cache:
          paths:
            - ./venv
          key: >-
            publisher-dependencies-{{ checksum "dev-requirements.txt" }}

      # Fake publish, just to make sure everything works after merging a PR and
      # before actual release jos run.
      - run:
          name: Preview python-semantic-release actions
          command: |
            unset CIRCLE_PULL_REQUEST CIRCLE_PULL_REQUESTS CI_PULL_REQUEST \
              CI_PULL_REQUESTS
            export CIRCLE_BRANCH=main
            source venv/bin/activate
            git config --global user.name "semantic-release (via CircleCI)"
            git config --global user.email "bjoern.ludwig@ptb.de"
            echo "The changelog of the next release will contain:"
            semantic-release --unreleased changelog
            echo "The output of 'semantic-release --noop publish' is:"
            semantic-release --noop publish
