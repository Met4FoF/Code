{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Multi Agent System\n",
    "\n",
    "We initialize the data source and create the agent network, once the agents are fully up and running, run the dashboard code in a separate terminal to visualize the agents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import osbrain\n",
    "from osbrain.agent import run_agent\n",
    "\n",
    "from agentMET4FOF_bayesian_neural_network_ZeMA.Agent_models.agents import SensorNetwork\n",
    "\n",
    "# TYPES OF AGENT\n",
    "# 0 - SENSOR NETWORK\n",
    "# 1 - SENSOR\n",
    "# 2 - AGGREGATOR\n",
    "# 3 - PREDICTOR\n",
    "# 4 - DECISIONMAKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DemoMode= True\n",
    "pickle_path = \"pickles/\"\n",
    "data_input = pickle.load(open(pickle_path + \"data_input_data_1Hz_full.p\", \"rb\"))\n",
    "data_output = pickle.load(open(pickle_path + \"zema_outputs.p\", \"rb\"))\n",
    "\n",
    "X_data = data_input\n",
    "Y_data = data_output\n",
    "randomShuffling = True\n",
    "\n",
    "if randomShuffling :\n",
    "    index_list = np.arange(X_data.shape[0])\n",
    "    random.shuffle(index_list)\n",
    "    Y_data = Y_data[index_list, :]\n",
    "    X_data = X_data[index_list, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broadcast server running on 0.0.0.0:9091\n",
      "NS running on 127.0.0.1:14065 (127.0.0.1)\n",
      "URI = PYRO:Pyro.NameServer@127.0.0.1:14065\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ns = osbrain.nameserver.run_nameserver(addr='127.0.0.1:14065')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Agent\n",
    "\n",
    "We firstly create a SensorNetwork Agent which enable wrapper functions and manages agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO [2020-04-23 18:15:58.397952] (sensor_Temperature_0): SENSOR INITIALIZED\n",
      "INFO [2020-04-23 18:15:58.464641] (sensor_network): sensor added generator function\n",
      "INFO [2020-04-23 18:15:58.515470] (sensor_Temperature_1): SENSOR INITIALIZED\n",
      "INFO [2020-04-23 18:15:58.584225] (sensor_network): sensor added generator function\n",
      "INFO [2020-04-23 18:15:58.609399] (sensor_Temperature_2): SENSOR INITIALIZED\n",
      "INFO [2020-04-23 18:15:58.685038] (sensor_network): sensor added generator function\n",
      "INFO [2020-04-23 18:15:58.716567] (sensor_Temperature_3): SENSOR INITIALIZED\n",
      "INFO [2020-04-23 18:15:58.774240] (sensor_network): sensor added generator function\n",
      "INFO [2020-04-23 18:15:58.811919] (sensor_Vibration_4): SENSOR INITIALIZED\n",
      "INFO [2020-04-23 18:15:58.874366] (sensor_network): sensor added generator function\n",
      "INFO [2020-04-23 18:15:58.896641] (sensor_EfficiencyFactor_5): SENSOR INITIALIZED\n",
      "INFO [2020-04-23 18:15:58.954507] (sensor_network): sensor added generator function\n",
      "INFO [2020-04-23 18:15:58.990206] (sensor_VolumeFlow_6): SENSOR INITIALIZED\n",
      "INFO [2020-04-23 18:15:59.044253] (sensor_network): sensor added generator function\n",
      "INFO [2020-04-23 18:15:59.121325] (sensor_VolumeFlow_7): SENSOR INITIALIZED\n",
      "INFO [2020-04-23 18:15:59.213926] (sensor_network): sensor added generator function\n",
      "INFO [2020-04-23 18:15:59.242725] (sensor_Pressure_8): SENSOR INITIALIZED\n",
      "INFO [2020-04-23 18:15:59.304244] (sensor_network): sensor added generator function\n",
      "INFO [2020-04-23 18:15:59.331528] (sensor_Pressure_9): SENSOR INITIALIZED\n",
      "INFO [2020-04-23 18:15:59.394241] (sensor_network): sensor added generator function\n",
      "INFO [2020-04-23 18:15:59.422287] (sensor_Pressure_10): SENSOR INITIALIZED\n",
      "INFO [2020-04-23 18:15:59.474293] (sensor_network): sensor added generator function\n",
      "INFO [2020-04-23 18:15:59.495830] (sensor_Pressure_11): SENSOR INITIALIZED\n",
      "INFO [2020-04-23 18:15:59.565134] (sensor_network): sensor added generator function\n",
      "INFO [2020-04-23 18:15:59.593755] (sensor_Pressure_12): SENSOR INITIALIZED\n",
      "INFO [2020-04-23 18:15:59.664195] (sensor_network): sensor added generator function\n",
      "INFO [2020-04-23 18:15:59.698925] (sensor_Pressure_13): SENSOR INITIALIZED\n",
      "INFO [2020-04-23 18:15:59.774267] (sensor_network): sensor added generator function\n",
      "INFO [2020-04-23 18:15:59.799497] (sensor_MotorPower_14): SENSOR INITIALIZED\n",
      "INFO [2020-04-23 18:15:59.865378] (sensor_network): sensor added generator function\n",
      "INFO [2020-04-23 18:15:59.894473] (sensor_CoolingEfficiency_15): SENSOR INITIALIZED\n",
      "INFO [2020-04-23 18:15:59.954336] (sensor_network): sensor added generator function\n",
      "INFO [2020-04-23 18:15:59.986771] (sensor_CoolingPower_16): SENSOR INITIALIZED\n",
      "INFO [2020-04-23 18:16:00.044332] (sensor_network): sensor added generator function\n",
      "INFO [2020-04-23 18:16:00.500315] (aggregator_0): Binded all sensors\n",
      "INFO [2020-04-23 18:16:00.600127] (predictor_0): Binded with Aggregator: Pub-sub mode\n",
      "INFO [2020-04-23 18:16:00.677498] (predictor_1): Binded with Aggregator: Pub-sub mode\n",
      "INFO [2020-04-23 18:16:00.767632] (predictor_2): Binded with Aggregator: Pub-sub mode\n",
      "INFO [2020-04-23 18:16:00.847214] (predictor_3): Binded with Aggregator: Pub-sub mode\n",
      "INFO [2020-04-23 18:16:00.927169] (predictor_4): Binded with Aggregator: Pub-sub mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ludwig10/code/envs/agentMET4FOF_use-case_zema-bnn/lib/python3.8/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "/home/ludwig10/code/envs/agentMET4FOF_use-case_zema-bnn/lib/python3.8/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "sensor_network = run_agent('sensor_network', base=SensorNetwork)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor Agents\n",
    "\n",
    "1. Next, we create a Sensor Agent by `sensor_network.addsimsensor(type,unit)`, and store into a list `sensors`. \n",
    "2. We set the data source of the Sensor Agent : `sensor_new.set_generatorDataSet(dataSet)` where dataSet is a 3-dimensional numpy array with: [Row x Sequence Length x Sensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add sensors\n",
    "sensors=[]\n",
    "sensorTypes = [\"Temperature\",\"Temperature\",\"Temperature\",\"Temperature\",\"Vibration\",\"EfficiencyFactor\",\"VolumeFlow\",\"VolumeFlow\",\"Pressure\",\"Pressure\",\"Pressure\",\"Pressure\",\"Pressure\",\"Pressure\",\"MotorPower\",\"CoolingEfficiency\",\"CoolingPower\"]\n",
    "sensorUnits = [\"C\",\"C\",\"C\",\"C\",\"mm/s\",\"%\",\"l/min\",\"l/min\",\"bar\",\"bar\",\"bar\",\"bar\",\"bar\",\"bar\",\"W\",\"%\",\"kW\"]\n",
    "\n",
    "for sensor_num in range(X_data.shape[2]):\n",
    "    sensor_new = sensor_network.add_simsensor(type=sensorTypes[sensor_num], unit_v=sensorUnits[sensor_num])\n",
    "    sensor_new.set_generatorDataSet(X_data[:,:,sensor_num])\n",
    "    sensors.append(sensor_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We can access the Sensor Agents stored in array `sensors` .\n",
    "2. Alternatively, the SensorNetwork Agent automatically keeps track of sensors added by it, we can access the list by calling `get_attr('sensor_list')`\n",
    "3. Here, we demonstrate a function of Sensor Agent which is `read_generator` which returns a random data row from the loaded dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([54.492, 54.426, 54.336, 54.254, 54.242, 54.172, 54.094, 54.043,\n       54.012, 53.922, 53.898, 53.844, 53.934, 54.004, 54.066, 54.098,\n       54.176, 54.258, 54.273, 54.266, 54.348, 54.34 , 54.34 , 54.43 ,\n       54.414, 54.426, 54.437, 54.426, 54.43 , 54.445, 54.418, 54.496,\n       54.473, 54.508, 54.52 , 54.586, 54.602, 54.59 , 54.664, 54.668,\n       54.664, 54.668, 54.664, 54.664, 54.598, 54.59 , 54.602, 54.605,\n       54.598, 54.598, 54.586, 54.598, 54.59 , 54.586, 54.59 , 54.586,\n       54.598, 54.59 , 54.586, 54.602])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the sensors are loaded into array sensors\n",
    "sensor1 = sensors[0]\n",
    "print(len(sensors))\n",
    "\n",
    "#access sensors by either way\n",
    "sensor_network.get_attr('sensor_list')[0].read_generator()\n",
    "sensor1.read_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregator Agents\n",
    "\n",
    "1. We add an Aggregator Agent to the `sensor_network` by calling the function `.add_aggregator(sensorList)` where `sensorList` is an optional list of Sensor Agents which automatically binds the aggregator to the Sensor Agents. \n",
    "\n",
    "2. Aggregator Agent can bind to Sensor Agent in runtime by calling `.bind_sensors(sensorList)`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add aggregators and bind them to sensors\n",
    "aggregator1 = sensor_network.add_aggregator(sensors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor Agents\n",
    "\n",
    "1. Similarly, we can add Predictor Agent by `.add_predictor(aggregator)` with the optional `aggregator` to be binded to.\n",
    "2. For each Predictor Agent, we load the prediction model by `.load_predictor_model(model)` where `model` is a trained ML_Wrapper with signature such as `.predict_model_wUnc(x_test,num_samples)` where `x_test` is the data input and `num_samples` is the number of samples for Monte Carlo sampling.\n",
    "3. Here, we load the previously pickled prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ludwig10/code/envs/agentMET4FOF_use-case_zema-bnn/lib/python3.8/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pickles/bnn_wrapper_2.p'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-4dd81e8ec598>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0mpredictor1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_predictor_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpickle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"pickles/\"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"bnn_wrapper_0.p\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"rb\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0mpredictor2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_predictor_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpickle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"pickles/\"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"bnn_wrapper_1.p\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"rb\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0mpredictor3\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_predictor_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpickle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"pickles/\"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"bnn_wrapper_2.p\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"rb\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0mpredictor4\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_predictor_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpickle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"pickles/\"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"bnn_wrapper_3.p\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"rb\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0mpredictor5\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_predictor_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpickle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"pickles/\"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"bnn_wrapper_4.p\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"rb\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'pickles/bnn_wrapper_2.p'"
     ]
    }
   ],
   "source": [
    "#add predictor and bind to aggregator\n",
    "predictor1 = sensor_network.add_predictor(aggregator=aggregator1)\n",
    "predictor2 = sensor_network.add_predictor(aggregator=aggregator1)\n",
    "predictor3 = sensor_network.add_predictor(aggregator=aggregator1)\n",
    "predictor4 = sensor_network.add_predictor(aggregator=aggregator1)\n",
    "predictor5 = sensor_network.add_predictor(aggregator=aggregator1)\n",
    "\n",
    "#load predictor models\n",
    "predictor1.load_predictor_model(pickle.load(open(\"pickles/\" + \"bnn_wrapper_0.p\", \"rb\")))\n",
    "predictor2.load_predictor_model(pickle.load(open(\"pickles/\" + \"bnn_wrapper_1.p\", \"rb\")))\n",
    "predictor3.load_predictor_model(pickle.load(open(\"pickles/\" + \"bnn_wrapper_2.p\", \"rb\")))\n",
    "predictor4.load_predictor_model(pickle.load(open(\"pickles/\" + \"bnn_wrapper_3.p\", \"rb\")))\n",
    "predictor5.load_predictor_model(pickle.load(open(\"pickles/\" + \"bnn_wrapper_4.p\", \"rb\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionMaker Agent\n",
    "1. We add Decision Maker Agent calling `.add_decisionMaker()` on SensorNetwork agent\n",
    "2. The DM Agent is binded to every predictor by calling `.bind_predictor(predictor)` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionMaker = sensor_network.add_decisionMaker()\n",
    "decisionMaker.bind_predictor(predictor1)\n",
    "decisionMaker.bind_predictor(predictor2)\n",
    "decisionMaker.bind_predictor(predictor3)\n",
    "decisionMaker.bind_predictor(predictor4)\n",
    "decisionMaker.bind_predictor(predictor5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo\n",
    "1. For demo, we run an infinite loop which continuously runs the `.request_sensors_data()`\n",
    "2. Due to the bindings, the requested data will immediately be propagated to all binded Predictor Agents and to Decision Maker Agent\n",
    "3. While this is running, run the dashboard code in a separate terminal to visualize the multi-agent testbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send request to aggregator agents for data from sensors\n",
    "\n",
    "if DemoMode:\n",
    "    for i in range(99999999999):\n",
    "        aggregator1.request_sensors_data()\n",
    "        time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}