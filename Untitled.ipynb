{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook, Fourier transform was performed for all sensors and all cycles. All time signals were deduced the same length by adding the value of the last element at their original length. Amplitudes and uncertainties have been saved into .hdf5 file, which will be read in one of the next cells. Phases are neglected. 24 sensor have been taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import time\n",
    "%pip install openpyxl\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from scipy.signal import find_peaks\n",
    "from scipy import integrate\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from matplotlib._png import read_png\n",
    "from matplotlib.cbook import get_sample_data\n",
    "import h5py\n",
    "import PyDynamic\n",
    "font = {'family' : 'Times New Roman', 'weight' : 'normal', 'size'   : 20}\n",
    "mpl.rcParams['figure.figsize'] = (20,10)\n",
    "mpl.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_a = h5py.File('Amplitudes.hdf5', 'r')\n",
    "hf_uap=h5py.File('Uncertainties.hdf5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_df=[None]*24\n",
    "UAP_df=[None]*24\n",
    "for i in range(24):\n",
    "    A_df[i]=hf_a[\"A_df\"+str(i)]\n",
    "    UAP_df[i]=hf_uap[\"UAP\"+str(i)]\n",
    "    A_df[i]=pd.DataFrame(A_df[i])\n",
    "    UAP_df[i]=pd.DataFrame(UAP_df[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, two ways of feature extraction will be presented. One approach is to calculate the means of all amplitudes at given frequencies (columns) and to choose 200 of the highest ones. This will be done with the function `sort_amplitudes_and_uncertainties`. It will sort the amplitudes´ columns in descending order, according to their means. The number of columns of amplitudes corresponds also to the number of columns of their standard squared uncertainties in UAP. As mentioned before, phases and covariance between amplitudes and phases will be neglected. This means that only columns of uncertainties of amplitudes will be sorted in the way that they follow the columns of amplitudes for which they are calculated.\n",
    "If you want to sort the whole matrix of uncertainties, please have a look at ZEMA machine learning tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The length of time signals with padded values is 23853 (number of points) and sampling period is 0.01 s. This will serve us to get the frequencies for our amplitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_of_sampling_pts=23853\n",
    "sample_period=0.01\n",
    "time=0.01*n_of_sampling_pts# number of sampling points\n",
    "time_steps=np.arange(0, time, 0.01)  \n",
    "freq=PyDynamic.uncertainty.propagate_DFT.GUM_DFTfreq(n_of_sampling_pts,float(time)/n_of_sampling_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_amplitudes_and_uncertainties (N,Amp,U,freq):\n",
    "\n",
    "    Amp.columns = freq                    # Column labels are frequencies. \n",
    "    n_rows, n_columns=Amp.shape\n",
    "    print(\"\\nNumber of cycles is: %s, and number of features is: %s\" % (n_rows, n_columns))\n",
    "    # Calculating the average of absolute vales for each frequency (column).\n",
    "    average_values_from_columns=(Amp.mean())\n",
    "    # Sorting column indices in amplitudes for sorting phases and uncertainties\n",
    "    sorted_columns=np.argsort(average_values_from_columns)[::-1]\n",
    "    # Reindexing all matrices based on columns.\n",
    "    Amp=Amp.reindex(Amp.mean().sort_values(ascending=False).index, axis=1)\n",
    "    c=U.reindex(columns=sorted_columns)\n",
    "    # Taking first N percent columns from sorted amplitudes,phases and ucertainties. \n",
    "    sorted_values_amp=Amp.iloc[:,:N]\n",
    "    sorted_values_uncert_aa=c.iloc[:,:N]                                           \n",
    "    n_rows, n_columns = np.shape(sorted_values_amp)\n",
    "    print(\"\\nNumber of cycles is: %s, and number of selected features is: %s\" % (n_rows, n_columns))\n",
    "    print(np.shape(sorted_values_amp))\n",
    "    \n",
    "    # Informations about the selected frequencies are columns in sorted data frame. \n",
    "    freq_of_sorted_values=(pd.DataFrame(sorted_values_amp.columns)).transpose()\n",
    "    print(\"\\nFirst 200 selected frequencies are:\\n\\n %s\" % freq_of_sorted_values.values[:,:N])\n",
    "    \n",
    "    # Resetting the column labels.\n",
    "    sorted_values_amp.columns=range(N)\n",
    "    sorted_values_uncert_aa.columns=range(N)\n",
    "\n",
    "    print(\"---------------------------------------------------------------------------------\\n\")\n",
    "    # Output \"sorted_values_matrix\" is data frame whose rows-\n",
    "    # -are cycles and columns are selected frequencies. For example,- \n",
    "    # -value at position (i,j) is amplitude for frequency j in cycle i.\n",
    "    return freq_of_sorted_values,sorted_values_amp,sorted_values_uncert_aa\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_of_sorted_values=[None]*24\n",
    "sorted_values_amp=[None]*24\n",
    "sorted_values_uncert_aa=[None]*24\n",
    "for i in range(24):\n",
    "    print(\"Sensor:\",i)\n",
    "    freq_of_sorted_values[i],sorted_values_amp[i],sorted_values_uncert_aa[i] =sort_amplitudes_and_uncertainties(200,A_df[i],UAP_df[i],freq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### An overwiev of the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_of_sorted_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_values_amp[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_values_uncert_aa[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, an arbitrary column of measured data for all parts will be taken (because of simplicity) from the file CMMData.xlsx. For example, it will be 38 dia @200 (external diameter at 200 mm from the left)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measured_part=pd.read_excel(Path('Data')/'AFRC Radial Forge - Zenodoo Upload v3'/'CMMData.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measured_part.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First three columns of `measured_part` are the nominal value and tolerances. These will be dropped, because only measured data of the parts is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target200=measured_part.iloc[3:,6]\n",
    "target200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson correlation between amplitudes at given frequencies (200 columns) and measured diameter at 200 mm from the left is performed in the following cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_coefs=[None]*24\n",
    "column_indices=[None]*24\n",
    "freq_indices=[None]*24\n",
    "for i in range(24):\n",
    "    corr_coefs[i]=sorted_values_amp[i].corrwith(other=target200)\n",
    "    column_indices[i]=np.argsort(np.abs(corr_coefs[i]))[::-1]\n",
    "    freq_indices[i]=freq_of_sorted_values[i][column_indices[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_indices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensors with significant correlation coefficients will be identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "font = {'family' : 'Times New Roman', 'weight' : 'normal', 'size'   : 20}\n",
    "mpl.rcParams['figure.figsize'] = (20,15)\n",
    "mpl.rc('font', **font)\n",
    "def sensors_correlation(i):\n",
    "    num_of_sensor=['Power [kW]', 'Force [kN]', 'A_ges_vibr', 'Schlagzahl [1/min]','A_ACTpos [mm]', 'L_ACTpos [mm]', 'R_ACTpos [mm]','SBA_ActPos [mm]', 'A_ACT_Force [kN]', 'DB_ACT_Force [kN]','L_NOMpos [mm]', 'R_NOMpos [mm]', 'INDA_NOMpos [deg]','A_NOMpos [mm]', 'Frc_Volt', 'IP_ActPos [mm]', 'IP_NomPos','RamRetract_ActSpd [rpm]', 'ForgingBox_Temp', 'TMP_Ind_U1 [°C]','TMP_Ind_F [°C]', 'W2 Durchfluss [l]', 'W1 Durchfluss [l]','L1.R_B41 [bar]']\n",
    "    plt.stem(corr_coefs[i][column_indices[i]] )\n",
    "    plt.ylabel(\"Correlation coefficients\") \n",
    "    plt.title(num_of_sensor[i])\n",
    "\n",
    "interact(sensors_correlation,i=widgets.IntSlider(min=0, max=24, step=1))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second approach is to perform Pearson correlation on unsorted amplitudes at given frequencies. It means Pearson correlation is performed between columns in  *A_df[i]*, where i denotes the sensor. There are 11927 columns in total. After that 200 of columns with highest Pearson correlation coefficients will be extracted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_coefs2=[None]*24\n",
    "column_indices2=[None]*24\n",
    "freq_indices2=[None]*24\n",
    "for i in range(24):\n",
    "    A_df[i].columns=range(11927)\n",
    "    corr_coefs2[i]=(A_df[i].corrwith(other=target200))\n",
    "    column_indices2[i]=np.argsort(np.abs(corr_coefs2[i]))[::-1]\n",
    "    freq_indices2[i]=freq[column_indices2[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in  range(24):\n",
    "    freq_indices2[i]=pd.DataFrame(freq_indices2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_indices2[0].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "font = {'family' : 'Times New Roman', 'weight' : 'normal', 'size'   : 20}\n",
    "mpl.rcParams['figure.figsize'] = (20,15)\n",
    "mpl.rc('font', **font)\n",
    "def sensors_correlation2(i):\n",
    "    num_of_sensor=['Power [kW]', 'Force [kN]', 'A_ges_vibr', 'Schlagzahl [1/min]','A_ACTpos [mm]', 'L_ACTpos [mm]', 'R_ACTpos [mm]','SBA_ActPos [mm]', 'A_ACT_Force [kN]', 'DB_ACT_Force [kN]','L_NOMpos [mm]', 'R_NOMpos [mm]', 'INDA_NOMpos [deg]','A_NOMpos [mm]', 'Frc_Volt', 'IP_ActPos [mm]', 'IP_NomPos','RamRetract_ActSpd [rpm]', 'ForgingBox_Temp', 'TMP_Ind_U1 [°C]','TMP_Ind_F [°C]', 'W2 Durchfluss [l]', 'W1 Durchfluss [l]','L1.R_B41 [bar]']\n",
    "    plt.stem(range(len(column_indices2[i].iloc[:200])),corr_coefs2[i][column_indices2[i].iloc[:200]])\n",
    "    plt.ylabel(\"Correlation coefficients\") \n",
    "    plt.title(num_of_sensor[i])\n",
    "\n",
    "interact(sensors_correlation2,i=widgets.IntSlider(min=0, max=24, step=1))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous plots, it can be concluded that there are significant differences in these approaches. Because the second approach relies only on the correlation coefficients without sorting, this approach will be chosen for the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Amp_corr=[None]*24\n",
    "UA_corr=[None]*24\n",
    "for i in range(24):\n",
    "    Amp_corr[i]=A_df[i].iloc[:,column_indices2[i].iloc[:200]]\n",
    "    UA_corr[i]=UAP_df[i].iloc[:,column_indices2[i].iloc[:200]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensors which are identified as the most significant for the measurements of external diameter are:\n",
    "- 'Power [kW]', \n",
    "- 'Force [kN]', \n",
    "- 'A_ges_vibr', \n",
    "- 'Schlagzahl [1/min]',\n",
    "- 'SBA_ActPos [mm]',  \n",
    "- 'DB_ACT_Force [kN]',\n",
    "- 'Frc_Volt', \n",
    "- 'L1.R_B41 [bar]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assignment of column names\n",
    "list1=[None]*200\n",
    "for i in range(200):\n",
    "    list1[i]=\"Column\"+str(i)\n",
    "Amp_corr[0].columns=list1\n",
    "UA_corr[0].columns=list1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the outcome of the following work is not certain and it is not relied on some previous knowledge, only one sensor will be considered. This is the first sensor, that measures the power.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data from this sensor will be split into training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=pd.read_excel(Path('Data')/'AFRC Radial Forge - Zenodoo Upload v3'/'Data'/'CMMData.xlsx', index_col=3)\n",
    "target=target.drop(columns=['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2'])\n",
    "#target.index\n",
    "\n",
    "nominal_val=pd.DataFrame(target.iloc[0:3,:])\n",
    "target=target.iloc[3:,:]\n",
    "#Path('Data')/'AFRC Radial Forge - Zenodoo Upload v3'/'Data'/file_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=target['38 dia @200'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.columns=[\"Diameter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=Amp_corr[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "X_scale = scale.fit_transform(X)\n",
    "X_scale=pd.DataFrame(X_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assignment of column names\n",
    "list1=[None]*200\n",
    "for i in range(200):\n",
    "    list1[i]=\"Column\"+str(i)\n",
    "X_scale.columns=list1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scale.insert(0, \"Diameter\", y, allow_duplicates = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scale=X_scale.drop(X.columns[3:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, X_scale[\"Diameter\"], test_size = 0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "UA_df_train,UA_df_test,X_train, X_test, y_train, y_test = train_test_split(UA_corr[0],X, y, test_size = 0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "clf=BayesianRidge()\n",
    "a=clf.fit( X_train, y_train, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows the trace with a vertical line at the mean of the trace\n",
    "def plot_trace(trace):\n",
    "    # Traceplot with vertical lines at the mean value\n",
    "    ax = pm.traceplot(trace, figsize=(14, len(trace.varnames)*1.8),\n",
    "                      lines={k: v['mean'] for k, v in pm.df_summary(trace).iterrows()})\n",
    "    \n",
    "    matplotlib.rcParams['font.size'] = 16\n",
    "    \n",
    "    # Labels with the median value\n",
    "    for i, mn in enumerate(pm.df_summary(trace)['mean']):\n",
    "        ax[i, 0].annotate('{:0.2f}'.format(mn), xy = (mn, 0), xycoords = 'data', size = 8,\n",
    "                          xytext = (-18, 18), textcoords = 'offset points', rotation = 90,\n",
    "                          va = 'bottom', fontsize = 'large', color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_trace(normal_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pymc3\n",
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "X_scale = scale.fit_transform(X_train)\n",
    "X_scale=pd.Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_0:\n",
    "    alpha = pm.Normal('alpha', mu=0, sigma=10)\n",
    "    beta = pm.Normal('beta', mu=0, sigma=10,shape=4)\n",
    "    sigma = pm.HalfNormal('sigma',10)\n",
    "\n",
    "    mu = alpha + pm.math.dot(beta, (X_train).T)\n",
    "    Diameter = pm.Normal('Diameter', mu=mu, sigma=sigma, observed=X_train['Diameter'])\n",
    "    trace_0 = pm.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = [trace_0]\n",
    "pm.forestplot(traces, figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.densityplot(traces, var_names=['alpha', 'sigma']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_dict = dict(zip([model_0], traces))\n",
    "comp = pm.compare(model_dict, method='BB-pseudo-BMA')\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3 import traceplot\n",
    "traceplot(trace_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#import theano.tensor as T\n",
    "#from pymc3 import DensityDist, Uniform\n",
    "#with Model() as model:\n",
    "#alpha = Uniform(’intercept’, -100, 100)\n",
    "# Create custom densities\n",
    "#beta = DensityDist(’beta’, lambda value: -1.5 * T.log(1 + value**2), testval=0)\n",
    "#eps = DensityDist(’eps’, lambda value: -T.log(T.abs_(value)), testval=1)\n",
    "# Create likelihood\n",
    "#like = Normal(’y_est’, mu=alpha + beta * X, sd=eps, observed=Y)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formula for Bayesian Linear Regression (follows R formula syntax\n",
    "formula = 'Diameter ~ ' + ' + '.join(['%s' % variable for variable in X_train.columns[1:3]])\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context for the model\n",
    "with pm.Model() as normal_model:\n",
    "  \n",
    "    \n",
    "    # Creating the model requires a formula and data (and optionally a family)\n",
    "    pm.GLM.from_formula(formula, data = X_train)\n",
    "    \n",
    "    # Perform Markov Chain Monte Carlo sampling\n",
    "    normal_trace = pm.sample(draws=100, chains = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install arviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows the trace with a vertical line at the mean of the trace\n",
    "def plot_trace(trace):\n",
    "    # Traceplot with vertical lines at the mean value\n",
    "    ax = pm.traceplot(trace, figsize=(14, len(trace.varnames)*1.8),\n",
    "                      lines={k: v['mean'] for k, v in pm.df_summary(trace).iterrows()})\n",
    "    \n",
    "    matplotlib.rcParams['font.size'] = 16\n",
    "    \n",
    "    # Labels with the median value\n",
    "    for i, mn in enumerate(pm.df_summary(trace)['mean']):\n",
    "        ax[i, 0].annotate('{:0.2f}'.format(mn), xy = (mn, 0), xycoords = 'data', size = 8,\n",
    "                          xytext = (-18, 18), textcoords = 'offset points', rotation = 90,\n",
    "                          va = 'bottom', fontsize = 'large', color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_trace(normal_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(normal_trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_a.close()\n",
    "hf_uap.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(normal_trace, figsize = (14, 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_formula = 'Diameter = '\n",
    "for variable in normal_trace.varnames:\n",
    "    model_formula += ' %0.2f * %s +' % (np.mean(normal_trace[variable]), variable)\n",
    "\n",
    "' '.join(model_formula.split(' ')[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
