{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Methods for Feature Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Before usage of this notebook, please download folder from this link https://drive.google.com/open?id=1Eme87KqRZx8-sANpoHeCIOOWcSRYsMLy\n",
    "and store the files in the same folder which is location for this notebook.*    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Importing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ehlimana\\Anaconda3\\envs\\ZEMA\\lib\\site-packages\\PyDynamic\\identification\\fit_filter.py:34: DeprecationWarning: The module *identification* will be combined with the module *deconvolution* and renamed to *model_estimation* in the next major release 3.0. From then on you should only use the new module *model_estimation* instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import h5py                                     # Importing the h5 package.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import PyDynamic  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.79'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PyDynamic import __version__ as version\n",
    "version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "    Input matrices have dimensions: (2000, 6291), where 2000 represents number of measurements in time\n",
      "    and 6291 represents number of cycles.\n"
     ]
    }
   ],
   "source": [
    "filename = 'Sensor_data_2kHz.h5'                # Data filename.\n",
    "f = h5py.File(filename, 'r')                    # Importing the h5 file. \n",
    "\n",
    "#print(\"Keys: %s\" % f.keys())\n",
    "a_group_key = list(f.keys())[0]\n",
    "\n",
    "data = list(f[a_group_key])                     # Transforming data into list\n",
    "\n",
    "sensorADC=[]                                       # Initialising a list \"sensor\" and\n",
    "for i in range(11):                                # Filling it with data from all sensors \n",
    "    sensorADC.append(pd.DataFrame(data[i][:][:]))\n",
    "\n",
    "for i in range(11):                             \n",
    "    sensorADC[i]=sensorADC[i].iloc[:,:6291]           # Cuting the last cycle because it contains all zero elements.\n",
    "\n",
    "print(\"\"\"    \n",
    "    Input matrices have dimensions: %s, where %s represents number of measurements in time\n",
    "    and %s represents number of cycles.\"\"\" % (np.shape(sensorADC[0]),np.shape(sensorADC[0])[0],np.shape(sensorADC[0])[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting into SI units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset=[0, 0, 0, 0, 0.00488591, 0.00488591, 0.00488591,  0.00488591, 1.36e-2, 1.5e-2, 1.09e-2]\n",
    "gain=[5.36e-9, 5.36e-9, 5.36e-9, 5.36e-9, 3.29e-4, 3.29e-4, 3.29e-4, 3.29e-4, 8.76e-5, 8.68e-5, 8.65e-5]\n",
    "b=[1, 1, 1, 1, 1, 1, 1, 1, 5.299641744, 5.299641744, 5.299641744]\n",
    "k=[250, 1, 10, 10, 1.25, 1, 30, 0.5, 2, 2, 2]\n",
    "units=['[Pa]', '[g]', '[g]', '[g]', '[kN]', '[bar]', '[mm/s]', '[A]', '[A]', '[A]', '[A]']\n",
    "\n",
    "sensor=[0]*len(sensorADC)\n",
    "\n",
    "for i in range(len(sensorADC)):\n",
    "    sensor[i]=((sensorADC[i]*gain[i])+offset[i])*b[i]*k[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### If you have problems with previous step, you can skip conversion into SI units by runing next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor=sensorADC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading of train and test data\n",
    "*Note: see 2_Machine_Learning_using_Best_Fourier_Coefficients.ipynb. Data were split into train and test data for k=85% \n",
    "Based on this, target_train_vector and target_test_vector were provided. These vectors will be used for FFT and DFT methods.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "train_test1= h5py.File(\"Train_test_data_split\",\"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train_vector=train_test1[\"target_train_vector\"]\n",
    "target_test_vector=train_test1[\"target_test_vector\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting arrays into data frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train_vector=pd.DataFrame(target_train_vector)\n",
    "target_test_vector=pd.DataFrame(target_test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=list(target_train_vector[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, after this step main data to work on are lists: \n",
    "\n",
    "\"sensor_train\" with their class labels \"train_target\"\n",
    " \n",
    "and \n",
    " \n",
    "\"sensor_test\" with their class labels \"test_target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning data for one sensor has dimensions:  (2000, 5347) ,      ('sensor_train') \n",
      "and it's target vector has length:  (5347, 1) ,               ('target_train_vector') \n",
      "\n",
      "Testing data for one sensor has dimensions:  (2000, 944) ,      ('sensor_test') \n",
      "and it's target vector has length:  (944, 1) ,        ('target_test_vector') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sensor_train=[0]*11\n",
    "sensor_test=[0]*11\n",
    "\n",
    "for i in range(11):\n",
    "    sensor_train[i]=sensor[i].loc[:,target_train_vector.index]\n",
    "\n",
    "print(\"Traning data for one sensor has dimensions: \", sensor_train[10].shape,\",      ('sensor_train') \")\n",
    "print(\"and it's target vector has length: \", target_train_vector.shape,\",               ('target_train_vector') \\n\")\n",
    "\n",
    "for i in range(11):\n",
    "    sensor_test[i]=sensor[i].loc[:,target_test_vector.index]\n",
    "\n",
    "print(\"Testing data for one sensor has dimensions: \", sensor_test[10].shape,\",      ('sensor_test') \")\n",
    "print(\"and it's target vector has length: \", target_test_vector.shape,\",        ('target_test_vector') \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at the data from one sensor after splitting for better understanding of structure for next steps. Number of rows is 2000 and each column is one random measurement cycle. Table shows only first five samples in time (five rows) for each cycle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5337</th>\n",
       "      <th>5338</th>\n",
       "      <th>5339</th>\n",
       "      <th>5340</th>\n",
       "      <th>5341</th>\n",
       "      <th>5342</th>\n",
       "      <th>5343</th>\n",
       "      <th>5344</th>\n",
       "      <th>5345</th>\n",
       "      <th>5346</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.052346</td>\n",
       "      <td>0.035353</td>\n",
       "      <td>0.150057</td>\n",
       "      <td>0.165182</td>\n",
       "      <td>0.007607</td>\n",
       "      <td>0.085452</td>\n",
       "      <td>-0.004497</td>\n",
       "      <td>-0.015737</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>0.030425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175565</td>\n",
       "      <td>0.329240</td>\n",
       "      <td>0.210907</td>\n",
       "      <td>0.184818</td>\n",
       "      <td>0.050059</td>\n",
       "      <td>0.108024</td>\n",
       "      <td>0.142261</td>\n",
       "      <td>0.358908</td>\n",
       "      <td>0.161659</td>\n",
       "      <td>0.362495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013661</td>\n",
       "      <td>0.062294</td>\n",
       "      <td>0.073791</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>0.045830</td>\n",
       "      <td>0.097229</td>\n",
       "      <td>0.054530</td>\n",
       "      <td>0.065786</td>\n",
       "      <td>0.283926</td>\n",
       "      <td>0.108324</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218415</td>\n",
       "      <td>0.447456</td>\n",
       "      <td>0.349365</td>\n",
       "      <td>0.299143</td>\n",
       "      <td>0.048282</td>\n",
       "      <td>0.207124</td>\n",
       "      <td>0.431144</td>\n",
       "      <td>0.638964</td>\n",
       "      <td>0.378436</td>\n",
       "      <td>0.698642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088680</td>\n",
       "      <td>-0.157930</td>\n",
       "      <td>0.016507</td>\n",
       "      <td>0.020354</td>\n",
       "      <td>0.090973</td>\n",
       "      <td>-0.215526</td>\n",
       "      <td>0.061279</td>\n",
       "      <td>0.034248</td>\n",
       "      <td>0.184389</td>\n",
       "      <td>0.141985</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.369747</td>\n",
       "      <td>0.213356</td>\n",
       "      <td>0.078377</td>\n",
       "      <td>0.058016</td>\n",
       "      <td>-0.075154</td>\n",
       "      <td>0.073886</td>\n",
       "      <td>0.393118</td>\n",
       "      <td>0.545816</td>\n",
       "      <td>0.170193</td>\n",
       "      <td>0.216192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040834</td>\n",
       "      <td>-0.081864</td>\n",
       "      <td>0.264404</td>\n",
       "      <td>0.090820</td>\n",
       "      <td>0.189913</td>\n",
       "      <td>0.068431</td>\n",
       "      <td>-0.101957</td>\n",
       "      <td>0.105077</td>\n",
       "      <td>0.037419</td>\n",
       "      <td>0.232769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012711</td>\n",
       "      <td>0.306476</td>\n",
       "      <td>0.201671</td>\n",
       "      <td>0.298681</td>\n",
       "      <td>0.069645</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>0.371483</td>\n",
       "      <td>0.673113</td>\n",
       "      <td>0.286716</td>\n",
       "      <td>0.490413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033578</td>\n",
       "      <td>-0.044107</td>\n",
       "      <td>0.056629</td>\n",
       "      <td>0.022157</td>\n",
       "      <td>0.091190</td>\n",
       "      <td>-0.215849</td>\n",
       "      <td>-0.147002</td>\n",
       "      <td>0.120792</td>\n",
       "      <td>0.155922</td>\n",
       "      <td>0.038234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026665</td>\n",
       "      <td>0.382832</td>\n",
       "      <td>0.299239</td>\n",
       "      <td>0.259937</td>\n",
       "      <td>0.135226</td>\n",
       "      <td>0.151655</td>\n",
       "      <td>0.500641</td>\n",
       "      <td>0.763004</td>\n",
       "      <td>0.247051</td>\n",
       "      <td>0.542166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5347 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0 -0.052346  0.035353  0.150057  0.165182  0.007607  0.085452 -0.004497   \n",
       "1  0.013661  0.062294  0.073791  0.002720  0.045830  0.097229  0.054530   \n",
       "2  0.088680 -0.157930  0.016507  0.020354  0.090973 -0.215526  0.061279   \n",
       "3  0.040834 -0.081864  0.264404  0.090820  0.189913  0.068431 -0.101957   \n",
       "4  0.033578 -0.044107  0.056629  0.022157  0.091190 -0.215849 -0.147002   \n",
       "\n",
       "       7         8         9     ...      5337      5338      5339      5340  \\\n",
       "0 -0.015737  0.004307  0.030425  ... -0.175565  0.329240  0.210907  0.184818   \n",
       "1  0.065786  0.283926  0.108324  ... -0.218415  0.447456  0.349365  0.299143   \n",
       "2  0.034248  0.184389  0.141985  ... -0.369747  0.213356  0.078377  0.058016   \n",
       "3  0.105077  0.037419  0.232769  ...  0.012711  0.306476  0.201671  0.298681   \n",
       "4  0.120792  0.155922  0.038234  ... -0.026665  0.382832  0.299239  0.259937   \n",
       "\n",
       "       5341      5342      5343      5344      5345      5346  \n",
       "0  0.050059  0.108024  0.142261  0.358908  0.161659  0.362495  \n",
       "1  0.048282  0.207124  0.431144  0.638964  0.378436  0.698642  \n",
       "2 -0.075154  0.073886  0.393118  0.545816  0.170193  0.216192  \n",
       "3  0.069645  0.011811  0.371483  0.673113  0.286716  0.490413  \n",
       "4  0.135226  0.151655  0.500641  0.763004  0.247051  0.542166  \n",
       "\n",
       "[5 rows x 5347 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_train[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection \n",
    "### Feature selection using Pearson correlation coefficients\n",
    "\n",
    "After all these unsupervised steps, this step is done with knowledge of cycle‘s group affiliation. Selection is based on a target vector which represents label for each cycle. The method is very simple, Pearson correlation coefficient is calculated between selected features and target vector and it is done for all sensors. After that, number of features with overall highest Pearson correlation coefficients is selected.\n",
    "\n",
    "#### Pearson correlation\n",
    "\n",
    "A Pearson correlation is a number between -1 and 1 that indicates the extent to which two variables are linearly related. A correlation coefficient indicates the extent to which dots in a scatterplot lie on a straight line. The stronger the association of the two variables, the closer the Pearson correlation coefficient, r, will be to either +1 or -1 depending on whether the relationship is positive or negative, respectively.\n",
    "\n",
    "_Pearson correlation formula [3]:_\n",
    "\n",
    "<img src=\"pictures/formula1.png\">\n",
    "\n",
    "- $x$ and $y$ are two vectors of length n\n",
    "- $m_x$ and $m_y$ corresponds to the means of x and y, respectively.\n",
    "\n",
    "Different relationships and their correlation coefficients are shown in the figure below [4]:\n",
    "\n",
    "<img src=\"pictures/Correlation_examples.png\">\n",
    "\n",
    "Firstly, correlation coefficients are calculated for all features and their values are stored in the list `corr`. Then, function called `largest_indices` finds indices for wanted amount of features with highest correlation coefficients. Function output is stored into lists 'sensor_n' and 'feature_n', where element in 'sensor_n' means which sensor, and related element in 'feature_n' means which feature of that sensor is accessed.\n",
    "\n",
    "Example:\n",
    "If element in 'sensor_n' is 5, and the element in 'feature_n' at the same position is 50, that means that you can access that feature in this way:\n",
    "\n",
    "``` python\n",
    "    sorted_values_from_all_sensors[5].iloc[:][50]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Reading the data for 10% of the highest amplitudes from the file Machine_Learning_using_Best_Fourier_Coefficients.ipynb calculated from FFT:\n",
    "Values were obtained by using factor of splitting data into train and test from the above.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "amp_fft1= h5py.File(\"Sorted_vaules_from_all_sensors.hdf5\",\"r\")\n",
    "freq_fft1= h5py.File(\"Sorted_freq_from_all_sensors.hdf5\",\"r\")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_of_sorted_values=[0]*len(sensor_train)\n",
    "sorted_values_from_all_sensors=[0]*len(sensor_train)\n",
    "for i in range(len(sensor)):\n",
    "    freq_of_sorted_values[i]=freq_fft1[\"freq_of_sorted_values\"+str(i)]\n",
    "    sorted_values_from_all_sensors[i]=amp_fft1[\"sorted_values_from_all_sensors\"+str(i)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results provided from FFT do not contain uncertainties. First method analyzed for the feature selection is Pearson correlation performed on these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many features out of 1100 you want to select (recommended is 500): 500\n",
      "\n",
      "Dimension of target matrix is:\n",
      "                                                  (5347, 1)\n",
      "Dimension of amplitude matrix for one sensor is:\n",
      "                                                  (5347, 100)\n",
      "Array of correlation coefficients has size:\n",
      "                                                  (11, 100)\n",
      "Sensor indices of location of features in >sorted_values_from_all_sensors< matrix: \n",
      "\n",
      "[ 7 10 10  8  8  2  9  0  0  1  0  7  2  3  2  9  2  3  5  3  1  3  7  3\n",
      "  3  3  9 10  0  5  7  0  0  0  0  2  3  0  2  0  9  3  3  2  7  3  3  3\n",
      "  3  0  0  3  3  3  3  0  3  2  0  3  2  3  3  0  2  3  9  2  2  0  2  0\n",
      "  8  2  0 10  2  7  2  3  3  2  2  0  3  3  3  3  1  8  3  0  2  3  1  2\n",
      "  3  3  2  9  3  3  0  3  0  3  8 10 10  0  2  3  2  3  3  3  3  0  7  3\n",
      "  1  0  3  0  3  0  3  9 10  2  7  0  1  3  1 10  3  2  9  3  7  0  5  9\n",
      "  1 10 10  2  2  2  1 10  7  2  2  3  7  8  2  2  8  9  2  2  2  2  2  2\n",
      "  0  2  0 10  1  1  2  2  7  7  0  3  2  0  0  2  2  0  3  0  0  2  2  7\n",
      "  1  3  2  1  0  7  0  7  3  2  2  2  0  2  8  2  2  3  2  9  0  0  2  7\n",
      "  2  2  0  0  2  5  3  0  8  7  8  2  0  0  2  3  2  2  7  9  2 10  0  7\n",
      " 10  0  2  0  2  3  0  2  0  0  0  7  2  7  2  7  9  2  0  1  3  2  7  7\n",
      "  7  0  1  7  2  7  3  7  3  7  3  7  7  7  0  7  7  7  0  1  3  1  9  0\n",
      "  3  3  7  8  7  7  5  0  3 10  7  7  0  7  0  7  0  0 10  3  7  1  7  7\n",
      "  7  7  0  7  7  7  2  7  2  7  7 10  7  9  1  8  3  1  9  0  8 10  9  3\n",
      "  7  7  2  0  7 10 10  9  1  7  7  1  4  1  8  3 10  8  1  9  9 10  0  0\n",
      "  9  6  1 10  9  0  9  7 10  3  9  1  7  8  9  0  2 10 10  1  9  1  2  1\n",
      "  9 10  1 10  8  9  7  9  9  9  8  7  9  6  3  9  8  7  8  7  8  8 10  7\n",
      "  2  8 10  8 10  9  8  8  5  9  0  1  8 10  1 10 10 10  3  7  6 10  0  0\n",
      "  8  9  8 10  8  8 10 10  1  9  9  9  8  7  9 10  9  8  8  8 10  8  9 10\n",
      "  3  8  8  1  3  8  8  8  7  6  1  1  4 10  7 10  3  6  0  4  8  4  0  1\n",
      "  9  9 10  3  2  8  4  2  8 10  8  8  1  8  8  8  9  7  8  2]\n",
      "\n",
      "Column indices of location of features in >sorted_values_from_all_sensors< matrix: \n",
      "\n",
      "[27 44 41 60 82 25 73  1 18  2 78 14 98 80 97  2 17  2 12 26  0 36 47 30\n",
      " 40 23 17  6 52 13  8 59 53 67 95 74 24 56 41 96 37 56  4 33 62  7  1 43\n",
      " 72 61 50 64 47 60 87 43 58 81 44  6 35 88 97 40 56 78 66 85 69 41 12 45\n",
      " 37 51 14 24 42 35 22 25 15 52 71 51 18 86  5 77 37 41 73 60 34  9 16 72\n",
      " 14 12 88 44 98 20 93 22  3 32 11 34 87 36 68 45  7 19 82 16 17 39 87 13\n",
      "  4 58 68 37 28 47 10 71  2 75 67 86 20 11 15 91 62 82 80 33 53 25 10  1\n",
      " 59  1 73 84 43 10 50 50 11 19 32 34  1 25 31 94  1 25 92 60 83 29 26 61\n",
      " 35 30 27 26 31 44 13 59 69 78 11 44 67 21 15 55 95 76 53 57  0 20 73 10\n",
      "  8 52 21 65  6 58 34 36 69 48 62 63 26 38 28 79 53 92 86 21 77 66 49 13\n",
      " 27 44  9 99 39  8  8 20 90 90 20 77 32 23 89 41 46 40 70 28 54 30 48 38\n",
      " 22 31 50  8 76 37 68 57 81 82 38 73 70 97 66 98 16 47 22 13 29 58 79 34\n",
      " 84 80 28 43 45 32  3 52 49 56 74 28 37 92 83  9 44 83 85 78 31  1 92 72\n",
      " 65 76 49 19 46 41  7 55 89 65 72 48 92 50 65 31 28 30 18 59 59 52 86 25\n",
      " 22 94 49 95 89 39 91 91 65 77 23 35 85 29 48 30 54 47 47 74 17 60 18 66\n",
      " 65 21 36 91 15 33 99 97 99 54 19 93  7 67 62 27 29 31 43 32 31 19 62 70\n",
      " 77  1 27 94 86 71 84  7 96 21 26 57 81 32 88 64 18 88 90 60 95 49 93 18\n",
      "  0  0 72 32 95 40 33 53 65 49 86 18 13 33 95 58 94  6  0 45 75 14 27 55\n",
      "  6 35 71 24 74 60 29 59  5 55 17 90 69 15 82 76 86 77 46  0 41 70 33 19\n",
      " 83 62 64 72 45 78 49 81 56 34 46 67 70 71 43 52 23 46 72 96 57 33 63 55\n",
      " 96 54 43 70 71 85 55 67 17 35 29 23 93 63 16 58 38 43 89 94 61  9 29 55\n",
      " 38 12 36 48 78 81 92 24 63 47 73 87 83 48 68 13 42  5 65 87]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "N=10 #percentage of highest amplitudes, see: Machine_Learning_using_Best_Fourier_Coefficients.ipynb\n",
    "n_of_samples=2000 #number of samples, see: Machine_Learning_using_Best_Fourier_Coefficients.ipynb\n",
    "\n",
    "n_features_for_select=0\n",
    "for i in range(len(sorted_values_from_all_sensors)):\n",
    "    n_features_for_select=n_features_for_select+int(len(sorted_values_from_all_sensors[i][0][:]))\n",
    "\n",
    "# Defining how much of features with biggest Pearson correllation coeff. will be selected.\n",
    "n_of_features = int(input(\"How many features out of %s you want to select (recommended is 500): \" % n_features_for_select))\n",
    "\n",
    "\n",
    "target_matrix = pd.DataFrame(target)        # Transforming list \"target\" into data frame \"target_matrix\"\n",
    "\n",
    "print(\"\\nDimension of target matrix is:\")\n",
    "print(\"                                                 \", target_train_vector.shape)\n",
    "print(\"Dimension of amplitude matrix for one sensor is:\")\n",
    "print(\"                                                 \", sorted_values_from_all_sensors[0][:,:].shape)\n",
    "\n",
    "corr=list(range(11))                      # Making list for correlation coefficients.\n",
    "p_value=list(range(11))\n",
    "\n",
    "for j in range(11):                       # Making sublists in \"corr\" for each sensor.\n",
    "    corr[j]=list(range(round((N/100.0)*n_of_samples/2)))\n",
    "    p_value[j]=list(range(round((N/100.0)*n_of_samples/2)))\n",
    "    \n",
    "# Calculating correlation coefficients for each column of each sensor with respect to target.\n",
    "for j in range(11):\n",
    "    for i in range(round((N/100.0)*n_of_samples/2)):\n",
    "        corr[j][i],p_value[j][i]=pearsonr(np.abs(sorted_values_from_all_sensors[j][:,i]),target_train_vector[0])\n",
    "\n",
    "#matrix_corr_coeff = np.transpose(pd.DataFrame(corr))# Transforming list of correlation coefficients to data frame.\n",
    "corr_array=np.array(corr)                                   # Transforming list of correlation coefficients to nparray\n",
    "\n",
    "print(\"Array of correlation coefficients has size:\")\n",
    "print(\"                                                 \",corr_array.shape)  \n",
    "\n",
    "def largest_indices(array, n):                               # Function that find indices for 500 biggest Pearson-\n",
    "    \"\"\"Returns the n largest indices from a numpy array.\"\"\"  # -correlation coefficients.\n",
    "    flat = array.flatten()\n",
    "    indices = np.argpartition(flat, -n)[-n:]\n",
    "    indices = indices[np.argsort(-flat[indices])]\n",
    "    return np.unravel_index(indices, array.shape)  \n",
    "\n",
    "# sensor_n is the index of the sensor number.\n",
    "# feature_n is the index of the feature number for each sensor number.\n",
    "sensor_n, feature_n = largest_indices(corr_array, n_of_features)\n",
    "\n",
    "print(\"Sensor indices of location of features in >sorted_values_from_all_sensors< matrix: \\n\")\n",
    "print(sensor_n)\n",
    "print(\"\\nColumn indices of location of features in >sorted_values_from_all_sensors< matrix: \\n\")\n",
    "print(feature_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  76 or  15.20 %\n",
      "Number of features from sensor  1 is:  38 or  7.60 %\n",
      "Number of features from sensor  2 is:  80 or  16.00 %\n",
      "Number of features from sensor  3 is:  77 or  15.40 %\n",
      "Number of features from sensor  4 is:   5 or  1.00 %\n",
      "Number of features from sensor  5 is:   6 or  1.20 %\n",
      "Number of features from sensor  6 is:   5 or  1.00 %\n",
      "Number of features from sensor  7 is:  72 or  14.40 %\n",
      "Number of features from sensor  8 is:  50 or  10.00 %\n",
      "Number of features from sensor  9 is:  45 or  9.00 %\n",
      "Number of features from sensor 10 is:  46 or  9.20 %\n",
      "----------------------------------------------------\n",
      "                                             100.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "abs_top_n_together_matrix=np.zeros((sorted_values_from_all_sensors[0].shape[0], n_features_for_select))\n",
    "percentage_p,abs_top_n_together_matrix=percentage(sensor_n,feature_n,sorted_values_from_all_sensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the found indices for highest features, all of them are put together into a list `top_n_features`, but separated into sublists based on the sensor they are taken from. Then, by comparing the sizes of these groups it is shown how many of those selected features are from which sensor.\n",
    "\n",
    "After that, they are merged into one feature matrix `abs_top_n_together_matrix`, and all steps from here on are done on these features with absolute values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo method for the feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Reading the data for 10% of the highest amplitudes from the file Machine_Learning_using_Best_Fourier_Coefficients.ipynb calculated from DFT:\n",
    "Values were obtained by using factor of splitting data into train and test from the above.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "amp_dft2= h5py.File(\"DFTSorted_vaules__from_all_sensors.hdf5\",\"r\")\n",
    "freq_dft2= h5py.File(\"DFTSorted_freq_from_all_sensors.hdf5\",\"r\") \n",
    "ph_dft2= h5py.File(\"DFTSorted_ph_from_all_sensors.hdf5\",\"r\")\n",
    "u_a_dft2= h5py.File(\"DFTSorted_uncer_from_all_sensors_a.hdf5\",\"r\")\n",
    "u_ap_dft2= h5py.File(\"DFTSorted_uncer_from_all_sensors_ap.hdf5\",\"r\")    \n",
    "u_pp_dft= h5py.File(\"DFTSorted_uncer_from_all_sensors_pp.hdf5\",\"r\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_of_sorted_values=[0]*len(sensor_train)\n",
    "sorted_values__amp_from_all_sensors=[0]*len(sensor_train)\n",
    "sorted_uncer_from_all_sensors_a=[0]*len(sensor_train)\n",
    "for i in range(len(sensor)):\n",
    "    freq_of_sorted_values[i]=freq_dft2[\"freq_of_sorted_values\"+str(i)]\n",
    "    sorted_values__amp_from_all_sensors[i]=amp_dft2[\"sorted_values_amp_from_all_sensors\"+str(i)]\n",
    "    sorted_uncer_from_all_sensors_a[i]=u_a_dft2[\"sorted_uncer_from_all_sensors_a\"+str(i)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results provided from DFT contain uncertainties of amplitudes, phases and their covariances. Second method analyzed for the feature selection is Monte Carlo method which uses Pearson correlation performed on these data. \n",
    "\n",
    "Random samples were taken from multivariate normal distribution of amplitudes and their uncertainties. Phases and their uncertainties have not been included. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features with highest Pearson correlation coefficients through M Monte Carlo trials will be selected. \n",
    "\n",
    "The application of Monte Carlo method can be stated through following steps:\n",
    "\n",
    "1) Class `Normal_ZeroCorr` -  Multivariate normal distribution with zero correlation was defined. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source code from PyDynamic\n",
    "class Normal_ZeroCorr:\n",
    "    \"\"\"     Multivariate normal distribution with zero correlation\"\"\"\n",
    "    def __init__(self, loc=np.zeros(1), scale=np.zeros(1)):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "            loc: np.ndarray, optional\n",
    "                mean values, default is zero\n",
    "            scale: np.ndarray, optional\n",
    "                standard deviations for the elements in loc, default is zero\n",
    "        \"\"\"\n",
    "        if isinstance(loc, np.ndarray) or isinstance(scale, np.ndarray):\n",
    "            # convert loc to array if necessary\n",
    "            if not isinstance(loc, np.ndarray):\n",
    "                self.loc = loc * np.ones(1)\n",
    "            else:\n",
    "                self.loc = loc\n",
    "            # convert scale to arraym if necessary\n",
    "            if not isinstance(scale, np.ndarray):\n",
    "                self.scale = scale * np.ones(1)\n",
    "            else:\n",
    "                self.scale = scale\n",
    "\n",
    "            # if one of both (loc/scale) has length one, make it bigger to fit\n",
    "            # size of the other\n",
    "            if self.loc.size != self.scale.size:\n",
    "                Nmax = max(self.loc.size, self.scale.size)\n",
    "                if self.loc.size == 1 and self.scale.size != 1:\n",
    "                    self.loc = self.loc * np.ones(Nmax)\n",
    "                elif self.scale.size == 1 and self.loc.size != 1:\n",
    "                    self.scale = self.scale * np.ones(Nmax)\n",
    "                else:\n",
    "                    raise ValueError(\n",
    "                        \"loc and scale do not have the same dimensions. (And \"\n",
    "                        \"none of them has dim == 1)\")\n",
    "        else:\n",
    "            raise TypeError(\"At least one of loc or scale must be of type \"\n",
    "                            \"numpy.ndarray.\")\n",
    "    def rvs(self, size=1):\n",
    "        # This function mimics the behavior of the scipy stats package\n",
    "        return np.tile(self.loc, (size, 1)) + \\\n",
    "               np.random.randn(size, len(self.loc)) * \\\n",
    "               np.tile(self.scale, (size, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) N% of amplitudes are considered as input quantities *Xi*, along with their uncertainties. \n",
    "\n",
    "3) Sampling from the assigned distribution (in this case, normal distribution ) is performed  for every cycle by using class `Normal_ZeroCorr` -  Multivariate normal distribution with zero correlation. For example, number of  performed MC trials is 100.\n",
    "\n",
    "4) List *Xi_dist* sized´[number of sensors] with sublist sized [number of cycles] contains samples from multivariate normal distribution of N% of amplitudes for 100 MC trials. Sublist contains np.array((100, N% of amplitudes)). This means for each cycle, there are 100 draws for every of 10% amplitudes.\n",
    "\n",
    "5) List *A* sized´[number of trials=100] with sublist sized [number of sensors] collects samples from all cycles for each MC trial in np.array((num of cycles, N% of amplitudes)). This means, for example for the first trial, draws from all cycles were collected.\n",
    "\n",
    "\n",
    "*Note: Despite the mathematical and physical connection of amplitude and phase, in many practical cases the covariances  are considered to be zero.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of Monte Carlo trials:10\n"
     ]
    }
   ],
   "source": [
    "#setting MC trials\n",
    "trials=int(input(\"Enter the number of Monte Carlo trials:\"))\n",
    "#Xi_dist collects samples in trials for every sensor\n",
    "Xi_dist=list(range(len(sensor)))\n",
    "\n",
    "\n",
    "for s in range(len(sensor)):\n",
    "    #Example: sensor index=0, 5000 cycles, 1000 trials for each cycle,N% of amplitudes = 100: \n",
    "    #Xi_dist[0][:5000].shape=(1000,100)\n",
    "    Xi_dist[s]=list(range(sorted_values__amp_from_all_sensors[0].shape[0]))\n",
    "    for d in range(sorted_values__amp_from_all_sensors[0].shape[0]):\n",
    "        Xi_dist[s][d]=np.zeros((trials,sorted_values__amp_from_all_sensors[0].shape[1]))\n",
    "        \n",
    "\n",
    "#A - collecting value of each trial for every cycle. \n",
    "A=list(range(trials))\n",
    "\n",
    "for f in range(trials):\n",
    "#Example: Zero sensor, first trial, - A[0][1].shape=5347,100\n",
    "#initializing zero values\n",
    "    A[f]=list(range(len(sensor)))\n",
    "    for s in range(len(sensor)):\n",
    "        #Example:sensor index=0, 5000 cycles, 1000 trials for each cycle,N% of amplitudes = 100: \n",
    "        #A[:1000][0].shape=(5000,100)\n",
    "        A[f][s]=np.zeros((sorted_values__amp_from_all_sensors[0].shape))\n",
    "\n",
    "for i in range(len(sensor)):\n",
    "    for m in range(sorted_values__amp_from_all_sensors[0].shape[0]):\n",
    "        dist = Normal_ZeroCorr(loc=sorted_values__amp_from_all_sensors[i][m,:],scale=np.sqrt(sorted_uncer_from_all_sensors_a[i][m,:]))\n",
    "        Xi_dist[i][m]=dist.rvs(trials)\n",
    "        #A matrix will be used for Pearson's correlation:\n",
    "        # Adding values from Xi_dist to A:\n",
    "    for j in range(trials):\n",
    "        for s in range(sorted_values__amp_from_all_sensors[0].shape[0]):\n",
    "            A[j][i][s]=Xi_dist[i][s][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Model function is function largest_indices(corr_array[trial], n_of_features), which is based on Pearson correlation with output quantitites: *corr* and *p_value*\n",
    "\n",
    "6) First, Pearson correlation is conducted for *100* MC trials, resulting in:\n",
    "    \n",
    "    corr=list(range(100))                   \n",
    "    p_value=list(range(100))\n",
    "\n",
    "7) For every trial, values stored in *corr* list were put in np.array (corr_array[trial]=np.array(corr[trial]))\n",
    "\n",
    "8) Function largest_indices(corr_array[trial], n_of_features_x) is executed.\n",
    "\n",
    "9) Results of the function execution (sensor and column indices of features) were stored in  lists: \n",
    "    sensor_n_x[trial],feature_n_x[trial]. For 100 MC trials, there will be 100 elements of lists in sensor_n_x and feature_n_x. One element for one trial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many features out of 1100 you want to select (recommended is 500): 500\n",
      "Array of correlation coefficients for one trial has size:\n",
      "                                                  (11, 100)\n",
      "Sensor indices of location of features for the first trial in >sorted_values__amp_from_all_sensors< matrix  \n",
      "\n",
      "[ 2  0 10  0  2  0  2  2  3  9  3  3  3  9  3  3  2 10  2  2  0  3  3  3\n",
      "  1  7  8  0  3  7  0  0  8  1  0  2  3  0  3  0  2  0  3  0  2 10  0  3\n",
      "  2  0  2  2  2  2  2  3  0  2  3  0  0  2  3 10  3  0  3  9  3  0  3  2\n",
      "  3  3  0  2  3  3  3  3  0  2  8  3  2  2  3  3  3  3  3  3  3  3  0  0\n",
      "  3  3  0  2  0  3  3  5 10  2  3  0 10  3  0  3  2  2  2  2  8  2  2  2\n",
      "  0  2  3  2  5  2  9  2  2  0  2 10  2  3  2  2  0  0  2  2  0  0  3  2\n",
      "  2  0  2  8  3  2  0  3  0  2  2  2  9  2  2  2  0  2  7  2  0  3  2  2\n",
      "  2  3  2  1  0  0  2  2  0  2  0  0  2  2  0  0  0  2  2  2  2  0  3  2\n",
      "  0  0  0  3  3  2  0  0  1  2  3  3  1  3  8  9  3  0 10  5  0  3  9  0\n",
      "  3  0 10 10  8 10  3  3  1  1  1  0  0  7  3  0  0  8  2  7  0  0  0  1\n",
      "  3  1  0  0  2  3  2  9  1  0  7  3 10  5  1  9  9  1  3 10  3  9  1  6\n",
      "  4  0  3  5  1  8  2  9  0  0  9  1  0 10  2  0  3  7  3  8  7  2  9 10\n",
      "  8  9  3  8  1  0  8  7  7  1  9  5 10  0  0  9 10 10  8  7  1  9  9  8\n",
      "  7  8  1  1  9  7  4  9  3  2  1  3  1 10  2  1  0  8  1  7  2  1  1  9\n",
      " 10  1  8  0  8  2  1  1  3  9  9  1  9  7  2  7  3  9  3  7  7  9 10  0\n",
      " 10  9  4  6  9  0  8  8  8  7  1  1 10  9 10  7  7  9  7  3  1  7  9  3\n",
      "  9  7  1  0  8  2  9  1 10  7  9  8  6  7  9 10  9  4  1  7 10  9  7  2\n",
      "  9  8 10  8  7  9  1  8 10  7  6  0 10 10  8  1  9  8  8  7 10  7  7  8\n",
      "  9  1  8  6  7 10  7 10  7  8 10  9  7  9  8 10  7  1  9  7 10 10  9 10\n",
      "  7  9  6  7 10  0  4  1  9  7  7  9  8  8  7 10  8  7  4  4  9  8  4  1\n",
      "  7  8 10 10  4  9  9  7  7 10  8  8  7  0  8  4  8  7 10 10]\n",
      "\n",
      "Column indices of location of features for the first trial in >sorted_values__amp_from_all_sensors< matrix \n",
      "\n",
      "[25  1 44 18 98 78 97 17  2 73 26 30 36  2 23 40 41 41 74 33 52  4  7 24\n",
      "  2 14 82 59  1 27 53 67 60  0 95 81 43 50 56 61 35 96  6 56 56  6 44 47\n",
      " 85 43 12 69 51 42 22 60 14 52 15 41 40 71 18 24  5 45 64 17 58 51 25 34\n",
      " 72  9 60 72 14 87 12 20  3 88 37 22 68  7 32 78 16 88 19 97 17 13 39 36\n",
      " 10 73 37 75 93 28 77 12 34 82 11 58  2 45 86 86 43 84 10 19 11 32 31 94\n",
      " 25 60 33 92 13 29  1 83 26 47 61  1 30 34 59 13 27 15 55 67 35 11 68 95\n",
      " 20  0 73  1 82 21  6 98 21 48 63 62 44 38 53 79 57 86  1 49 26 44 39 27\n",
      " 44  8 77 16  9 20 46 40 23 54 34 32 50 76 76 48  8 70 57 66 89 31 62 47\n",
      " 99 66 77 41 37 58 22 38  4 45 53  3 15 80 25 25 29 81 26  8 68 69 21 82\n",
      " 92 85 22 73 20 87 49 31  1 37 20 80 83 11 65 30 65 28 65 10 28 92 55 59\n",
      " 74 50 72 49 91 59 36 28 44 74  9 76 30 10 28 71 66 13 54 91 66 47 31  1\n",
      "  7 62 27  7 65 17 18 18 70 91  0  8 64  0 93 71 21 13 52  0  7  6 13 19\n",
      " 14 40 95 30 27 17 24  6  0 78 92  5 15 33 19 29 29 33 32 67 18 31 26 95\n",
      " 15 31 52 48 32 62  9 37 46 24 49 48 99 27 78 57 29 19 60  5 87 47 67 12\n",
      " 35 43 13 89 29 14 93 72 71 23 16 29 42 22  8 41 89 53 96 45 32  9 32 75\n",
      " 13 58  8 33 43 97  8 35 41 19 83 23 57 80 18 36 21 34 25 38 55 28 84 63\n",
      " 65 53 56 88 33 28 49 82 49 18  6 90 41  3 46 72 77  6 90 34 94 88 16 15\n",
      " 67 55 52 26 58 86 12 62 25  8 43 63  7  9 42 63 38 94  6 37 50 48 38 61\n",
      " 95 32 38 38 23 58 44 96 39  9 99  5 54 63 48 38 52 64 97 17 65 55  7 37\n",
      " 81 10 35  4 36 73  1 70 11 43 73 22 34 64 56 88 40 50  0 81 55  7 40 74\n",
      " 84 63 76 47 19 33 60 49 35  5 69 46 46 87 78 20 68 77 42 60]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "n_features_for_select_x=0\n",
    "for i in range(len(sorted_values_from_all_sensors)):\n",
    "    n_features_for_select_x=n_features_for_select_x+int(len(sorted_values__amp_from_all_sensors[i][0,:]))\n",
    "\n",
    "# Defining how much of features with biggest Pearson correllation coeff. will be selected.\n",
    "n_of_features_x= int(input(\"How many features out of %s you want to select (recommended is 500): \" % n_features_for_select_x))\n",
    "\n",
    "\n",
    "corr=list(range(trials))                    # Making list for correlation coefficients for all trials.\n",
    "p_value=list(range(trials))\n",
    "\n",
    "\n",
    "for j in range(trials):# Making sublists in \"corr\" for each sensor.\n",
    "    corr[j]=list(range(len(sorted_values_from_all_sensors)))\n",
    "    p_value[j]=list(range(len(sorted_values_from_all_sensors)))\n",
    "    for d in range(len(sorted_values_from_all_sensors)):        \n",
    "        corr[j][d]=list(range(round((N/100.0)*n_of_samples/2)))\n",
    "        p_value[j][d]=list(range(round((N/100.0)*n_of_samples/2)))\n",
    "\n",
    "\n",
    "# Calculating correlation coefficients for each column of each sensor with respect to target for all trials.\n",
    "for s in range(trials):\n",
    "    for k in range(len(sorted_values_from_all_sensors)):\n",
    "        for i in range(round((N/100.0)*n_of_samples/2)):\n",
    "            corr[s][k][i],p_value[s][k][i]=pearsonr(A[s][k][:,i],target_train_vector[0])\n",
    "            \n",
    "\n",
    "corr_array=list(range(trials)) # Transforming list of correlation coefficients to nparray\n",
    "for p in range(trials):\n",
    "    corr_array[p]=np.array(corr[p])   \n",
    "\n",
    "print(\"Array of correlation coefficients for one trial has size:\")\n",
    "print(\"                                                 \",corr_array[0].shape)  \n",
    "\n",
    "# sensor_n_x is the index of the sensor number.\n",
    "# feature_n_x is the index of the feature number for each sensor number.\n",
    "\n",
    "sensor_n_x=list(range(trials))\n",
    "feature_n_x=list(range(trials))\n",
    "for p in range(trials): \n",
    "    sensor_n_x[p], feature_n_x[p] = largest_indices(corr_array[p], n_of_features_x)\n",
    "\n",
    "print(\"Sensor indices of location of features for the first trial in >sorted_values__amp_from_all_sensors< matrix  \\n\")\n",
    "print(sensor_n_x[0])\n",
    "print(\"\\nColumn indices of location of features for the first trial in >sorted_values__amp_from_all_sensors< matrix \\n\")\n",
    "print(feature_n_x[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  43 or  8.60 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   8 or  1.60 %\n",
      "Number of features from sensor  5 is:   7 or  1.40 %\n",
      "Number of features from sensor  6 is:   8 or  1.60 %\n",
      "Number of features from sensor  7 is:  45 or  9.00 %\n",
      "Number of features from sensor  8 is:  47 or  9.40 %\n",
      "Number of features from sensor  9 is:  50 or  10.00 %\n",
      "Number of features from sensor 10 is:  48 or  9.60 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  43 or  8.60 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:  10 or  2.00 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  47 or  9.40 %\n",
      "Number of features from sensor  8 is:  44 or  8.80 %\n",
      "Number of features from sensor  9 is:  51 or  10.20 %\n",
      "Number of features from sensor 10 is:  46 or  9.20 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  40 or  8.00 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:  10 or  2.00 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  46 or  9.20 %\n",
      "Number of features from sensor  8 is:  45 or  9.00 %\n",
      "Number of features from sensor  9 is:  52 or  10.40 %\n",
      "Number of features from sensor 10 is:  48 or  9.60 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  42 or  8.40 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   7 or  1.40 %\n",
      "Number of features from sensor  5 is:   7 or  1.40 %\n",
      "Number of features from sensor  6 is:   6 or  1.20 %\n",
      "Number of features from sensor  7 is:  47 or  9.40 %\n",
      "Number of features from sensor  8 is:  48 or  9.60 %\n",
      "Number of features from sensor  9 is:  51 or  10.20 %\n",
      "Number of features from sensor 10 is:  48 or  9.60 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  43 or  8.60 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:  11 or  2.20 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   6 or  1.20 %\n",
      "Number of features from sensor  7 is:  44 or  8.80 %\n",
      "Number of features from sensor  8 is:  48 or  9.60 %\n",
      "Number of features from sensor  9 is:  51 or  10.20 %\n",
      "Number of features from sensor 10 is:  47 or  9.40 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  43 or  8.60 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   9 or  1.80 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   9 or  1.80 %\n",
      "Number of features from sensor  7 is:  44 or  8.80 %\n",
      "Number of features from sensor  8 is:  45 or  9.00 %\n",
      "Number of features from sensor  9 is:  50 or  10.00 %\n",
      "Number of features from sensor 10 is:  48 or  9.60 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  44 or  8.80 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:  11 or  2.20 %\n",
      "Number of features from sensor  5 is:   7 or  1.40 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  46 or  9.20 %\n",
      "Number of features from sensor  8 is:  45 or  9.00 %\n",
      "Number of features from sensor  9 is:  51 or  10.20 %\n",
      "Number of features from sensor 10 is:  45 or  9.00 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  40 or  8.00 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   9 or  1.80 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  47 or  9.40 %\n",
      "Number of features from sensor  8 is:  45 or  9.00 %\n",
      "Number of features from sensor  9 is:  51 or  10.20 %\n",
      "Number of features from sensor 10 is:  49 or  9.80 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  42 or  8.40 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   8 or  1.60 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  47 or  9.40 %\n",
      "Number of features from sensor  8 is:  44 or  8.80 %\n",
      "Number of features from sensor  9 is:  52 or  10.40 %\n",
      "Number of features from sensor 10 is:  46 or  9.20 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  81 or  16.20 %\n",
      "Number of features from sensor  1 is:  43 or  8.60 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   8 or  1.60 %\n",
      "Number of features from sensor  5 is:   7 or  1.40 %\n",
      "Number of features from sensor  6 is:   8 or  1.60 %\n",
      "Number of features from sensor  7 is:  47 or  9.40 %\n",
      "Number of features from sensor  8 is:  43 or  8.60 %\n",
      "Number of features from sensor  9 is:  51 or  10.20 %\n",
      "Number of features from sensor 10 is:  50 or  10.00 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  40 or  8.00 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   8 or  1.60 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   6 or  1.20 %\n",
      "Number of features from sensor  7 is:  49 or  9.80 %\n",
      "Number of features from sensor  8 is:  45 or  9.00 %\n",
      "Number of features from sensor  9 is:  49 or  9.80 %\n",
      "Number of features from sensor 10 is:  49 or  9.80 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  40 or  8.00 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   8 or  1.60 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   8 or  1.60 %\n",
      "Number of features from sensor  7 is:  49 or  9.80 %\n",
      "Number of features from sensor  8 is:  42 or  8.40 %\n",
      "Number of features from sensor  9 is:  52 or  10.40 %\n",
      "Number of features from sensor 10 is:  49 or  9.80 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  42 or  8.40 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:  11 or  2.20 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  45 or  9.00 %\n",
      "Number of features from sensor  8 is:  44 or  8.80 %\n",
      "Number of features from sensor  9 is:  51 or  10.20 %\n",
      "Number of features from sensor 10 is:  48 or  9.60 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  81 or  16.20 %\n",
      "Number of features from sensor  1 is:  40 or  8.00 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   9 or  1.80 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   8 or  1.60 %\n",
      "Number of features from sensor  7 is:  46 or  9.20 %\n",
      "Number of features from sensor  8 is:  46 or  9.20 %\n",
      "Number of features from sensor  9 is:  49 or  9.80 %\n",
      "Number of features from sensor 10 is:  51 or  10.20 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  81 or  16.20 %\n",
      "Number of features from sensor  1 is:  41 or  8.20 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   9 or  1.80 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   8 or  1.60 %\n",
      "Number of features from sensor  7 is:  45 or  9.00 %\n",
      "Number of features from sensor  8 is:  42 or  8.40 %\n",
      "Number of features from sensor  9 is:  52 or  10.40 %\n",
      "Number of features from sensor 10 is:  52 or  10.40 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  41 or  8.20 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   9 or  1.80 %\n",
      "Number of features from sensor  5 is:   7 or  1.40 %\n",
      "Number of features from sensor  6 is:   8 or  1.60 %\n",
      "Number of features from sensor  7 is:  46 or  9.20 %\n",
      "Number of features from sensor  8 is:  45 or  9.00 %\n",
      "Number of features from sensor  9 is:  52 or  10.40 %\n",
      "Number of features from sensor 10 is:  48 or  9.60 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  42 or  8.40 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   9 or  1.80 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  49 or  9.80 %\n",
      "Number of features from sensor  8 is:  42 or  8.40 %\n",
      "Number of features from sensor  9 is:  50 or  10.00 %\n",
      "Number of features from sensor 10 is:  49 or  9.80 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  43 or  8.60 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   8 or  1.60 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  47 or  9.40 %\n",
      "Number of features from sensor  8 is:  48 or  9.60 %\n",
      "Number of features from sensor  9 is:  51 or  10.20 %\n",
      "Number of features from sensor 10 is:  46 or  9.20 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  43 or  8.60 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   9 or  1.80 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   6 or  1.20 %\n",
      "Number of features from sensor  7 is:  48 or  9.60 %\n",
      "Number of features from sensor  8 is:  43 or  8.60 %\n",
      "Number of features from sensor  9 is:  49 or  9.80 %\n",
      "Number of features from sensor 10 is:  50 or  10.00 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  44 or  8.80 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   7 or  1.40 %\n",
      "Number of features from sensor  5 is:   7 or  1.40 %\n",
      "Number of features from sensor  6 is:   8 or  1.60 %\n",
      "Number of features from sensor  7 is:  47 or  9.40 %\n",
      "Number of features from sensor  8 is:  46 or  9.20 %\n",
      "Number of features from sensor  9 is:  50 or  10.00 %\n",
      "Number of features from sensor 10 is:  47 or  9.40 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  42 or  8.40 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   9 or  1.80 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   6 or  1.20 %\n",
      "Number of features from sensor  7 is:  48 or  9.60 %\n",
      "Number of features from sensor  8 is:  45 or  9.00 %\n",
      "Number of features from sensor  9 is:  54 or  10.80 %\n",
      "Number of features from sensor 10 is:  44 or  8.80 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  42 or  8.40 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:  10 or  2.00 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   6 or  1.20 %\n",
      "Number of features from sensor  7 is:  44 or  8.80 %\n",
      "Number of features from sensor  8 is:  43 or  8.60 %\n",
      "Number of features from sensor  9 is:  51 or  10.20 %\n",
      "Number of features from sensor 10 is:  52 or  10.40 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  40 or  8.00 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   8 or  1.60 %\n",
      "Number of features from sensor  5 is:   7 or  1.40 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  49 or  9.80 %\n",
      "Number of features from sensor  8 is:  47 or  9.40 %\n",
      "Number of features from sensor  9 is:  49 or  9.80 %\n",
      "Number of features from sensor 10 is:  49 or  9.80 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  41 or  8.20 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   8 or  1.60 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   6 or  1.20 %\n",
      "Number of features from sensor  7 is:  47 or  9.40 %\n",
      "Number of features from sensor  8 is:  48 or  9.60 %\n",
      "Number of features from sensor  9 is:  54 or  10.80 %\n",
      "Number of features from sensor 10 is:  44 or  8.80 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  41 or  8.20 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   7 or  1.40 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   6 or  1.20 %\n",
      "Number of features from sensor  7 is:  44 or  8.80 %\n",
      "Number of features from sensor  8 is:  45 or  9.00 %\n",
      "Number of features from sensor  9 is:  52 or  10.40 %\n",
      "Number of features from sensor 10 is:  51 or  10.20 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  44 or  8.80 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   8 or  1.60 %\n",
      "Number of features from sensor  5 is:   7 or  1.40 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  49 or  9.80 %\n",
      "Number of features from sensor  8 is:  42 or  8.40 %\n",
      "Number of features from sensor  9 is:  52 or  10.40 %\n",
      "Number of features from sensor 10 is:  47 or  9.40 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  42 or  8.40 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   7 or  1.40 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  49 or  9.80 %\n",
      "Number of features from sensor  8 is:  46 or  9.20 %\n",
      "Number of features from sensor  9 is:  51 or  10.20 %\n",
      "Number of features from sensor 10 is:  46 or  9.20 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  42 or  8.40 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:  10 or  2.00 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  49 or  9.80 %\n",
      "Number of features from sensor  8 is:  42 or  8.40 %\n",
      "Number of features from sensor  9 is:  51 or  10.20 %\n",
      "Number of features from sensor 10 is:  45 or  9.00 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  41 or  8.20 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   9 or  1.80 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   8 or  1.60 %\n",
      "Number of features from sensor  7 is:  49 or  9.80 %\n",
      "Number of features from sensor  8 is:  45 or  9.00 %\n",
      "Number of features from sensor  9 is:  50 or  10.00 %\n",
      "Number of features from sensor 10 is:  46 or  9.20 %\n",
      "----------------------------------------------------\n",
      "                                             100.00\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  40 or  8.00 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:  10 or  2.00 %\n",
      "Number of features from sensor  5 is:   7 or  1.40 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  44 or  8.80 %\n",
      "Number of features from sensor  8 is:  47 or  9.40 %\n",
      "Number of features from sensor  9 is:  50 or  10.00 %\n",
      "Number of features from sensor 10 is:  51 or  10.20 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  45 or  9.00 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   8 or  1.60 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   5 or  1.00 %\n",
      "Number of features from sensor  7 is:  46 or  9.20 %\n",
      "Number of features from sensor  8 is:  44 or  8.80 %\n",
      "Number of features from sensor  9 is:  49 or  9.80 %\n",
      "Number of features from sensor 10 is:  51 or  10.20 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  39 or  7.80 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:  11 or  2.20 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  46 or  9.20 %\n",
      "Number of features from sensor  8 is:  47 or  9.40 %\n",
      "Number of features from sensor  9 is:  49 or  9.80 %\n",
      "Number of features from sensor 10 is:  49 or  9.80 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  41 or  8.20 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:  10 or  2.00 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  44 or  8.80 %\n",
      "Number of features from sensor  8 is:  48 or  9.60 %\n",
      "Number of features from sensor  9 is:  51 or  10.20 %\n",
      "Number of features from sensor 10 is:  47 or  9.40 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  41 or  8.20 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   9 or  1.80 %\n",
      "Number of features from sensor  5 is:   7 or  1.40 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  46 or  9.20 %\n",
      "Number of features from sensor  8 is:  48 or  9.60 %\n",
      "Number of features from sensor  9 is:  49 or  9.80 %\n",
      "Number of features from sensor 10 is:  49 or  9.80 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  40 or  8.00 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   8 or  1.60 %\n",
      "Number of features from sensor  5 is:   7 or  1.40 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  50 or  10.00 %\n",
      "Number of features from sensor  8 is:  47 or  9.40 %\n",
      "Number of features from sensor  9 is:  51 or  10.20 %\n",
      "Number of features from sensor 10 is:  46 or  9.20 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  42 or  8.40 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   7 or  1.40 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   8 or  1.60 %\n",
      "Number of features from sensor  7 is:  46 or  9.20 %\n",
      "Number of features from sensor  8 is:  47 or  9.40 %\n",
      "Number of features from sensor  9 is:  50 or  10.00 %\n",
      "Number of features from sensor 10 is:  48 or  9.60 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  45 or  9.00 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:  10 or  2.00 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   6 or  1.20 %\n",
      "Number of features from sensor  7 is:  50 or  10.00 %\n",
      "Number of features from sensor  8 is:  45 or  9.00 %\n",
      "Number of features from sensor  9 is:  50 or  10.00 %\n",
      "Number of features from sensor 10 is:  42 or  8.40 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  42 or  8.40 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   7 or  1.40 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  46 or  9.20 %\n",
      "Number of features from sensor  8 is:  47 or  9.40 %\n",
      "Number of features from sensor  9 is:  51 or  10.20 %\n",
      "Number of features from sensor 10 is:  48 or  9.60 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  44 or  8.80 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:  10 or  2.00 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   8 or  1.60 %\n",
      "Number of features from sensor  7 is:  47 or  9.40 %\n",
      "Number of features from sensor  8 is:  46 or  9.20 %\n",
      "Number of features from sensor  9 is:  47 or  9.40 %\n",
      "Number of features from sensor 10 is:  47 or  9.40 %\n",
      "----------------------------------------------------\n",
      "                                             100.00\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  81 or  16.20 %\n",
      "Number of features from sensor  1 is:  40 or  8.00 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   9 or  1.80 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  51 or  10.20 %\n",
      "Number of features from sensor  8 is:  49 or  9.80 %\n",
      "Number of features from sensor  9 is:  48 or  9.60 %\n",
      "Number of features from sensor 10 is:  45 or  9.00 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  41 or  8.20 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  79 or  15.80 %\n",
      "Number of features from sensor  4 is:   8 or  1.60 %\n",
      "Number of features from sensor  5 is:   7 or  1.40 %\n",
      "Number of features from sensor  6 is:   5 or  1.00 %\n",
      "Number of features from sensor  7 is:  51 or  10.20 %\n",
      "Number of features from sensor  8 is:  45 or  9.00 %\n",
      "Number of features from sensor  9 is:  50 or  10.00 %\n",
      "Number of features from sensor 10 is:  48 or  9.60 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  42 or  8.40 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   7 or  1.40 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  47 or  9.40 %\n",
      "Number of features from sensor  8 is:  45 or  9.00 %\n",
      "Number of features from sensor  9 is:  51 or  10.20 %\n",
      "Number of features from sensor 10 is:  48 or  9.60 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  43 or  8.60 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:  11 or  2.20 %\n",
      "Number of features from sensor  5 is:   7 or  1.40 %\n",
      "Number of features from sensor  6 is:   9 or  1.80 %\n",
      "Number of features from sensor  7 is:  42 or  8.40 %\n",
      "Number of features from sensor  8 is:  44 or  8.80 %\n",
      "Number of features from sensor  9 is:  51 or  10.20 %\n",
      "Number of features from sensor 10 is:  49 or  9.80 %\n",
      "----------------------------------------------------\n",
      "                                             100.00\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  42 or  8.40 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:  12 or  2.40 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  45 or  9.00 %\n",
      "Number of features from sensor  8 is:  41 or  8.20 %\n",
      "Number of features from sensor  9 is:  52 or  10.40 %\n",
      "Number of features from sensor 10 is:  49 or  9.80 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  81 or  16.20 %\n",
      "Number of features from sensor  1 is:  43 or  8.60 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  79 or  15.80 %\n",
      "Number of features from sensor  4 is:   8 or  1.60 %\n",
      "Number of features from sensor  5 is:   7 or  1.40 %\n",
      "Number of features from sensor  6 is:  10 or  2.00 %\n",
      "Number of features from sensor  7 is:  47 or  9.40 %\n",
      "Number of features from sensor  8 is:  42 or  8.40 %\n",
      "Number of features from sensor  9 is:  51 or  10.20 %\n",
      "Number of features from sensor 10 is:  48 or  9.60 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  41 or  8.20 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   7 or  1.40 %\n",
      "Number of features from sensor  5 is:   7 or  1.40 %\n",
      "Number of features from sensor  6 is:   8 or  1.60 %\n",
      "Number of features from sensor  7 is:  43 or  8.60 %\n",
      "Number of features from sensor  8 is:  49 or  9.80 %\n",
      "Number of features from sensor  9 is:  52 or  10.40 %\n",
      "Number of features from sensor 10 is:  49 or  9.80 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  42 or  8.40 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:  10 or  2.00 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  46 or  9.20 %\n",
      "Number of features from sensor  8 is:  45 or  9.00 %\n",
      "Number of features from sensor  9 is:  50 or  10.00 %\n",
      "Number of features from sensor 10 is:  48 or  9.60 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  81 or  16.20 %\n",
      "Number of features from sensor  1 is:  43 or  8.60 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:  10 or  2.00 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   6 or  1.20 %\n",
      "Number of features from sensor  7 is:  45 or  9.00 %\n",
      "Number of features from sensor  8 is:  46 or  9.20 %\n",
      "Number of features from sensor  9 is:  54 or  10.80 %\n",
      "Number of features from sensor 10 is:  45 or  9.00 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  42 or  8.40 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   8 or  1.60 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   8 or  1.60 %\n",
      "Number of features from sensor  7 is:  50 or  10.00 %\n",
      "Number of features from sensor  8 is:  43 or  8.60 %\n",
      "Number of features from sensor  9 is:  52 or  10.40 %\n",
      "Number of features from sensor 10 is:  44 or  8.80 %\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  42 or  8.40 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:  10 or  2.00 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   6 or  1.20 %\n",
      "Number of features from sensor  7 is:  49 or  9.80 %\n",
      "Number of features from sensor  8 is:  48 or  9.60 %\n",
      "Number of features from sensor  9 is:  50 or  10.00 %\n",
      "Number of features from sensor 10 is:  43 or  8.60 %\n",
      "----------------------------------------------------\n",
      "                                             100.00\n"
     ]
    }
   ],
   "source": [
    "#\"Pearson correlation through Monte Carlo trials:\n",
    "\n",
    "# Initialising a list of best features. 11 sublists containing features from each sensor, respectively.\n",
    "\n",
    "top_n_features_x=list(range(trials))\n",
    "percentage_x=list(range(trials))\n",
    "k=list(range(trials))\n",
    "top_n_together_x=list(range(trials))\n",
    "top_n_together_x_matrix=list(range(trials))\n",
    "abs_top_n_together_matrix_x=list(range(trials))\n",
    "print(\"Pearson correlation through Monte Carlo trials:\")\n",
    "for d in range(trials):\n",
    "    top_n_features_x[d]=[[], [], [], [], [], [], [], [], [], [], []]\n",
    "    for i in range(len(sensor)):\n",
    "        for j in range(len(sensor_n_x[d])):\n",
    "            if sensor_n_x[d][j]==i:\n",
    "                top_n_features_x[d][i].append(sorted_values__amp_from_all_sensors[i][:,feature_n_x[d][j]]);\n",
    "\n",
    "    for i in range(len(sensor)):\n",
    "        for j in range(len(top_n_features_x[d][i])):\n",
    "            top_n_features_x[d][i][j]=list(top_n_features_x[d][i][j])\n",
    "\n",
    "    # Merging sublists into one list with all elements.\n",
    "    top_n_together_x[d]=[j for i in top_n_features_x[d] for j in i]  \n",
    "\n",
    "    top_n_together_x_matrix[d]=np.transpose(pd.DataFrame(top_n_together_x[d]))\n",
    "    print(type(top_n_together_x_matrix[0]), \"\\n\")\n",
    "\n",
    "    # Continue working with abosulte values.\n",
    "    abs_top_n_together_matrix_x[d]=top_n_together_x_matrix[d]\n",
    "\n",
    "\n",
    "    percentage_x[d]=list(range(len(sensor)))\n",
    "    k[d]=0\n",
    "    for i in range(len(sensor)):\n",
    "        #print(top_n_features_matrix.shape)\n",
    "        print(\"Number of features from sensor %2.0f is: %3.0f or  %4.2f %%\" % (i, len(top_n_features_x[d][i]), len(top_n_features_x[d][i])/len(sensor_n_x[d])*100))\n",
    "        percentage_x[d][i]=len(top_n_features_x[d][i])\n",
    "        k[d]=k[d]+len(top_n_features_x[d][i])/len(sensor_n_x[d])*100\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"                                             %4.2f\" % (k[d]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array of correlation coefficients has size:\n",
      "                                                  (11, 100)\n",
      "Covariance matrix of correlation coefficients for has size:\n",
      "                                                  (11, 11)\n",
      "Sensor indices of location of features for the mean value of Monte Carlo method >sorted_values__amp_from_all_sensors< matrix  \n",
      "\n",
      "[ 2  0 10  0  2  0  2  2  9  3  3  3  9  3  3  3 10  2  2  2  0  3  3  3\n",
      "  8  0  7  1  3  0  0  1  8  0  7  0  2  3  0  0  3  2  0  3  2 10  0  3\n",
      "  0  2  2  2  2  2  3  0  2  2  0  3  2  3 10  0  3  0  3  9  3  3  3  2\n",
      "  0  3  0  2  8  3  3  3  2  0  3  3  3  3  2  2  3  3  3  3  3  0  3  0\n",
      "  3  0  2  3  0  3  3  3  2 10  3  3  0  5  0 10  2  2  2  8  2  2  2  2\n",
      "  3  0  2  2  2  2  5  2  9  2 10  2  2  0  2  3  0  0  2  0  2  2  0  0\n",
      "  8  2  2  3  0  9  3  2  3  0  2  2  2  2  2  2  0  2  2  2  2  0  0  2\n",
      "  3  2  7  3  0  2  2  2  1  0  0  0  2  2  0  0  2  0  0  2  2  2  1  2\n",
      "  0  0  2  0  0  3  0  3  3  3  3  2  5  8  3  1  3  0  9  3 10  0  9  0\n",
      "  1  8  0  3  3  3  1 10  0 10  7  1  7  0  3  0  2  0 10  0  8  0  0  1\n",
      "  0  3  0  2  1  3  2  3  9  0 10  5  1  7  9  1  9  3  3  5  1  3  6  1\n",
      "  4  0  0  7  1  8  9 10  9  0  2  1  3  9 10  2  3  0  0 10  7  8  2  9\n",
      "  8  9  3  8  8  0  9  7  7  5  1  1  0  9  1 10  7  8  0 10  1  9  1 10\n",
      "  9  8  8  9  1  1  3  3  7  4  2  2 10 10  1  3  0  7  1  9  9  0  1  2\n",
      "  1  8  8  1  1  2  7 10  2  3  3  1  8  9  9  4 10  7  9  9  8  8  9  1\n",
      "  0  1  7  7  9  3  0  7  9  7  8  8  7  6  7  7 10  9  9  9  7  7  7  2\n",
      "  0  3  7  1  4  6  1  1  9  9  9  9  1 10  7  9 10 10  2 10  9  7  9  7\n",
      "  7  9  1  8  7  8  7 10  9  1  7  8  1  9  6 10  9  7  9 10  8 10  7  8\n",
      "  8 10  9 10 10  7  9  8 10  6  7  0  0 10  7  7  8  8  8 10  8  7  0  4\n",
      "  7 10  7  9  8  1  9  9  1  8  8 10  4  9  7  7 10  9 10  6  7  5  8  8\n",
      " 10  8  8 10  8  7  5  6  1 10  9  8 10 10  4  8  8 10 10  7]\n",
      "\n",
      "Column indices of location of features for the mean value of Monte Carlo method >sorted_values__amp_from_all_sensors< matrix \n",
      "\n",
      "[25  1 44 18 98 78 97 17 73  2 26 36  2 30 23 40 41 74 41 33 52  4 24  7\n",
      " 82 59 14  2  1 53 67  0 60 95 27 61 81 56 50 96 43 35 56  6 56  6 44 47\n",
      " 43 85 69 12 51 42 60 14 22 52 40 15 71 18 24 41  5 45 72 17 25 64 58 34\n",
      " 51  9 60 72 37 14 87 12 88  3 20 78 22 88 68  7 16 97 32 19 17 36 13 39\n",
      " 10 37 75 28 93 86 73 77 82 34 45 11 58 12 86  2 10 43 84 11 19 32 31 94\n",
      " 33 25 92 60 29 83 13 61  1 26  1 30 13 47 59 34 27 11 67 35 55 95 15  0\n",
      "  1 20 73 68 21 44 82 21 98  6 48 63 62 38 53 79 57 86 49 27 39 26  9 44\n",
      " 44 77  1  8 20 40 46 54 16 23 34 32 50 76 76  8 57 31 48 70 66 89  4 47\n",
      " 66 77 58 99 22 53 38 37 80 41 62 45  8 25  3 15 29 81 25 69 26 82 21 68\n",
      " 20 20 85 31 92 49 37 73 80 22 10  1 11 65 65 83 65 28 87 30 28 92 49 50\n",
      " 55 59 72 36 59 76 91 74 28 74 30 10 44  9 66 13 71 54 66  7 31 27  1 28\n",
      "  7 91 62 13 65 17 47 91 18 70 18  8 52  0  0 93 21 71 64 19  7  0  6 13\n",
      " 24 40 95 30 14 17 92  0  6  5 78 27 19 29 48 15 67 32 33 33 47 31 52 29\n",
      " 26 31 95 32 18 43 46 89 15  9 78 24 35 27 49 48 29 62 60 37 12 89 93 87\n",
      " 99 29 13 67 57 14  5 32  8 96 71 29 35 23 80  8 13 22  9 42 19  8 16 72\n",
      " 97 56 19 21 49 38 75 45 53 32 33 41 28 33 36  3 18 34 58  6 25 18 34 28\n",
      " 88 63 23 82  6 41 90 23 43 84 65 46 55 57 41 77 49 25 15  9 97 37  7 53\n",
      " 17 55 70 26  8 90 81  7 60 32 58 62 83 86 43 52 95 39 38 36 43 55 44 55\n",
      " 45 47 22 37 71 16  5 40 94 35 69 73 87 65 46 49  6  7 61 50 68 43 63  1\n",
      " 48 99 38 63  9 12 10 88 61 46 94 88  0 67 52 56 96 33 58 38 70  6 59 63\n",
      "  5 54 73 54 81 50  4 40 63 76 11 34 42 86 19 96 42 63 77 35]\n"
     ]
    }
   ],
   "source": [
    "#mean value\n",
    "\n",
    "corr_array_mean=np.mean(corr,axis=0) \n",
    "\n",
    "\n",
    "sum2=0\n",
    "for s in range(trials):\n",
    "    sum2=sum2+np.dot((corr_array_mean-corr_array[s]),(corr_array_mean[p]-corr_array[s]).T)\n",
    "Uy=(1/(trials-1))*sum2\n",
    "\n",
    " # Transforming list of correlation coefficients to nparray\n",
    "  \n",
    "\n",
    "print(\"Array of correlation coefficients has size:\")\n",
    "print(\"                                                 \",corr_array_mean.shape)  \n",
    "print(\"Covariance matrix of correlation coefficients for has size:\")\n",
    "print(\"                                                 \",Uy.shape)  \n",
    "\n",
    "# sensor_n_m is the index of the sensor number.\n",
    "# feature_n_m is the index of the feature number for each sensor number.\n",
    "\n",
    "sensor_n_m, feature_n_m = largest_indices(corr_array_mean, n_of_features_x)\n",
    "print(\"Sensor indices of location of features for the mean value of Monte Carlo method >sorted_values__amp_from_all_sensors< matrix  \\n\")\n",
    "print(sensor_n_m)\n",
    "print(\"\\nColumn indices of location of features for the mean value of Monte Carlo method >sorted_values__amp_from_all_sensors< matrix \\n\")\n",
    "print(feature_n_m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariances of best estimates (mean values) for all sensors are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.012090</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>-0.000479</td>\n",
       "      <td>-0.000407</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>-0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000048</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.003129</td>\n",
       "      <td>-0.000363</td>\n",
       "      <td>-0.000391</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>-0.000383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000225</td>\n",
       "      <td>-0.000479</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-0.000363</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>-0.001122</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>-0.000872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000407</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>-0.000391</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.012878</td>\n",
       "      <td>-0.000371</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>-0.000371</td>\n",
       "      <td>0.015450</td>\n",
       "      <td>-0.000558</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>-0.000708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.001122</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.000558</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.011142</td>\n",
       "      <td>0.000213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.000287</td>\n",
       "      <td>-0.000633</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>-0.000383</td>\n",
       "      <td>-0.000872</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>-0.000708</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.011190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   0.002013  0.000116  0.000040 -0.000091 -0.000048  0.000225 -0.000037   \n",
       "1   0.000116  0.012090 -0.000008 -0.000221  0.000447 -0.000479 -0.000407   \n",
       "2   0.000040 -0.000008  0.000208 -0.000045 -0.000024  0.000069 -0.000049   \n",
       "3  -0.000091 -0.000221 -0.000045  0.003763  0.000330 -0.000350 -0.000208   \n",
       "4  -0.000048  0.000447 -0.000024  0.000330  0.003129 -0.000363 -0.000391   \n",
       "5   0.000225 -0.000479  0.000069 -0.000350 -0.000363  0.017715  0.000482   \n",
       "6  -0.000037 -0.000407 -0.000049 -0.000208 -0.000391  0.000482  0.012878   \n",
       "7   0.000216  0.000237  0.000023  0.000039 -0.000007 -0.000302 -0.000371   \n",
       "8  -0.000012  0.000150 -0.000027  0.000098  0.000007 -0.001122 -0.000036   \n",
       "9   0.000341  0.000012 -0.000022  0.000068 -0.000300 -0.000265  0.000112   \n",
       "10 -0.000287 -0.000633 -0.000011 -0.000173 -0.000383 -0.000872  0.000058   \n",
       "\n",
       "           7         8         9        10  \n",
       "0   0.000216 -0.000012  0.000341 -0.000287  \n",
       "1   0.000237  0.000150  0.000012 -0.000633  \n",
       "2   0.000023 -0.000027 -0.000022 -0.000011  \n",
       "3   0.000039  0.000098  0.000068 -0.000173  \n",
       "4  -0.000007  0.000007 -0.000300 -0.000383  \n",
       "5  -0.000302 -0.001122 -0.000265 -0.000872  \n",
       "6  -0.000371 -0.000036  0.000112  0.000058  \n",
       "7   0.015450 -0.000558  0.000303 -0.000708  \n",
       "8  -0.000558  0.011143  0.000299  0.000771  \n",
       "9   0.000303  0.000299  0.011142  0.000213  \n",
       "10 -0.000708  0.000771  0.000213  0.011190  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Uy=pd.DataFrame(Uy)\n",
    "Uy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe5e17e8bab435d83f15d416234cb39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='num_of_sensors', max=10), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.MC_correlation_mean_value(num_of_sensors)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "def MC_correlation_mean_value(num_of_sensors):\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.errorbar(range(sorted_values__amp_from_all_sensors[0].shape[1]),corr_array_mean[num_of_sensors],fmt=\"o-\")\n",
    "    plt.xlabel('Column indices - Amplitudes')\n",
    "    plt.ylabel('Correlation coefficient')\n",
    "    plt.title('Mean values of correlation coefficients for all sensors')\n",
    "interact(MC_correlation_mean_value,num_of_sensors=widgets.IntSlider(min=0, max=10, step=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representation of sensors in percentages for each tral has been given  in the list percentage_x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  41 or  8.20 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   8 or  1.60 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  49 or  9.80 %\n",
      "Number of features from sensor  8 is:  42 or  8.40 %\n",
      "Number of features from sensor  9 is:  52 or  10.40 %\n",
      "Number of features from sensor 10 is:  49 or  9.80 %\n",
      "----------------------------------------------------\n",
      "                                             100.00\n"
     ]
    }
   ],
   "source": [
    "# Initialising a list of best features. 11 sublists containing features from each sensor, respectively.\n",
    "top_n_features=[[], [], [], [], [], [], [], [], [], [], []]\n",
    "for i in range(len(sensor)):\n",
    "    for j in range(len(sensor_n_m)):\n",
    "        if sensor_n_m[j]==i:\n",
    "            top_n_features[i].append(sorted_values_from_all_sensors[i][:,feature_n_m[j]]);\n",
    "\n",
    "for i in range(len(sensor)):\n",
    "    for j in range(len(top_n_features[i])):\n",
    "        top_n_features[i][j]=list(top_n_features[i][j])\n",
    "\n",
    "# Merging sublists into one list with all elements.\n",
    "top_n_together=[j for i in top_n_features for j in i]  \n",
    "\n",
    "top_n_together_matrix=np.transpose(pd.DataFrame(top_n_together))\n",
    "print(type(top_n_together_matrix), \"\\n\")\n",
    "\n",
    "# Continue working with abosulte values.\n",
    "abs_top_n_together_matrix=np.abs(top_n_together_matrix)\n",
    "\n",
    "percentage=list(range(11))\n",
    "k=0\n",
    "for i in range(len(sensor)):\n",
    "    #print(top_n_features_matrix.shape)\n",
    "    print(\"Number of features from sensor %2.0f is: %3.0f or  %4.2f %%\" % (i, len(top_n_features[i]), len(top_n_features[i])/len(sensor_n)*100))\n",
    "    percentage[i]=len(top_n_features[i])\n",
    "    k=k+len(top_n_features[i])/len(sensor_n)*100\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"                                             %4.2f\" % (k))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows comparison of frequency of occurrences for the sensors of features with highest correlation coefficients in case of methods: Pearson correlation (amplitudes only) and Pearson correlation results performed for the specific number of Monte Carlo trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2062ad05f0d14e5c893a0498c0f9ad26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='trials', max=99), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.MC_plot(trials)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "def MC_plot(trials):\n",
    "    bins = len(sensor)\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.hist(sensor_n, bins, alpha=0.5, label='Pearson_corr - amplitudes only')\n",
    "    plt.xlabel(\"Sensor (0-10)\")\n",
    "    plt.ylabel(\"Frequency\") \n",
    "    plt.title(\"Frequency of sensor indices of features with biggest correlation \")\n",
    "    plt.hist(sensor_n_x[trials], bins, alpha=0.5, label='Monte Carlo: Pearson_corr')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "interact(MC_plot,trials=widgets.IntSlider(min=0, max=99, step=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows comparison of frequency of occurrences for the features with highest correlation coefficients in case of methods: Pearson correlation (amplitudes only) and Pearson correlation results performed for the specific number of Monte Carlo trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39c02b8f43b4fd0a2039867aa3aa83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='runs', max=99), Output()), _dom_classes=('widget-interac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.MC_plot1(runs)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "def MC_plot1(runs):\n",
    "    bins = sorted_values__amp_from_all_sensors[0].shape[1]\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.hist(feature_n, bins, alpha=0.5, label='Pearson_corr amplitudes only')\n",
    "    plt.xlabel(\"Columns (1-100)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.hist(feature_n_x[runs], bins, alpha=0.5, label='Monte Carlo: Pearson_corr')\n",
    "    plt.title(\"Frequency of column indices of features with biggest correlation for all sensors\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "interact(MC_plot1,runs=widgets.IntSlider(min=0, max=99, step=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Weighted correlation\n",
    "\n",
    "A weighted correlation allows application of a weight, or relative significance to each value comparison. Correlation comparisons with a higher value for their weight are considered as more significant when compared to the other value comparisons. Weighted correlation requires following arguments:\n",
    "\n",
    "- x and y are - values being compared.\n",
    "- w is the weight applied to each comparison. With these arguments, it is possible to calculate:\n",
    "\n",
    "weighted mean:\n",
    "$$m(x;w)=\\frac {\\sum_{i}w_i*x_i}{\\sum_{i}w_i}$$ \n",
    "weighted covariance:\n",
    "$$cov(x,y;w)=\\frac {\\sum _{i}w_i(x_i-m(x;w))(y_i-m(y;w))}{\\sum _{i}w_i} $$\n",
    "weighted correlation:\n",
    "$$corr(x,y;w)=\\frac{cov(x,y;w)}{\\sqrt{cov(x,x;w)*cov(y,y;w))}}$$\n",
    "\n",
    "After application of MC method, estimates of amplitudes are correlated with target vector, and correlation is weighted with weight factor:\n",
    "$$ w_i= \\frac {1}{u²(\\hat{y_i})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted correlation was performed on data obtained from DFT. Correlation of amplitudes and train_vector has been weighted by uncertainties of amplitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating weights from diagonal elements of uncertainty matrix\n",
    "# W -list of eleven np.arrays sized (number of cycles, N% of amplitudes) containing weight factors\n",
    "W=[0]*len(sorted_values__amp_from_all_sensors)\n",
    "B=np.zeros((sorted_values__amp_from_all_sensors[0].shape))\n",
    "for k in range(len(sorted_values__amp_from_all_sensors)):\n",
    "    for i in range (sorted_values__amp_from_all_sensors[0].shape[0]):\n",
    "        B[i]=1/((sorted_uncer_from_all_sensors_a[k][i,:])) #elements in u_a already squared\n",
    "    W[k]=B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weighted mean\n",
    "def m(x, w):\n",
    "    \"\"\"Weighted Mean\"\"\"\n",
    "    return np.sum(x * w) / np.sum(w)\n",
    "#weighted covariance\n",
    "def cov(x, y, w):\n",
    "    \"\"\"Weighted Covariance\"\"\"\n",
    "    return np.sum(w * (x - m(x, w)) * (y - m(y, w))) / np.sum(w)\n",
    "#weighted correlation\n",
    "def corr(x, y, w):\n",
    "    \"\"\"Weighted Correlation\"\"\"\n",
    "    return cov(x, y, w) / np.sqrt(cov(x, x, w) * cov(y, y, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing functions m, cov and corr for the largest correlation coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many features out of 1100 you want to select (recommended is 500): 500\n",
      "\n",
      "Dimension of target matrix is:\n",
      "                                                  (5347, 1)\n",
      "Dimension of amplitude matrix for one sensor is:\n",
      "                                                  (5347, 100)\n",
      "Array of weighted correlation coefficients has size:\n",
      "                                                  (11, 100)\n",
      "Sensor indices of location of features in >sorted_values__amp_from_all_sensors< matrix: \n",
      "\n",
      "[ 7 10 10  8  8  2  9  0  0  1  0  7  2  3  2  9  2  3  5  3  1  3  7  3\n",
      "  3  3  9 10  0  5  7  0  0  0  0  2  3  0  2  0  9  3  3  2  7  3  3  3\n",
      "  3  0  0  3  3  3  3  0  3  2  0  3  2  3  3  0  2  3  9  2  2  0  2  0\n",
      "  8  2  0 10  2  7  2  3  3  2  2  0  3  3  3  3  1  8  3  0  2  3  1  2\n",
      "  3  3  2  9  3  3  0  3  0  3  8 10 10  0  2  3  2  3  3  3  3  0  7  3\n",
      "  1  0  3  0  3  0  3  9 10  2  7  0  1  3  1 10  3  2  9  3  7  0  5  9\n",
      "  1 10 10  2  2  2  1 10  7  2  2  3  7  8  2  2  8  9  2  2  2  2  2  2\n",
      "  0  2  0 10  1  1  2  2  7  7  0  3  2  0  0  2  2  0  3  0  0  2  2  7\n",
      "  1  3  2  1  0  7  0  7  3  2  2  2  0  2  8  2  2  3  2  9  0  0  2  7\n",
      "  2  2  0  0  2  5  3  0  8  7  8  2  0  0  2  3  2  2  7  9  2 10  0  7\n",
      " 10  0  2  0  2  3  0  2  0  0  0  7  2  7  2  7  9  2  0  1  3  2  7  7\n",
      "  7  0  1  7  2  7  3  7  3  7  3  7  7  7  0  7  7  7  0  1  3  1  9  0\n",
      "  3  3  7  8  7  7  5  0  3 10  7  7  0  7  0  7  0  0 10  3  7  1  7  7\n",
      "  7  7  0  7  7  7  2  7  2  7  7 10  7  9  1  8  3  1  9  0  8 10  9  3\n",
      "  7  7  2  0  7 10 10  9  1  7  7  1  4  1  8  3 10  8  1  9  9 10  0  0\n",
      "  9  6  1 10  9  0  9  7 10  3  9  1  7  8  9  0  2 10 10  1  9  1  2  1\n",
      "  9 10  1 10  8  9  7  9  9  9  8  7  9  6  3  9  8  7  8  7  8  8 10  7\n",
      "  2  8 10  8 10  9  8  8  5  9  0  1  8 10  1 10 10 10  3  7  6 10  0  0\n",
      "  8  9  8 10  8  8 10 10  1  9  9  9  8  7  9 10  9  8  8  8 10  8  9 10\n",
      "  3  8  8  1  3  8  8  8  7  6  1  1  4 10  7 10  3  6  0  4  8  4  0  1\n",
      "  9  9 10  3  2  8  4  2  8 10  8  8  1  8  8  8  9  7  8  2]\n",
      "\n",
      "Column indices of location of features in >sorted_values__amp_from_all_sensors< matrix: \n",
      "\n",
      "[27 44 41 60 82 25 73  1 18  2 78 14 98 80 97  2 17  2 12 26  0 36 47 30\n",
      " 40 23 17  6 52 13  8 59 53 67 95 74 24 56 41 96 37 56  4 33 62  7  1 43\n",
      " 72 61 50 64 47 60 87 43 58 81 44  6 35 88 97 40 56 78 66 85 69 41 12 45\n",
      " 37 51 14 24 42 35 22 25 15 52 71 51 18 86  5 77 37 41 73 60 34  9 16 72\n",
      " 14 12 88 44 98 20 93 22  3 32 11 34 87 36 68 45  7 19 82 16 17 39 87 13\n",
      "  4 58 68 37 28 47 10 71  2 75 67 86 20 11 15 91 62 82 80 33 53 25 10  1\n",
      " 59  1 73 84 43 10 50 50 11 19 32 34  1 25 31 94  1 25 92 60 83 29 26 61\n",
      " 35 30 27 26 31 44 13 59 69 78 11 44 67 21 15 55 95 76 53 57  0 20 73 10\n",
      "  8 52 21 65  6 58 34 36 69 48 62 63 26 38 28 79 53 92 86 21 77 66 49 13\n",
      " 27 44  9 99 39  8  8 20 90 90 20 77 32 23 89 41 46 40 70 28 54 30 48 38\n",
      " 22 31 50  8 76 37 68 57 81 82 38 73 70 97 66 98 16 47 22 13 29 58 79 34\n",
      " 84 80 28 43 45 32  3 52 49 56 74 28 37 92 83  9 44 83 85 78 31  1 92 72\n",
      " 65 76 49 19 46 41  7 55 89 65 72 48 92 50 65 31 28 30 18 59 59 52 86 25\n",
      " 22 94 49 95 89 39 91 91 65 77 23 35 85 29 48 30 54 47 47 74 17 60 18 66\n",
      " 65 21 36 91 15 33 99 97 99 54 19 93  7 67 62 27 29 31 43 32 31 19 62 70\n",
      " 77  1 27 94 86 71 84  7 96 21 26 57 81 32 88 64 18 88 90 60 95 49 93 18\n",
      "  0  0 72 32 95 40 33 53 65 49 86 18 13 33 95 58 94  6  0 45 75 14 27 55\n",
      "  6 35 71 24 74 60 29 59  5 55 17 90 69 15 82 76 86 77 46  0 41 70 33 19\n",
      " 83 62 64 72 45 78 49 81 56 34 46 67 70 71 43 52 23 46 72 96 57 33 63 55\n",
      " 96 54 43 70 71 85 55 67 17 35 29 23 93 63 16 58 38 43 89 94 61  9 29 55\n",
      " 38 12 36 48 78 81 92 24 63 47 73 87 83 48 68 13 42  5 65 87]\n"
     ]
    }
   ],
   "source": [
    "n_features_for_select_w=0\n",
    "for i in range(len(sorted_values__amp_from_all_sensors)):\n",
    "    n_features_for_select_w=n_features_for_select_w+int(len(sorted_values__amp_from_all_sensors[i][0,:]))\n",
    "\n",
    "# Defining how much of features with biggest correllation coeff. will be selected.\n",
    "n_of_features_w = int(input(\"How many features out of %s you want to select (recommended is 500): \" % n_features_for_select_w))\n",
    "\n",
    "\n",
    "target_matrix = pd.DataFrame(target)        # Transforming list \"target\" into data frame \"target_matrix\"\n",
    "\n",
    "print(\"\\nDimension of target matrix is:\")\n",
    "print(\"                                                 \", target_train_vector.shape)\n",
    "print(\"Dimension of amplitude matrix for one sensor is:\")\n",
    "print(\"                                                 \", sorted_values__amp_from_all_sensors[0][:,:].shape)\n",
    "\n",
    "weighted_mean=list(range(11))                      # Making list for weighted mean, covariance andf correlation coefficients.\n",
    "weighted_covariance=list(range(11))\n",
    "weighted_corelation=list(range(11))\n",
    "for j in range(11):                       # Making sublists \" for each sensor.\n",
    "    \n",
    "    weighted_mean[j]=list(range(round((N/100.0)*n_of_samples/2)))\n",
    "    weighted_covariance[j]=list(range(round((N/100.0)*n_of_samples/2)))\n",
    "    weighted_corelation[j]=list(range(round((N/100.0)*n_of_samples/2)))\n",
    "# Calculating weighted correlation coefficients for each column of each sensor with respect to target.\n",
    "for j in range(11):\n",
    "    for i in range(round((N/100.0)*n_of_samples/2)):\n",
    "        weighted_mean[j][i]=m(sorted_values__amp_from_all_sensors[j][:,i],W[j][:,i])\n",
    "        weighted_covariance[j][i]=cov(sorted_values__amp_from_all_sensors[j][:,i],target_train_vector[0],W[j][:,i])\n",
    "        weighted_corelation[j][i]=corr(sorted_values__amp_from_all_sensors[j][:,i],target_train_vector[0],W[j][:,i])\n",
    "    \n",
    "\n",
    "corr_array_w=np.array(weighted_corelation) # Transforming list of correlation coefficients to nparray\n",
    "\n",
    "print(\"Array of weighted correlation coefficients has size:\")\n",
    "print(\"                                                 \",corr_array_w.shape)  \n",
    "\n",
    "sensor_n_w, feature_n_w = largest_indices(corr_array_w, n_of_features)\n",
    "\n",
    "print(\"Sensor indices of location of features in >sorted_values__amp_from_all_sensors< matrix: \\n\")\n",
    "print(sensor_n_w)\n",
    "print(\"\\nColumn indices of location of features in >sorted_values__amp_from_all_sensors< matrix: \\n\")\n",
    "print(feature_n_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Number of features from sensor  0 is:  76 or  15.20 %\n",
      "Number of features from sensor  1 is:  38 or  7.60 %\n",
      "Number of features from sensor  2 is:  80 or  16.00 %\n",
      "Number of features from sensor  3 is:  77 or  15.40 %\n",
      "Number of features from sensor  4 is:   5 or  1.00 %\n",
      "Number of features from sensor  5 is:   6 or  1.20 %\n",
      "Number of features from sensor  6 is:   5 or  1.00 %\n",
      "Number of features from sensor  7 is:  72 or  14.40 %\n",
      "Number of features from sensor  8 is:  50 or  10.00 %\n",
      "Number of features from sensor  9 is:  45 or  9.00 %\n",
      "Number of features from sensor 10 is:  46 or  9.20 %\n",
      "----------------------------------------------------\n",
      "                                             100.00\n"
     ]
    }
   ],
   "source": [
    "abs_top_n_together_matrix_w=np.zeros((sorted_values__amp_from_all_sensors[0].shape[0],n_features_for_select))\n",
    "percentage_w,abs_top_n_together_matrix_w=percentage(sensor_n_w,feature_n_w,sorted_values__amp_from_all_sensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representation of sensors in percentages for each tral has been given  in the list percentage_w:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows comparison of frequency of occurrences for the features with highest correlation coefficients in case of methods: Weighted correlation and Pearson correlation performed for the specific number of Monte Carlo trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5a3d25e40a4cfeabba421acae43b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='trials', max=99), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.MC_plot3(trials)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def MC_plot3(trials):\n",
    "    bins = sorted_values__amp_from_all_sensors[0].shape[1]\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.hist(feature_n_w, bins, alpha=0.5, label='Weighted_corr')\n",
    "    plt.xlabel(\"Columns (1-100)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.hist(feature_n_x[trials], bins, alpha=0.5, label='Monte Carlo: Pearson_corr')\n",
    "    plt.title(\"Frequency of column indices of features with biggest correlation for all sensors\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "interact(MC_plot3,trials=widgets.IntSlider(min=0, max=99, step=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows comparison of frequency of occurrences for the features with highest correlation coefficients in case of methods: Weighted correlation and Pearson correlation (for N% of amplitudes only). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "    bins = sorted_values__amp_from_all_sensors[0].shape[1]\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.hist(feature_n_w, bins, alpha=0.5, label='Weighted_corr')\n",
    "    plt.hist(feature_n, bins, alpha=0.5, label='Pearson_corr - amplitudes only')\n",
    "    plt.xlabel(\"Columns (1-100)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Frequency of column indices of features with biggest correlation for all sensors\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representation of sensors in percentages for each tral has been given  in the list percentage_w:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47886c0117184da98fa2b62e7fd998ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='runs', max=99), Output()), _dom_classes=('widget-interac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.MC_plot2(runs)>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def MC_plot2(runs):\n",
    "    bins = len(sensor)\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.hist(sensor_n, bins, alpha=0.5, label='Pearson_corr - amplitudes only')\n",
    "    plt.xlabel(\"Sensor (0-10)\")\n",
    "    plt.ylabel(\"Frequency\") \n",
    "    plt.title(\"Frequency of sensor indices of features with biggest correlation \")\n",
    "    plt.hist(sensor_n_x[runs], bins, alpha=0.5, label='Monte Carlo: Pearson_corr')\n",
    "    plt.hist(sensor_n_w, bins, alpha=0.5, label='Weighted_corr')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "interact(MC_plot2,runs=widgets.IntSlider(min=0, max=99, step=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these histograms and percentages, conclusion about how valuable is each of the sensors for this kind of prediction. Differences in contributions are visualised in a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentages of features from each sensor are:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815b0be035a1448d85d05016bc3f2143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='trials', max=99), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.Pie_MC(trials)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.rcParams['font.size'] = 9.0\n",
    "labels = 'Microphone','Vibration plain bearing','Vibration piston rod','Vibration ball bearing', 'Axial force','Pressure','Velocity','Active current','Motor current phase 1','Motor current phase 2','Motor current phase 3'\n",
    "print(\"Percentages of features from each sensor are:\")\n",
    "\n",
    "def Pie_MC(trials):   \n",
    "\n",
    "    fig1,(ax1,ax2,ax3) = plt.subplots(1,3, figsize=(20,10))\n",
    "   \n",
    "    ax1.pie(percentage_p, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "    ax1.axis('equal')\n",
    "    ax1.legend(title=\"Pearson_corr - amplitudes only\")\n",
    "    ax2.pie(percentage_w,labels=labels, autopct='%1.1f%%', shadow=True, startangle=90 )\n",
    "    ax2.axis('equal')\n",
    "    ax2.legend(title=\"Weighted_corr\")\n",
    "    ax3.pie(percentage_x[trials], labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "    ax3.axis('equal')\n",
    "    ax3.legend(title=\"Monte Carlo: Pearson_corr\")\n",
    "# plot each pie chart in a separate subplot\n",
    "\n",
    "    plt.show()\n",
    "interact(Pie_MC,trials=widgets.IntSlider(min=0, max=99, step=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A value of M, the number of Monte Carlo trials, i.e. the number of model evaluations to be made, needs to be selected. \n",
    "A value of M = $10^6$ can often be expected to deliver a 95 % coverage interval for the output quantity such that this length is correct to one or two signiﬁcant decimal digits.  \n",
    "The choice of avalue of M that is large compared with 1/(1−p), e.g. M at least $10^4$ times greater than 1/(1−p), should be made (p-coverage interval). \n",
    "\n",
    "1) best estimate\n",
    "\\begin{align}\n",
    "\\mathbf{y} =& mean \\{ \\mathbf{y}^{(k)}, k=1,\\ldots,M\\} \\\\\n",
    "=& \\frac{1}{M} \\sum_{k=1}^M \\mathbf{y}^{(k)}\n",
    "\\end{align}\n",
    "2) uncertainty associated with the best estimate\n",
    "\\begin{align}\n",
    "U_\\mathbf{y} =& cov\\{ \\mathbf{y}^{(k)}, k=1,\\ldots,M\\} \\\\\n",
    "=& \\frac{1}{M-1} \\sum_{k=1}^M (\\mathbf{y}-\\mathbf{y}^{(k)})(\\mathbf{y}-\\mathbf{y}^{(k)})^T\n",
    "\\end{align}\n",
    " $$\\hat{y_r}=\\frac{1}{M}*\\sum_{i=1}^r y_r$$\n",
    "\n",
    "1) best estimate\n",
    "\\begin{align}\n",
    "\\mathbf{y} =& mean \\{ \\mathbf{y}^{(k)}, k=1,\\ldots,M\\} \\\\\n",
    "=& \\frac{1}{M} \\sum_{k=1}^M \\mathbf{y}^{(k)}\n",
    "\\end{align}\n",
    "2) uncertainty associated with the best estimate\n",
    "\\begin{align}\n",
    "U_\\mathbf{y} =& cov\\{ \\mathbf{y}^{(k)}, k=1,\\ldots,M\\} \\\\\n",
    "=& \\frac{1}{M-1} \\sum_{k=1}^M (\\mathbf{y}-\\mathbf{y}^{(k)})(\\mathbf{y}-\\mathbf{y}^{(k)})^T\n",
    "\\end{align}\n",
    "\n",
    "In the case of function *largest_indices* whose outputs are sensor and column indices of features with highest Pearson correlation, the of frequency of occurence of every sensor in M MC trials has been calculated and stored in `sensor_count_MC`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sensor_count_MC=np.zeros((trials,len(sensor)))\n",
    "sensor_count_Pear=np.zeros((len(sensor)))\n",
    "sensor_count_Weighted=np.zeros((len(sensor)))\n",
    "for a in range(trials):\n",
    "    #counting the frequency of occurences for every sensor in trial and storing in  sensor_count_MC list.\n",
    "    sensor_count_MC[a,:]=np.bincount(sensor_n_x[a], weights=None, minlength=0)\n",
    "\n",
    "sensor_count_df=pd.DataFrame(sensor_count_MC)\n",
    "mean_val=sensor_count_df.mean(axis=0)\n",
    "std_val=sensor_count_df.std(axis=0)\n",
    "#counting the frequency of occurences for every sensor for two others methods.\n",
    "sensor_count_Pear=np.bincount(sensor_n, weights=None, minlength=0)\n",
    "sensor_count_Weighted=np.bincount(sensor_n_w, weights=None, minlength=0)\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "w = 0.3\n",
    "ax.bar(np.arange(11)-w,mean_val,yerr=std_val, width=w, color='peachpuff', align='center',label=\"Monte Carlo mean value\")\n",
    "ax.bar(np.arange(11), sensor_count_Pear,width=w, color='lightsteelblue', align='center',label=\"Pearson_corr - amplitudes only\")\n",
    "ax.bar(np.arange(11)+w, sensor_count_Weighted, width=w, color='g', align='center',label=\"Weighted correlation\")\n",
    "\n",
    "ax.autoscale(tight=True)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualise some of the features, and see how they are correlated to each other and to the target vector.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter indices of two features out of 500 for ploting (0-499): 55 56\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b97035b1c6d49d5a9b47f4ed02d5439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='trials', max=99), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.Compare_two(trials)>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1, x2 = input(\"Enter indices of two features out of %s for ploting (0-499): \" % n_of_features).split()\n",
    "x1, x2 = [int(x1), int(x2)]\n",
    "def Compare_two(trials): \n",
    "\n",
    "    plt.subplot\n",
    " \n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.scatter(abs_top_n_together_matrix[x1], abs_top_n_together_matrix[x2],c=target_train_vector[0], cmap=\"viridis\")\n",
    "    plt.xlabel('Feature number %s' % x1 ,fontsize=12)\n",
    "    plt.title(\"Pearson_corr - amplitudes only\")\n",
    "    plt.ylabel('Feature number %s' % x2 ,fontsize=12)\n",
    "    plt.colorbar().set_label('% of wear',fontsize=12 ,rotation=90)\n",
    "    \n",
    "    plt.subplot\n",
    "    plt.title(\"Monte Carlo: Pearson_corr\")\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.scatter(abs_top_n_together_matrix_x[trials][x1], abs_top_n_together_matrix_x[trials][x2],c=target_train_vector[0], cmap=\"viridis\")\n",
    "    plt.xlabel('Feature number %s' % x1 ,fontsize=12)\n",
    "    plt.ylabel('Feature number %s' % x2 ,fontsize=12)\n",
    "    plt.colorbar().set_label('% of wear',fontsize=12 ,rotation=90)\n",
    "    \n",
    "    plt.subplot\n",
    "    plt.title(\"Weighted_corr\")\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.scatter(abs_top_n_together_matrix_w[x1], abs_top_n_together_matrix_w[x2],c=target_train_vector[0], cmap=\"viridis\")\n",
    "    plt.xlabel('Feature number %s' % x1 ,fontsize=12)\n",
    "    plt.ylabel('Feature number %s' % x2 ,fontsize=12)\n",
    "    plt.colorbar().set_label('% of wear',fontsize=12 ,rotation=90)\n",
    "interact(Compare_two,trials=widgets.IntSlider(min=0, max=99, step=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the initial number of Monte Carlo trials:0\n",
      "Enter the total number of Monte Carlo trials:50\n",
      "Enter the chosen number of Monte Carlo trials:10\n"
     ]
    }
   ],
   "source": [
    "#Updating Monte Carlo\n",
    "K0=int(input(\"Enter the initial number of Monte Carlo trials:\"))\n",
    "K=int(input(\"Enter the total number of Monte Carlo trials:\"))\n",
    "Kseq=int(input(\"Enter the chosen number of Monte Carlo trials:\"))\n",
    "#Xi_dist collects samples in trials for every sensor\n",
    "Xi_dist=list(range(len(sensor)))\n",
    "\n",
    "\n",
    "for s in range(len(sensor)):\n",
    "    #Example: sensor index=0, 5000 cycles, 1000 trials for each cycle,N% of amplitudes = 100: \n",
    "    #Xi_dist[0][:5000].shape=(1000,100)\n",
    "    Xi_dist[s]=list(range(sorted_values__amp_from_all_sensors[0].shape[0]))\n",
    "    for d in range(sorted_values__amp_from_all_sensors[0].shape[0]):\n",
    "        Xi_dist[s][d]=np.zeros((Kseq,sorted_values__amp_from_all_sensors[0].shape[1]))\n",
    "        \n",
    "\n",
    "#A - collecting value of each trial for every cycle. \n",
    "A=list(range(Kseq))\n",
    "\n",
    "for f in range(Kseq):\n",
    "#Example: Zero sensor, first trial, - A[0][1].shape=5347,100\n",
    "#initializing zero values\n",
    "    A[f]=list(range(len(sensor)))\n",
    "    for s in range(len(sensor)):\n",
    "        #Example:sensor index=0, 5000 cycles, 1000 trials for each cycle,N% of amplitudes = 100: \n",
    "        #A[:1000][0].shape=(5000,100)\n",
    "        A[f][s]=np.zeros((sorted_values__amp_from_all_sensors[0].shape))\n",
    "\n",
    "for i in range(len(sensor)):\n",
    "    for m in range(sorted_values__amp_from_all_sensors[0].shape[0]):\n",
    "        dist = Normal_ZeroCorr(loc=sorted_values__amp_from_all_sensors[i][m,:],scale=np.sqrt(sorted_uncer_from_all_sensors_a[i][m,:]))\n",
    "        Xi_dist[i][m]=dist.rvs(Kseq)\n",
    "        #A matrix will be used for Pearson's correlation:\n",
    "        # Adding values from Xi_dist to A:\n",
    "    for j in range(Kseq):\n",
    "        for s in range(sorted_values__amp_from_all_sensors[0].shape[0]):\n",
    "            A[j][i][s]=Xi_dist[i][s][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many features out of 1100 you want to select (recommended is 500): 500\n",
      "Array of correlation coefficients for one trial has size:\n",
      "                                                  (11, 100)\n",
      "Sensor indices of location of features for the first trial in >sorted_values__amp_from_all_sensors< matrix  \n",
      "\n",
      "[ 2  0 10  0  2  0  2  2  9  3  3  9  3  3  3  3 10  2  2  2  0  3  8  3\n",
      "  3  0  7  3  1  0  0  1  8  0  7  2  0  3  0  3  0  0  2  3  0  2 10  3\n",
      "  0  2  2  2  2  2  0  2  3  2  0  3  2  3 10  3  0  0  3  3  3  3  9  0\n",
      "  2  3  0  8  3  2  3  2  3  0  3  3  3  3  2  2  3  3  3  3  3  3  0  0\n",
      "  3  0  2  3  0  3  3  3  3  3  2  0 10  0  5 10  2  2  2  2  8  2  2  2\n",
      "  3  2  2  0  2  5  2  9  2  2 10  2  2  2  0  3  0  0  2  2  0  3  8  2\n",
      "  0  0  2  2  3  9  3  0  2  0  2  2  2  2  2  2  2  0  2  0  2  2  7  0\n",
      "  2  2  3  3  0  2  2  2  0  1  0  2  0  0  2  0  2  2  0  2  2  0  0  2\n",
      "  1  0  2  0  0  0  3  3  8  3  2  3  3  5  9  3  3  3  0  1  0  0 10  1\n",
      "  9  0  8  3  1  3 10  0  3  7  1 10  3  0  2  7  0  0  8 10  0  0  3  0\n",
      "  2  0  9  3 10  0  2  7  0  5  1  1  3  9  1  9  3  1  1  3  5  3  1  4\n",
      "  6  1  8  0  9  0  1 10  9  2  0  7  3  9  0 10  3  2  0 10  8  7  2  3\n",
      "  9  8  9  8  0  8  1  9  1  7  5  7 10 10  1  0  8  9  0  9  1  1  7 10\n",
      "  8  9  9  3  3  8  1  7  1  4 10  2  1  2 10  9  9  3  0  0  1  1  2  1\n",
      "  8  8  1 10  7  1  2  3  9  2  8  7 10  9  1  7  4  9  9  8  8  7  0  6\n",
      "  1  9  9  8  7  3  0  1  3  9  7  7  9  8  7  7  7  7  1  9 10  7  7  9\n",
      "  3  9  9  2  1  7  1  0  4  9  9  8 10  9  7  7  2  6 10  7 10  9  1  8\n",
      "  7 10 10 10 10 10  9  1  9  9  9 10 10  8  9 10  1  9  7  7  7  8  9  8\n",
      "  9 10  6  1  9  7  0  9  8  7  1  7  7  8 10  8  8  9  6  7  5  4 10  0\n",
      "  8  0  6  1  4 10  7  8  8  8  9 10  6 10  7 10  8  9  8  7  7  7 10  7\n",
      "  7  4  8 10  7  4 10 10 10  8  8 10  8 10  5 10  7  8  8  4]\n",
      "\n",
      "Column indices of location of features for the first trial in >sorted_values__amp_from_all_sensors< matrix \n",
      "\n",
      "[25  1 44 18 98 78 97 17 73  2 26  2 36 23 30 40 41 74 41 33 52  4 82 24\n",
      "  7 59 14  1  2 53 67  0 60 95 27 81 61 43 96 56 50 56 35  6 44 56  6 47\n",
      " 43 85 69 12 51 42 14 22 60 52 40 15 71 18 24  5 41 45 72 25 64 58 17 51\n",
      " 34  9 60 37 87 72 14 88 12  3 20 22 78 88 68  7 97 32 16 17 19 13 36 39\n",
      " 10 37 75 86 93 28 45 73 77 11 82 58 34 86 12  2 84 10 43 19 11 32 31 94\n",
      " 33 92 60 25 29 13 83  1 26 61  1 30 13 59 47 34 27 11 67 55 35 68  1 95\n",
      "  0 15 20 73 98 44 82 21 21  6 48 62 63 38 53 79 86 57 49 26 39 27  1  9\n",
      " 44 77 44  8 20 40 46 54 23 16 76 50 34 32 76  8 57 66 31 70 89 48 66 47\n",
      "  4 77 58 99 38 22 62 53 25 37 45 80 41  8 25  3 29 69 81 15 82 68 26 20\n",
      " 21 85 20 31 37 92 22 80 49 10  1 73 65 83 65 11 28 65 28 87 30 92 59 49\n",
      " 36 55 28 76 30 72 91  9 74 10 50 59 74 66 13 71 54 44 31 66  7 27 28  7\n",
      "  1  8 17 91 47 62 65 91 18 18 70 13 52  0 71  0 21 93 64 19  0  7  6 95\n",
      " 40 24 13 30 17 14 78 92 27  6  5  0 15 33 48 19 32 29 33 31 52 47 67 29\n",
      " 31 26 32 46 89 95 43 15 18  9 35 24 49 78 27 12 37 48 29 89 60 93 87 99\n",
      " 13 29 67 32  5 57 14 71 80  8 35 62 13 23 29 36  8  9 42 41  8 19 75 33\n",
      " 72 53 58 19 22 96 97 56 38 49 21 28 16 33  3 45 32 34 82 46 18 25 23  6\n",
      " 63 34 55 28 90 18 23 88  6 97 86 90 25 43 41 53 15 41 52 43 36 60 55 26\n",
      " 37 49 37  7  9 55 77 83 65  7 38 94 57 62 84 96 32 67 17 39 16 55 88  6\n",
      " 63 65 43 12  5 44 73 22 45  8 70 81 58 46 76  7 61 95 35 50  6  1 71 63\n",
      " 40 87 40 61  0 77 49 68  9 59 33 42 38 90 87 88 63 10 43 70 38 46 47 52\n",
      " 48 19 34 99 56 20 50  5 63 47 73 58 48 86  4 38 78 96 94 81]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "n_features_for_select_u=0\n",
    "for i in range(len(sorted_values_from_all_sensors)):\n",
    "    n_features_for_select_u=n_features_for_select_u+int(len(sorted_values__amp_from_all_sensors[i][0,:]))\n",
    "\n",
    "# Defining how much of features with biggest Pearson correllation coeff. will be selected.\n",
    "n_of_features_u= int(input(\"How many features out of %s you want to select (recommended is 500): \" % n_features_for_select_u))\n",
    "\n",
    "\n",
    "corr=list(range(Kseq))                    # Making list for correlation coefficients for all trials.\n",
    "p_value=list(range(Kseq))\n",
    "\n",
    "for j in range(Kseq):# Making sublists in \"corr\" for each sensor.\n",
    "    corr[j]=list(range(len(sorted_values_from_all_sensors)))\n",
    "    p_value[j]=list(range(len(sorted_values_from_all_sensors)))\n",
    "    for d in range(len(sorted_values_from_all_sensors)):        \n",
    "            corr[j][d]=list(range(round((N/100.0)*n_of_samples/2)))\n",
    "            p_value[j][d]=list(range(round((N/100.0)*n_of_samples/2)))\n",
    "\n",
    "y_mean=np.zeros((len(sensor),100))    \n",
    "Uy_mean=np.zeros((100,100))  \n",
    "for g in range(int((K/Kseq))):\n",
    "    y0_mean=y_mean\n",
    "    Uy0_mean=Uy_mean\n",
    "    sum1=0\n",
    "    \n",
    "# Calculating correlation coefficients for each column of each sensor with respect to target for all trials.\n",
    "    for s in range(Kseq): \n",
    "        for k in range(len(sorted_values_from_all_sensors)):\n",
    "            for i in range(round((N/100.0)*n_of_samples/2)):\n",
    "                corr[s][k][i],p_value[s][k][i]=pearsonr(A[s][k][:,i],target_train_vector[0])\n",
    "        sum1=sum1+(corr[s]-y0_mean)\n",
    "    y_mean=y0_mean+(1/(K0+Kseq))*sum1\n",
    "    sum2=0\n",
    "    for s in range(Kseq): \n",
    "        sum2=sum2+np.matmul((corr[s]-y_mean).T, (corr[s]-y_mean))\n",
    "    b=np.outer((y_mean-y0_mean).T, y_mean-y0_mean)\n",
    "    Uy_mean=(1/(K0+Kseq-1))*((K0-1)* Uy0_mean+K0*b+sum2)\n",
    "    K0=K0+Kseq    \n",
    "\n",
    " # Transforming list of correlation coefficients to nparray\n",
    "corr_array=np.array(y_mean)   \n",
    "\n",
    "print(\"Array of correlation coefficients for one trial has size:\")\n",
    "print(\"                                                 \",corr_array.shape)  \n",
    "\n",
    "# sensor_n_x is the index of the sensor number.\n",
    "# feature_n_x is the index of the feature number for each sensor number.\n",
    "\n",
    "\n",
    "for p in range(Kseq): \n",
    "    sensor_n_u, feature_n_u = largest_indices(corr_array, n_of_features_u)\n",
    "\n",
    "print(\"Sensor indices of location of features for the first trial in >sorted_values__amp_from_all_sensors< matrix  \\n\")\n",
    "print(sensor_n_u)\n",
    "print(\"\\nColumn indices of location of features for the first trial in >sorted_values__amp_from_all_sensors< matrix \\n\")\n",
    "print(feature_n_u)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def UMC_generic(draw_samples, evaluate, runs = 100, blocksize = 8, runs_init = 10, nbins = 100, return_samples = False, n_cpu = multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, Uy, happr=UMC_generic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corr[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30087849,  0.25082557,  0.15260159, ..., -0.11513771,\n",
       "        -0.13547562,  0.15204716],\n",
       "       [ 0.25082557,  0.51951494,  0.24229883, ..., -0.03435356,\n",
       "        -0.08796454,  0.10811995],\n",
       "       [ 0.15260159,  0.24229883,  0.45916205, ..., -0.03049838,\n",
       "        -0.04540379,  0.00424317],\n",
       "       ...,\n",
       "       [-0.11513771, -0.03435356, -0.03049838, ...,  0.14551101,\n",
       "         0.13848995, -0.10726514],\n",
       "       [-0.13547562, -0.08796454, -0.04540379, ...,  0.13848995,\n",
       "         0.14371216, -0.11003598],\n",
       "       [ 0.15204716,  0.10811995,  0.00424317, ..., -0.10726514,\n",
       "        -0.11003598,  0.12365165]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Uy_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Weighted correlation:\n",
      "Number of features from sensor  0 is:  82 or  16.40 %\n",
      "Number of features from sensor  1 is:  41 or  8.20 %\n",
      "Number of features from sensor  2 is:  84 or  16.80 %\n",
      "Number of features from sensor  3 is:  78 or  15.60 %\n",
      "Number of features from sensor  4 is:   9 or  1.80 %\n",
      "Number of features from sensor  5 is:   8 or  1.60 %\n",
      "Number of features from sensor  6 is:   7 or  1.40 %\n",
      "Number of features from sensor  7 is:  47 or  9.40 %\n",
      "Number of features from sensor  8 is:  44 or  8.80 %\n",
      "Number of features from sensor  9 is:  51 or  10.20 %\n",
      "Number of features from sensor 10 is:  49 or  9.80 %\n",
      "----------------------------------------------------\n",
      "                                             100.00\n"
     ]
    }
   ],
   "source": [
    "# Percentages for all sensors for weighted correlation\n",
    "\n",
    "# Initialising a list of best features. 11 sublists containing features from each sensor, respectively.\n",
    "top_n_features_u=[[], [], [], [], [], [], [], [], [], [], []]\n",
    "for i in range(len(sensor)):\n",
    "    for j in range(len(sensor_n_u)):\n",
    "        if sensor_n_u[j]==i:\n",
    "            top_n_features_u[i].append(sorted_values__amp_from_all_sensors[i][:,feature_n_u[j]]);\n",
    "\n",
    "for i in range(len(sensor)):\n",
    "    for j in range(len(top_n_features_u[i])):\n",
    "        top_n_features_u[i][j]=list(top_n_features_u[i][j])\n",
    "\n",
    "# Merging sublists into one list with all elements.\n",
    "top_n_together_u=[j for i in top_n_features_u for j in i]  \n",
    "\n",
    "top_n_together_matrix_u=np.transpose(pd.DataFrame(top_n_together_u))\n",
    "print(type(top_n_together_matrix_u), \"\\n\")\n",
    "\n",
    "# Continue working with abosulte values.\n",
    "abs_top_n_together_matrix_u=np.abs(top_n_together_matrix_u)\n",
    "\n",
    "percentage_u=list(range(11))\n",
    "k=0\n",
    "print(\"Weighted correlation:\")\n",
    "for i in range(len(sensor)):\n",
    "    #print(top_n_features_matrix.shape)\n",
    "    print(\"Number of features from sensor %2.0f is: %3.0f or  %4.2f %%\" % (i, len(top_n_features_u[i]), len(top_n_features_u[i])/len(sensor_n_u)*100))\n",
    "    percentage_u[i]=len(top_n_features_u[i])\n",
    "    k=k+len(top_n_features_u[i])/len(sensor_n_u)*100\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"                                             %4.2f\" % (k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Uy_mean=np.zeros((len(sensor),100))  \n",
    "Uy_mean=(1/(K0+Kseq-1))*((K0-1)*Uy0_mean+K0*(y_mean-y0_mean).T*(y_mean-y0_mean)+sum((corr[s]-y_mean).T*(corr[s]-y_mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test1.close()\n",
    "amp_fft1.close()\n",
    "freq_fft1.close()\n",
    "amp_dft2.close()\n",
    "freq_dft2.close()\n",
    "ph_dft2.close()\n",
    "u_a_dft2.close()\n",
    "u_ap_dft2.close()\n",
    "u_pp_dft.close()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "[1]  PTB, ZeMA, - Deep dive into the ZeMA machine learning (ppt), January 2019\n",
    "\n",
    "[2]  https://www.nti-audio.com/en/support/know-how/fast-fourier-transform-fft\n",
    "\n",
    "[3]  http://www.sthda.com/english/wiki/correlation-test-between-two-variables-in-r\n",
    "\n",
    "[4]  https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\n",
    "\n",
    "[5]  Edouard Duchesnay, Tommy Löfstedt, - Statistics and Machine Learning in Python, March 2018\n",
    "\n",
    "[6]  https://ipywidgets.readthedocs.io/en/latest/examples/Using%20Interact.html\n",
    "\n",
    "[7]  Evaluation of measurement data — Supplement 1 to the “Guide to the expression of uncertainty in measurement” — Propagation      of distributions using a Monte Carlo method,  JCGM 101:2008 \n",
    "\n",
    "[8]  S Eichstädt (PTB) - Material for a Monte Carlo Uncertainty workshop with Jupyter notebooks https://github.com/eichstaedtPTB/MonteCarloHandsOn                   \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
