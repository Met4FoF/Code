{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "We preprocess and resample the raw data .txt files we downloaded earlier into numpy. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample 10Hz and 100Hz data to 1Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_path = \"Dataset/ZEMA_Hydraulic/\"\n",
    "\n",
    "filenames_input_data_10Hz = [\"fs1\",\"fs2\"]       \n",
    "filenames_input_data_10Hz = [file + \".txt\" for file in filenames_input_data_10Hz]\n",
    "\n",
    "filenames_input_data_100Hz = [\"ps1\",\"ps2\",\"ps3\",\"ps4\",\"ps5\",\"ps6\",\"eps1\"]       \n",
    "filenames_input_data_100Hz = [file + \".txt\" for file in filenames_input_data_100Hz]\n",
    "  \n",
    "data_input_data_10Hz = np.zeros((2205,600,len(filenames_input_data_10Hz)))\n",
    "data_input_data_100Hz = np.zeros((2205,6000,len(filenames_input_data_100Hz)))\n",
    "\n",
    "for id_,file_name in enumerate(filenames_input_data_10Hz):\n",
    "    input_data = np.loadtxt(data_path + file_name, delimiter = \"\\t\")\n",
    "    data_input_data_10Hz[:,:,id_] = input_data.copy()\n",
    "\n",
    "for id_,file_name in enumerate(filenames_input_data_100Hz):\n",
    "    input_data = np.loadtxt(data_path + file_name, delimiter = \"\\t\")\n",
    "    data_input_data_100Hz[:,:,id_] = input_data.copy()\n",
    "\n",
    "filenames_input_data_10Hz_resampled = [\"res_\"+file for file in filenames_input_data_10Hz]\n",
    "filenames_input_data_100Hz_resampled = [\"res_\"+file for file in filenames_input_data_100Hz]\n",
    "\n",
    "#resample 10Hz\n",
    "resample = np.linspace(0,600-1, num =60,dtype=\"int\")\n",
    "data_resampled_10Hz=data_input_data_10Hz[:,resample,:]\n",
    "\n",
    "#resample 100Hz \n",
    "resample = np.linspace(0,5999, num =60,dtype=\"int\")\n",
    "data_resampled_100Hz=data_input_data_100Hz[:,resample,:]\n",
    "\n",
    "#save file\n",
    "for id_,file_name in enumerate(filenames_input_data_10Hz_resampled):\n",
    "    np.savetxt(data_path+file_name,data_resampled_10Hz[:,:,id_],delimiter='\\t')\n",
    "for id_,file_name in enumerate(filenames_input_data_100Hz_resampled):\n",
    "    np.savetxt(data_path+file_name,data_resampled_100Hz[:,:,id_],delimiter='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all the 1Hz data\n",
    "\n",
    "Load all data including the resampled sensors into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data\n",
    "datarows = 2205\n",
    "seq_length = 60\n",
    "\n",
    "#deal with inputs data\n",
    "filenames_input_data_1Hz = [\"ts1\",\"ts2\",\"ts3\",\"ts4\",\"vs1\",\"se\",\"res_fs1\",\"res_fs2\",\"res_ps1\",\"res_ps2\",\"res_ps3\",\"res_ps4\",\"res_ps5\",\"res_ps6\",\"res_eps1\",\"ce\",\"cp\"]                           \n",
    "filenames_input_data_1Hz = [file + \".txt\" for file in filenames_input_data_1Hz]\n",
    "filename_target_data = \"profile.txt\" \n",
    "        \n",
    "data_input_data_1Hz = np.zeros((datarows,seq_length,len(filenames_input_data_1Hz)))\n",
    "\n",
    "for id_,file_name in enumerate(filenames_input_data_1Hz):\n",
    "    input_data = np.loadtxt(data_path + file_name, delimiter = \"\\t\")\n",
    "    data_input_data_1Hz[:,:,id_] = input_data.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the target multi-target, multi-class output data \n",
    "\n",
    "We load them and preprocess into one hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deal with output data now\n",
    "targets_data = np.loadtxt(data_path+filename_target_data, delimiter = \"\\t\")\n",
    "        \n",
    "#conversion of outputs to one hot\n",
    "def makeOneHotVectorMap(length):\n",
    "    map_toOneHot ={}\n",
    "    for i in range(length):\n",
    "        oneHot = np.zeros(length)\n",
    "        oneHot[i] = 1\n",
    "        map_toOneHot[i] = oneHot\n",
    "    return map_toOneHot\n",
    "        \n",
    "id2x_dictionaries = []\n",
    "x2id_dictionaries = []\n",
    "id2onehot_dictionaries = []\n",
    "        \n",
    "for label in range(targets_data.shape[1]):\n",
    "    label_column = list(set(targets_data[:,label]))\n",
    "    label_column.sort(reverse=True)\n",
    "    id2x_dictionary = {}\n",
    "    x2id_dictionary = {}\n",
    "    id2onehot_dictionary = makeOneHotVectorMap(len(label_column))\n",
    "    for i in range(len(label_column)):\n",
    "        id2x_dictionary[i] = label_column[i]   \n",
    "        x2id_dictionary[label_column[i]] = i\n",
    "    id2x_dictionaries+=[id2x_dictionary]\n",
    "    x2id_dictionaries+=[x2id_dictionary]\n",
    "    id2onehot_dictionaries+=[id2onehot_dictionary]\n",
    "            \n",
    "#convert a row into one-hot coded multi-class multi-label\n",
    "onehot_tensor_output = []\n",
    "id_output =[]\n",
    "for row in range(targets_data.shape[0]):\n",
    "    row_output_data= targets_data[row]\n",
    "    onehots_row =[]  \n",
    "    id_row =[] \n",
    "    for label in range(row_output_data.shape[0]):\n",
    "        id_ = x2id_dictionaries[label][row_output_data[label]]\n",
    "        onehot= id2onehot_dictionaries[label][id_]\n",
    "        onehots_row =np.append(onehots_row,onehot)\n",
    "        id_row = np.append(id_row,id_)\n",
    "    id_output+=[id_row]\n",
    "    onehot_tensor_output += [onehots_row]\n",
    "onehot_tensor_output = np.array(onehot_tensor_output)\n",
    "id_tensor_output = np.array(id_output)\n",
    "    \n",
    "tensor_output = id_tensor_output        \n",
    "all_tensor_output = id_tensor_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pickle_folder= \"pickles\"\n",
    "\n",
    "if os.path.exists(pickle_folder) == False:\n",
    "    os.mkdir(pickle_folder)\n",
    "\n",
    "#Pickle them\n",
    "pickle.dump(data_input_data_1Hz, open( pickle_folder+\"/data_input_data_1Hz_full.p\", \"wb\" ) )\n",
    "pickle.dump(data_input_data_10Hz, open( pickle_folder+\"/data_input_data_10Hz.p\", \"wb\" ) )\n",
    "pickle.dump(data_input_data_100Hz, open( pickle_folder+\"/data_input_data_100Hz.p\", \"wb\" ) )\n",
    "pickle.dump(id2onehot_dictionaries, open( pickle_folder+\"/id2onehot_dictionaries.p\", \"wb\" ) )\n",
    "pickle.dump(all_tensor_output, open( pickle_folder+\"/zema_outputs.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
