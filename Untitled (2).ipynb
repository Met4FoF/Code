{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data provided for the purpose of building these tutorials contains lot of sensors which might be correlated to deviations from nominal dimensions of production parts. \n",
    "\n",
    "Some of these sensors are not in use and some of these were chosen as relevant sensors for specific production phase (heating/transfer/forging) in *Strathcylde_AFRC_machine_learning_tutorials*. \n",
    "\n",
    "First step will be to examine if some other sensors can be also considered as relevant sensors for some production phase. This will be conducted for only one part because the same process is repeated for all other parts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import time\n",
    "%pip install openpyxl\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from scipy.signal import find_peaks\n",
    "from scipy import integrate\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from matplotlib._png import read_png\n",
    "from matplotlib.cbook import get_sample_data\n",
    "\n",
    "font = {'family' : 'Times New Roman', 'weight' : 'normal', 'size'   : 20}\n",
    "mpl.rcParams['figure.figsize'] = (20,10)\n",
    "mpl.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List `data` with length of 81 is containing matrix for each part, where columns are time series from sensors measurements. Column names are names of sensors, and row indices are samples numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[0]*81\n",
    "for i in range(81):\n",
    "    print(\"|\"*(i+1),(i+1), end=\"\\r\")\n",
    "    file_format=\"Scope\"+str(\"{:04d}\".format(i+1))+\".csv\"    \n",
    "    data[i] = pd.read_csv(Path('Data')/'AFRC Radial Forge - Zenodoo Upload v3'/'Data'/'ScopeTraces'/file_format.format(i), header=0, encoding = 'unicode_escape')#, index_col=0)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at column names of imported data gives us insight into sensors used for this measurement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating the data from all part will make one long time series. Index will be recreated, and timeline will be adjusted. Before concatenating part labels will be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,df in enumerate(data):\n",
    "    df['traceID'] = index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.concat(data, ignore_index=True)\n",
    "merged_data['Time [s]']=(merged_data.index.values)/100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will have a look in data for only one part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.iloc[0:23328].to_excel(\"Merged_data_from_1st_sensor.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sensor=pd.read_excel(\"Merged_data_from_1st_sensor.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensors that are not in use or are the part of auxiliary process measurement will be dropped:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_sensors=first_sensor.drop(['hydraulic low pressure [bar]','hydraulic high pressure [bar]','A_NOM_Force [kN]','B_ACTpos [mm]','B_ACT_Force [kN]',\"B_ACTspd [mm/min]\",\"B_NOMpos [mm]\",\"B_OUT [%]\",\"B_NOMspd [mm/min]\",\"B_NOM_Force [kN]\",\"Feedback B [%]\",\"DB_NOM_Force [kN]\",\"D_ACTpos [mm]\",\"D_ACT_Force [kN]\",\"D_ACTspd [mm/min]\",\"D_NOMpos [mm]\",\"D_OUT [%]\",\"D_NOMspd [mm/min]\",\"D_NOM_Force [kN]\", \"Feedback D [%]\",\"Lub_ActSpd [rpm]\",\"Hyd_ActSpd [rpm]\",\"O_EMERG\",\"STP || EM\",\"O_MASTOP\",\"$U_GH_NOMVAL_1 (U25W1)\",\"$H1P_Y12 (U11S17)\",\"$H1P_Y11 (U11S7)\",\"$U_GH_NOMEXT_2 (U26S1)\",\"$U_GH_HEATON_2 (U26S0)\",\"$U_GH_NOMEXT_1 (U25S1)\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look into rest of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "font = {'family' : 'Times New Roman', 'weight' : 'normal', 'size'   : 20}\n",
    "mpl.rcParams['figure.figsize'] = (20,10)\n",
    "mpl.rc('font', **font)\n",
    "\n",
    "def overview(num_of_sensor):\n",
    "    names=list(used_sensors.columns.values)\n",
    "    plt.plot(used_sensors['Time [s]'],used_sensors[names[num_of_sensor+3]])\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.title(names[num_of_sensor+3])\n",
    "    plt.ylabel('Values');\n",
    "interact(overview,num_of_sensor=widgets.IntSlider(min=0, max=99, step=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensors chosen as relevant sensors for specific production phase (heating/transfer/forging) in *Strathcylde_AFRC_machine_learning_tutorials* as well as those which had been dropped as non - relevant will not be considered in the next plot. Only the rest of the sensors will be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_sensors=used_sensors.drop(['Schlagzahl [1/min]',\"Power [kW]\",\"Force [kN]\",\"A_ACT_Force [kN]\",\"A_NOMpos [mm]\",\"A_ACTpos [mm]\",\"DB_ACT_Force [kN]\",\"SBA_ActPos [mm]\",\"IP_ActPos [mm]\",\"IP_NomPos\",\"TMP_Ind_U1 [°C]\",\"TMP_Ind_F [°C]\",\"L_ACTpos [mm]\",\"L_NOMpos [mm]\",\"R_ACTpos [mm]\",\"R_NOMpos [mm]\",\"EXZ_pos [deg]\",'A_ACTspd [mm/min]','A_NOMspd [mm/min]','A_OUT [%]','Feedback A [%]','DB_ACTpos [mm]','DB_ACTspd [mm/min]','DB_NOMpos [mm]','DB_OUT [%]','DB_NOMspd [mm/min]','Feedback DB [%]','L_ACTspd [mm/min]','L_OUT [%]','L_NOMspd [mm/min]','Feedback L [%]','R_ACTspd [mm/min]','R_OUT [%]','R_NOMspd [mm/min]','Feedback R [%]','SBA_NomPos [mm] [mm]','SBA_OUT [%]','Feedback SBA [%]',\"ForgingBox_Temp\",\"$U_GH_HEATON_1 (U25S0).1\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "font = {'family' : 'Times New Roman', 'weight' : 'normal', 'size'   : 20}\n",
    "mpl.rcParams['figure.figsize'] = (20,10)\n",
    "mpl.rc('font', **font)\n",
    "def overview_other_sensors(num_of_sensor):\n",
    "   \n",
    "    plt.plot(other_sensors['Time [s]'], other_sensors[[num_of_sensor]])\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.title(num_of_sensor)\n",
    "    plt.ylabel('Values');\n",
    "interact(overview_other_sensors,num_of_sensor=list(other_sensors.columns[3:].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the plot, additional sensors that will be considered are:\n",
    "- A_ges_vibr\n",
    "- INDA_NOMpos [deg]\n",
    "- FRC_Volt\n",
    "- RamRetract_ActSpd [rpm]\n",
    "- W1 Durchfluss [I]\n",
    "- W2 Durchfluss [I]\n",
    "- L1.R_B41 (bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_sensors.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_sensors=used_sensors.drop(['EXZ_pos [deg]','DB_ACTpos [mm]',\"IP_ActSpd [mm/min]\",\"IP_NomSpd [mm/min]\",'INDA_ACTpos [deg]','INDA_NOMspd [U/min]','INDA_OUT [%]','INDA_ACTspd [U/min]',\n",
    "       'Speed Vn_1 [rpm]', 'NOMforceSPA [kN]', '$F_F41L (I14S8)','SPA_OUT [%]','Feedback_SPA [%]','IP_Out [%]',\n",
    "       'ACTforceSPA [kN]', '$U_GH_HEATON_1 (U25S0)','$E_GH_FAULT_2 (I26S21)','L_ACTspd [mm/min]',\n",
    "       'R_ACTspd [mm/min]', 'SBA_NomPos [mm] [mm]', 'A_ACTspd [mm/min]',\n",
    "       'DB_ACTspd [mm/min]','SBA_OUT [%]', 'DB_NOMpos [mm]', 'L_OUT [%]', 'R_OUT [%]', 'Feedback SBA [%]',\n",
    "       'A_OUT [%]', 'DB_OUT [%]', 'L_NOMspd [mm/min]',\n",
    "       'R_NOMspd [mm/min]','A_NOMspd [mm/min]',\"Feedback A [%]\",\n",
    "       'Feedback DB [%]','DB_NOMspd [mm/min]', 'Feedback L [%]', 'Feedback R [%]','$E_GH_FAULT_1 (I25S21)', '$B12R_Y11 (U14S16)', 'Unnamed: 0','c01w', 'c02w', 'Timer Tick [ms]', 'Block-Nr','traceID','Time [s]','$U_GH_HEATON_1 (U25S0).1'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of sensors which will be analyzed is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(used_sensors.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and they are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_sensors.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These sensors will be analyzed for all parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts=[None]*81\n",
    "for i in range(len(data)):\n",
    "    parts[i]=data[i][used_sensors.columns.values].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the uncertainty propagation, software package PyDynamic will be used. For every sensor, measurements of each part will be considered as one cycle. It means that for every sensor, there will be 81 cycle because there are 81 parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyDynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyDynamic import __version__ as version\n",
    "version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Period of sampling is 0.01 s. This means that signals are sampled at frequency of 100 Hz.The number of sampling points (signal length) varies afrom part to part and because of this, cycles have to be separated into list elements. Unequal signal length will be considered in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors=[None]*(parts[0].shape[1])\n",
    "for p in range (parts[0].shape[1]):\n",
    "    sensors[p] = [None]*(len(parts))\n",
    "    for k in range(len(parts)):\n",
    "            sensors[p][k]=parts[k].iloc[:,p].values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of sampling points for the first sensor and first cycle (part):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sensors[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time domain signal will presented in frequency domain with associated uncertainty ux as squared standard deviation representing noise variances (sigma²) of the signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma=float(input(\"Enter the value of white noise standard deviation:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyDynamic.uncertainty.propagate_DFT import GUM_DFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyDynamic.uncertainty.propagate_DFT import GUM_DFT,DFT2AmpPhase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `Perform_Fourier` uses three functions from PyDynamic: *GUM_DFT*, *DFT2AmpPhase*, *GUM_DFTfreq*. First, by GUM_DFT applied on time signals and related uncertainties, we will get real and imaginary parts contained in vector F, as well as their uncertainties (vector UF). When only white noise is considered, all off-diagonal elements of UF are equal to zero. For this reason, UF is vector and not covariance matrix. Then, from the results of *GUM_DFT*, function *DFT2AmpPhase* will provide amplitudes, phases and their uncertainties.\n",
    "\n",
    "It is possible that PyDynamic raises a warning, such as:\n",
    "*Some amplitude values are below the defined threshold.\n",
    "The GUM formulas may become unreliable and a Monte Carlo approach is recommended instead.*\n",
    "\n",
    "This means that amplitudes are small relative to the uncertainty associated with real and imaginary parts and the GUM uncertainty propagation becomes unreliable and a Monte Carlo method is recommended instead.The default threshold in GUM2DFT is 1.0, but may be adjusted for specific applications.\n",
    "\n",
    "Function returns:\n",
    "- freq -  From Nyquist's theorem we know that the largest frequency component in the original signal must be half the sampling frequency. So, from a number of points of signals (*n_of_sampling_pts*) sampled at 100Hz we get (*n_of_sampling_pts*/2+1) unique spectral points covering the range 0 to 50Hz.,\n",
    "- A - amplitudes of time domain signals\n",
    "- P - phases of time domain signals\n",
    "- UAP - uncertainties of time domain signals (standard squared uncertainties of amplitudes,covariance between amplitudes and phases, and standard squared uncertainties of phases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perform_Fourier(sensor,sigma):\n",
    "    n_of_sampling_pts=len(sensor)\n",
    "    sample_period=0.01\n",
    "    time=0.01*n_of_sampling_pts# number of sampling points\n",
    "    time_steps=np.arange(0, time, 0.01)  \n",
    "    freq=PyDynamic.uncertainty.propagate_DFT.GUM_DFTfreq(n_of_sampling_pts,float(time)/n_of_sampling_pts)\n",
    "    ux=sigma**2\n",
    "    N=n_of_sampling_pts//2+1\n",
    "    selector=np.arange(N)\n",
    "    ns=len(selector)\n",
    "    A=np.zeros(ns)\n",
    "    P=np.zeros_like(A)\n",
    "    UAP=np.zeros(3*ns)\n",
    "    X,UX=GUM_DFT(sensor,ux)\n",
    "    A, P, UAP_m = DFT2AmpPhase(X, UX, keep_sparse=True)\n",
    "    UAP[:ns] = UAP_m.data[0][:N][selector]\n",
    "    UAP[ns:2*ns] = UAP_m.data[1][UAP_m.offsets[1]:2*N+UAP_m.offsets[1]][selector]\n",
    "    UAP[ 2*ns:] = UAP_m.data[0][N:][selector]\n",
    "    return freq,A,P,UAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unequal length of time signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the length of time signals varies, Fourier transform will be first performed for the cycles with minimum and maximum length. These two time signals will be considered as two extreme cases for solving this problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_length=[None]*(len(parts))\n",
    "for i in range(len(parts)):\n",
    "    cycle_length[i]=(parts[i].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=max(cycle_length)\n",
    "print(\"Maximum length of time signals is:\",max_length, \"and it is in\",cycle_length.index(max_length),\". cycle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length=min(cycle_length)\n",
    "print(\"Minimum length of time signals is:\",min_length, \"and it is in\",cycle_length.index(min_length),\". cycle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have a look at Fourier transform of time signals in 42nd cycle for all of 24 sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A_sensors_42=[None]*len(sensors)\n",
    "P_sensors_42=[None]*len(sensors)\n",
    "UAP_sensors_42=[None]*len(sensors)\n",
    "freq_42=[None]*len(sensors)\n",
    "for i in range(len(sensors)):\n",
    "    freq_42[i],A_sensors_42[i], P_sensors_42[i], UAP_sensors_42[i]=Perform_Fourier(sensors[i][42],sigma)\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have a look at Fourier transform of time signals in 17th cycle for all of 24 sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sensors_17=[None]*len(sensors)\n",
    "P_sensors_17=[None]*len(sensors)\n",
    "UAP_sensors_17=[None]*len(sensors)\n",
    "freq_17=[None]*len(sensors)\n",
    "for i in range(len(sensors)):\n",
    "    freq_17[i],A_sensors_17[i], P_sensors_17[i], UAP_sensors_17[i]=Perform_Fourier(sensors[i][17],sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next plot shows the differences in amplitudes between both cycles. Be aware of different frequency bins because of the length of time signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "font = {'family' : 'Times New Roman', 'weight' : 'normal', 'size'   : 20}\n",
    "mpl.rcParams['figure.figsize'] = (20,10)\n",
    "mpl.rc('font', **font)\n",
    "def overview_cycles(i):\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(freq_17[i],A_sensors_17[i])\n",
    "    plt.xlabel('Frequencies [Hz]')\n",
    "    plt.ylabel('Amplitudes');\n",
    "    plt.yscale('log')\n",
    "    num_of_sensor=list(parts[0].columns.values)\n",
    "    plt.title(num_of_sensor[i])\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.yscale('log')\n",
    "    plt.plot(freq_42[i],A_sensors_42[i])\n",
    "    plt.xlabel('Frequencies [Hz]')\n",
    "    plt.ylabel('Amplitudes');\n",
    "    \n",
    "interact(overview_cycles,i=widgets.IntSlider(min=0, max=24, step=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Value padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to analyze the amplitudes at the same frequencies for all cycles, the simplest way is to add some values at the end of short time series so that they have the length of the longest one. As a reminder, the longest time signal has length: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=max(cycle_length)\n",
    "print(\"Maximum length of time signals is:\",max_length, \"and it is in\",cycle_length.index(max_length),\". cycle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shortest time signal has length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length=min(cycle_length)\n",
    "print(\"Minimum length of time signals is:\",min_length, \"and it is in\",cycle_length.index(min_length),\". cycle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three cases of adding values will be examined:\n",
    "- zeros\n",
    "- mean value of the time signal\n",
    "- last value of time signal.\n",
    "The effect of adding values will be analyzed on the shortest time signal (17) for all sensors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `add_value` will be created. It will take time signals for all parts as arguments and return *sensors_value_0*, *sensors_value_mean*, *sensors_value_last* with values 0, mean value and last element value respectively added to the end of time signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_value(all_parts):\n",
    "    sensors_value_0=[None]*(all_parts[0].shape[1])\n",
    "    sensors_value_mean=[None]*(all_parts[0].shape[1])\n",
    "    sensors_value_last=[None]*(all_parts[0].shape[1])\n",
    "    for p in range (all_parts[0].shape[1]):\n",
    "        sensors_value_0[p]=np.zeros((len(all_parts),max_length))\n",
    "        sensors_value_mean[p]=np.zeros_like(sensors_value_0[p])\n",
    "        sensors_value_last[p]=np.zeros_like(sensors_value_0[p])\n",
    "        for k in range(len(all_parts)):\n",
    "                if all_parts[k].shape[0]==max_length:\n",
    "                    sensors_value_0[p][k,:]=all_parts[k].iloc[:,p].values\n",
    "                    sensors_value_mean[p][k,:]=sensors_value_0[p][k,:]\n",
    "                    sensors_value_last[p][k,:]=sensors_value_0[p][k,:]\n",
    "                else:\n",
    "                    sensors_value_0[p][k,:all_parts[k].shape[0]]=parts[k].iloc[:,p].values\n",
    "                    sensors_value_mean[p][k,:all_parts[k].shape[0]]= sensors_value_0[p][k,:all_parts[k].shape[0]]\n",
    "                    sensors_value_last[p][k,:all_parts[k].shape[0]]= sensors_value_0[p][k,:all_parts[k].shape[0]]\n",
    "                    sensors_value_0[p][k,parts[k].shape[0]:]=0\n",
    "                    sensors_value_mean[p][k,parts[k].shape[0]:]=np.mean(all_parts[k].iloc[-100:,p].values)\n",
    "                    sensors_value_last[p][k,parts[k].shape[0]:]=all_parts[k].iloc[-1,p]\n",
    "    return sensors_value_0,sensors_value_mean,sensors_value_last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_zero,sensors_mean,sensors_last=add_value(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourier transform into frequency domain will be performed for all cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sensors_17_zero=[None]*len(sensors_zero)\n",
    "P_sensors_17_zero=[None]*len(sensors_zero)\n",
    "UAP_sensors_17_zero=[None]*len(sensors_zero)\n",
    "freq_17_zero=[None]*len(sensors_zero)\n",
    "for i in range(len(sensors_zero)):\n",
    "    freq_17_zero[i],A_sensors_17_zero[i], P_sensors_17_zero[i], UAP_sensors_17_zero[i]=Perform_Fourier(sensors_zero[i][17],sigma)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sensors_17_mean=[None]*len(sensors_mean)\n",
    "P_sensors_17_mean=[None]*len(sensors_mean)\n",
    "UAP_sensors_17_mean=[None]*len(sensors_mean)\n",
    "freq_17_mean=[None]*len(sensors_mean)\n",
    "for i in range(len(sensors_mean)):\n",
    "    freq_17_mean[i],A_sensors_17_mean[i], P_sensors_17_mean[i], UAP_sensors_17_mean[i]=Perform_Fourier(sensors_mean[i][17],sigma)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sensors_17_last=[None]*len(sensors_last)\n",
    "P_sensors_17_last=[None]*len(sensors_last)\n",
    "UAP_sensors_17_last=[None]*len(sensors_last)\n",
    "freq_17_last=[None]*len(sensors_last)\n",
    "for i in range(len(sensors_last)):\n",
    "    freq_17_last[i],A_sensors_17_last[i], P_sensors_17_last[i], UAP_sensors_17_last[i]=Perform_Fourier(sensors_last[i][17],sigma)\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Padding based on cubic spline interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spline interpolation requires two essential steps: (1) a spline representation of the curve is computed, and (2) the spline is evaluated at the desired points. The direct method of representing a curve and obtaining spline coefficients is in a two- dimensional plane using the function splrep. The first two arguments are the only ones required, and these provide the x-axis and y-axis components of the curve. The normal output is a 3-tuple,(t,c,k), containing the knot-points,t, the coefficients c and the order k of the spline. The default spline order is cubic.\n",
    "\n",
    "The keyword argument, s , is used to specify the amount of smoothing to perform during the spline fit. The default value of  is  where  is the number of data-points being fit. Therefore, if no smoothing is desired a value of s=0 should be passed to the routines.\n",
    "\n",
    "Once the spline representation of the data has been determined, functions are available for evaluating the spline (splev). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the spline, new values of x-axis are needed and actually, x-axis values are time steps. For each cycle, number of additional points on x-axis depends on the difference between its cycle length and the highest cycle length. Difference is divided by 100 because sampling period is 100 ms (or 0.01 s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diff=[None]*len(cycle_length)\n",
    "for i in range(len(cycle_length)):\n",
    "    time_diff[i]=(cycle_length[42]-cycle_length[i])/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, cubic spline is created based on the original signal length and that is how variable tck is obtained. Then, this spline is used to obtain new y-axis values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "sensors_spl=[None]*(parts[0].shape[1])\n",
    "   \n",
    "for p in range (parts[0].shape[1]):\n",
    "    sensors_spl[p]=np.zeros((len(parts),max_length))\n",
    "        \n",
    "    for k in range(len(parts)):\n",
    "        if parts[k].shape[0]==max_length:\n",
    "            sensors_spl[p][k,:]=parts[k].iloc[:,p].values\n",
    "                    \n",
    "        else:\n",
    "            time_steps=np.arange(0,time_diff[k],0.01)   \n",
    "            x = np.arange(0,cycle_length[k]* 0.01, 0.01)\n",
    "            y = parts[k].iloc[:,p].values\n",
    "            tck = interpolate.splrep(x, y, s=0)\n",
    "            xnew = np.arange(0,time_diff[k],0.01)   \n",
    "            ynew = interpolate.splev(xnew, tck, der=0)\n",
    "            sensors_spl[p][k,:parts[k].shape[0]]=parts[k].iloc[:,p].values\n",
    "            sensors_spl[p][k,parts[k].shape[0]:]=ynew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Fourier transform can be perfomed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sensors_17_spl=[None]*len(sensors_spl)\n",
    "P_sensors_17_spl=[None]*len(sensors_spl)\n",
    "UAP_sensors_17_spl=[None]*len(sensors_spl)\n",
    "freq_17_spl=[None]*len(sensors_spl)\n",
    "for i in range(len(sensors_spl)):\n",
    "    freq_17_spl[i],A_sensors_17_spl[i], P_sensors_17_spl[i], UAP_sensors_17_spl[i]=Perform_Fourier(sensors_spl[i][17],sigma)\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next plot shows the amplitudes for given frequencies for the 17th cycle with added zero value, mean value,last element value and cubic spline. It can be seen that deviation of amplitudes for zero padding is often the most significant. That is shown on the joint, but also in separate plots. Note that, when compared with ('Amplitudes - without padding') all of the padded results have different frequency bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "font = {'family' : 'Times New Roman', 'weight' : 'normal', 'size'   : 20}\n",
    "mpl.rcParams['figure.figsize'] = (25,25)\n",
    "mpl.rc('font', **font)\n",
    "def overview_amplitudes(i):\n",
    "    plt.plot(freq_17[i],A_sensors_17[i],label=  'Amplitudes - without padding')\n",
    "    plt.plot(freq_17_zero[i],A_sensors_17_zero[i], label=  'Amplitudes - zero padding')\n",
    "    plt.plot(freq_17_mean[i],A_sensors_17_mean[i],label=  'Amplitudes - mean padding')\n",
    "    plt.plot(freq_17_last[i],A_sensors_17_last[i], label='Amplitudes - last element padding' )\n",
    "    plt.plot(freq_17_spl[i],A_sensors_17_spl[i], label=  'Amplitudes - spline interpolation')\n",
    "    plt.yscale('log')\n",
    "    plt.ylabel('Amplitudes');\n",
    "    num_of_sensor=list(parts[0].columns.values)\n",
    "    plt.title(num_of_sensor[i])\n",
    "    plt.legend()\n",
    "\n",
    "interact(overview_amplitudes,i=widgets.IntSlider(min=0, max=24, step=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "font = {'family' : 'Times New Roman', 'weight' : 'normal', 'size'   : 20}\n",
    "mpl.rcParams['figure.figsize'] = (25,25)\n",
    "mpl.rc('font', **font)\n",
    "def overview_amplitudes(i):\n",
    "\n",
    "    num_of_sensor=list(parts[0].columns.values)\n",
    "    plt.title(num_of_sensor[i])\n",
    "    plt.subplot(4,1,1)\n",
    "    plt.plot(freq_17_zero[i],A_sensors_17_zero[i],label=  'Amplitudes - zero padding')\n",
    "    plt.plot(freq_17[i],A_sensors_17[i],label=  'Amplitudes - without padding')\n",
    "    plt.yscale('log')\n",
    "    plt.ylabel('Amplitudes ');\n",
    "    plt.legend()\n",
    "    plt.title(num_of_sensor[i])\n",
    "    plt.subplot(4,1,2)\n",
    "    plt.plot(freq_17_mean[i],A_sensors_17_mean[i],label=  'Amplitudes - mean value padding')\n",
    "    plt.plot(freq_17[i],A_sensors_17[i],label=  'Amplitudes - without padding')\n",
    "    plt.yscale('log')\n",
    "    plt.ylabel('Amplitudes ');\n",
    "    plt.legend()\n",
    "    plt.subplot(4,1,3)\n",
    "    plt.plot(freq_17_last[i],A_sensors_17_last[i],label=  'Amplitudes - last element padding')\n",
    "    plt.plot(freq_17[i],A_sensors_17[i],label=  'Amplitudes - without padding')\n",
    "    plt.yscale('log')\n",
    "    plt.subplot(4,1,4)\n",
    "    plt.plot(freq_17_spl[i],A_sensors_17_spl[i],label=  'Amplitudes - spline interpolation')\n",
    "    plt.plot(freq_17[i],A_sensors_17[i],label=  'Amplitudes - without padding')\n",
    "    plt.xlabel('Frequencies [Hz]')\n",
    "    plt.yscale('log')\n",
    "    plt.ylabel('Amplitudes ' );\n",
    "    plt.legend()\n",
    "\n",
    "interact(overview_amplitudes,i=widgets.IntSlider(min=0, max=24, step=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effect of padding with some values will also be checked through rescaling DFT values with (1/(cycle_length * 0.01)), where cycle_length corresponds to the number of points for every signal (its length) and 0.01 represents the sampling period of 0.01s. Comparisons for different cases of padding will be shown on the joint and separate plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sensors_17_zero_scaled=[None]*len(sensors_last)\n",
    "A_sensors_17_last_scaled=[None]*len(sensors_last)\n",
    "A_sensors_17_mean_scaled=[None]*len(sensors_last)\n",
    "A_sensors_17_scaled=[None]*len(sensors_last)\n",
    "A_sensors_17_spl_scaled=[None]*len(sensors_spl)\n",
    "\n",
    "for k in range(len(sensors_mean)):\n",
    "    A_sensors_17_spl_scaled[k]=A_sensors_17_spl[k]*(1/(0.01*cycle_length[17]))\n",
    "    A_sensors_17_zero_scaled[k]=A_sensors_17_zero[k]*(1/(0.01*cycle_length[17]))\n",
    "    A_sensors_17_last_scaled[k]=A_sensors_17_last[k]*(1/(0.01*cycle_length[17]))\n",
    "    A_sensors_17_mean_scaled[k]=A_sensors_17_mean[k]*(1/(0.01*cycle_length[17]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "font = {'family' : 'Times New Roman', 'weight' : 'normal', 'size'   : 20}\n",
    "mpl.rcParams['figure.figsize'] = (25,25)\n",
    "mpl.rc('font', **font)\n",
    "def overview_amplitudes_scaled(i):\n",
    "    plt.subplot(4,1,1)\n",
    "    plt.plot(freq_17[i],A_sensors_17[i],label=  'Amplitudes - without padding')\n",
    "    plt.plot(freq_17_zero[i],A_sensors_17_zero_scaled[i], label=  'Amplitudes - zero padding')\n",
    "    plt.plot(freq_17_mean[i],A_sensors_17_mean_scaled[i], label='Amplitudes - mean element padding' )\n",
    "    plt.plot(freq_17_last[i],A_sensors_17_last_scaled[i], label='Amplitudes - last element padding' )\n",
    "    plt.plot(freq_17_spl[i],A_sensors_17_spl_scaled[i], label=  'Amplitudes - spline interpolation')\n",
    "    plt.yscale('log')\n",
    "    plt.ylabel('Amplitudes');\n",
    "    num_of_sensor=list(parts[0].columns.values)\n",
    "    plt.title(num_of_sensor[i])\n",
    "    plt.legend()\n",
    "    plt.xlabel('Frequencies [Hz]')\n",
    "interact(overview_amplitudes_scaled,i=widgets.IntSlider(min=0, max=24, step=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "font = {'family' : 'Times New Roman', 'weight' : 'normal', 'size'   : 20}\n",
    "mpl.rcParams['figure.figsize'] = (25,25)\n",
    "mpl.rc('font', **font)\n",
    "def overview_amplitudes(i):\n",
    "\n",
    "    num_of_sensor=list(parts[0].columns.values)\n",
    "    \n",
    "    plt.subplot(4,1,1)\n",
    "    plt.plot(freq_17_zero[i],A_sensors_17_zero_scaled[i],label=  'Amplitudes - zero padding')\n",
    "    plt.plot(freq_17[i],A_sensors_17[i],label=  'Amplitudes - without padding')\n",
    "    plt.yscale('log')\n",
    "    plt.ylabel('Amplitudes ');\n",
    "    plt.title(num_of_sensor[i])\n",
    "    plt.legend()\n",
    "    plt.subplot(4,1,2)\n",
    "    plt.plot(freq_17_mean[i],A_sensors_17_mean_scaled[i],label=  'Amplitudes - mean value padding')\n",
    "    plt.plot(freq_17[i],A_sensors_17[i],label=  'Amplitudes - without padding')\n",
    "    plt.yscale('log')\n",
    "    plt.ylabel('Amplitudes ');\n",
    "    plt.legend()\n",
    "    plt.subplot(4,1,3)\n",
    "    plt.plot(freq_17_last[i],A_sensors_17_last_scaled[i],label=  'Amplitudes - last element padding')\n",
    "    plt.plot(freq_17[i],A_sensors_17[i],label=  'Amplitudes - without padding')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.subplot(4,1,4)\n",
    "    plt.plot(freq_17_spl[i],A_sensors_17_spl_scaled[i],label=  'Amplitudes - spline interpolation')\n",
    "    plt.plot(freq_17[i],A_sensors_17[i],label=  'Amplitudes - without padding')\n",
    "    plt.xlabel('Frequencies [Hz]')\n",
    "    plt.yscale('log')\n",
    "    plt.ylabel('Amplitudes ' );\n",
    "    plt.legend()\n",
    "interact(overview_amplitudes,i=widgets.IntSlider(min=0, max=24, step=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, it is visible that padding with last element and the mean value are similar can give reasonable results in comparison to the case without padding. Zero padding has less chance to be chosen. Still, we want to choose only one case. Because of that, 200 of the highest amplitudes from the frequency domain of shortest time signal in:\n",
    "\n",
    "a) its original length\n",
    "\n",
    "b) length with zeros added at the end\n",
    "\n",
    "c) length with mean value added at the end\n",
    "\n",
    "d) length with last element value added at the end\n",
    "\n",
    "will be extracted.\n",
    "\n",
    "Note that frequency bins in a) differ from frequency bins in b), c) and d). The number 200 has been chosen as an arbitrary number. It can be user-defined.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `sort_amplitudes` will sort all the amplitudes and return number *N* of highest amplitudes for all cases of 17th cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_amplitudes (amplitudes,N):\n",
    "    Sorted_amplitudes=np.argsort(amplitudes)[::-1]\n",
    "    N_highest_amplitudes= amplitudes[Sorted_amplitudes[:N]]\n",
    "\n",
    "    return N_highest_amplitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_highest_amplitudes_17=[None]*len(sensors)\n",
    "N_highest_amplitudes_17_zero=[None]*len(sensors_zero)\n",
    "N_highest_amplitudes_17_mean=[None]*len(sensors_mean)\n",
    "N_highest_amplitudes_17_last=[None]*len(sensors_last)\n",
    "N_highest_amplitudes_17_spl=[None]*len(sensors_spl)\n",
    "for i in range(len(sensors)):\n",
    "    N_highest_amplitudes_17[i]= sort_amplitudes(A_sensors_17[i],200)\n",
    "    N_highest_amplitudes_17_zero[i]= sort_amplitudes(A_sensors_17_zero[i],200)\n",
    "    N_highest_amplitudes_17_mean[i]=sort_amplitudes(A_sensors_17_mean[i],200)\n",
    "    N_highest_amplitudes_17_last[i]=sort_amplitudes(A_sensors_17_last[i],200)\n",
    "    N_highest_amplitudes_17_spl[i]=sort_amplitudes(A_sensors_17_spl[i],200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest amplitudes for 17th cycle of all sensors are presented in the plot below. We can see that neither of padding cases perfectly matches the highest amplitudes without padding, but last element padding looks like the most similar. Because of that, it will be choosen as the way of creating the same length of time signals for all sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "font = {'family' : 'Times New Roman', 'weight' : 'normal', 'size'   : 20}\n",
    "mpl.rcParams['figure.figsize'] = (20,25)\n",
    "mpl.rc('font', **font)\n",
    "def amplitudes_zero(i):\n",
    "    num_of_sensor=list(parts[0].columns.values)\n",
    "    plt.plot(np.arange(200),(N_highest_amplitudes_17[i]),label=\"Amplitudes - without padding\" )\n",
    "    plt.ylabel(\"Amplitudes\") \n",
    "    plt.title(num_of_sensor[i])\n",
    "    plt.plot(np.arange(200),(N_highest_amplitudes_17_zero[i]),label=\"Amplitudes - zero padding\")\n",
    "\n",
    "    plt.plot(np.arange(200),(N_highest_amplitudes_17_mean[i]),label=\"Amplitudes mean value padding\")\n",
    "\n",
    "    plt.plot(np.arange(200),(N_highest_amplitudes_17_last[i]),label=\"Amplitudes - last element padding\")\n",
    "    plt.plot(np.arange(200),(N_highest_amplitudes_17_spl[i]),label=\"Amplitudes - spline\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "interact(amplitudes_zero,i=widgets.IntSlider(min=0, max=24, step=1))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the padding with the value of last element of time domain signals, Fourier transform for all sensors and cycles will be performed. This will result with amplitudes, phases and their uncertainties. For simplicity, the focus will be on the amplitudes and their standard squared uncertainties.  \n",
    "\n",
    "After that, two ways of extracting 200 amplitudes will be presented. One way is to sort all the columns of amplitudes (corresponding to the frequency bins) in descending order and to extract 200 of the highest ones. \n",
    "\n",
    "The second approach is to perform Pearson correlation between these columns and one column of measured data and to choose the columns with highest correlation coefficients. This approach will be explained in details later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyDynamic.uncertainty.propagate_DFT import Time2AmpPhase_multi\n",
    "A=[None]*len(sensors_last)\n",
    "UAP=[None]*len(sensors_last)\n",
    "for i in range(len(sensors_last)):\n",
    "    A[i],_,UAP[i]=Time2AmpPhase_multi(sensors_last[i],np.ones(sensors_last[i].shape[0])*sigma**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data will be written to the .hdf5 file in order to avoid long-lasting calculation everytime when the Jupyter Notebook is opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "hf_a = h5py.File('Amplitudes.hdf5', 'w')\n",
    "hf_uap=h5py.File('Uncertainties.hdf5', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sensors_last)):\n",
    "    hf_a[\"A_df\"+str(i)]=A_df[i]\n",
    "    hf_uap[\"UAP\"+str(i)]=UAP_df[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_a.close()\n",
    "hf_uap.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
