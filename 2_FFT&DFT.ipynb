{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#  Feature extraction using Best Fourier Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Before usage of this notebook, please download folder from this link https://drive.google.com/open?id=1Eme87KqRZx8-sANpoHeCIOOWcSRYsMLy\n",
    "and store the files in the same folder which is location for this notebook.\n",
    "It is also necessary to install pip in your environment and using this, package PyDynamic:*\n",
    "\n",
    "pip install PyDynamic\n",
    "\n",
    "*In order to see interactive diagrams, write:* \n",
    "\n",
    "pip install ipywidgets\n",
    "\n",
    "jupyter nbextension enable --py widgetsnbextension   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Importing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py                                     # Importing the h5 package.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import PyDynamic  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.79'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PyDynamic import __version__ as version\n",
    "version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "    Input matrices have dimensions: (2000, 6291), where 2000 represents number of measurements in time\n",
      "    and 6291 represents number of cycles.\n"
     ]
    }
   ],
   "source": [
    "filename = 'Sensor_data_2kHz.h5'                # Data filename.\n",
    "f = h5py.File(filename, 'r')                    # Importing the h5 file. \n",
    "\n",
    "#print(\"Keys: %s\" % f.keys())\n",
    "a_group_key = list(f.keys())[0]\n",
    "\n",
    "data = list(f[a_group_key])                     # Transforming data into list\n",
    "\n",
    "sensorADC=[]                                       # Initialising a list \"sensor\" and\n",
    "for i in range(11):                                # Filling it with data from all sensors \n",
    "    sensorADC.append(pd.DataFrame(data[i][:][:]))\n",
    "\n",
    "for i in range(11):                             \n",
    "    sensorADC[i]=sensorADC[i].iloc[:,:6291]           # Cuting the last cycle because it contains all zero elements.\n",
    "\n",
    "print(\"\"\"    \n",
    "    Input matrices have dimensions: %s, where %s represents number of measurements in time\n",
    "    and %s represents number of cycles.\"\"\" % (np.shape(sensorADC[0]),np.shape(sensorADC[0])[0],np.shape(sensorADC[0])[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting into SI units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset=[0, 0, 0, 0, 0.00488591, 0.00488591, 0.00488591,  0.00488591, 1.36e-2, 1.5e-2, 1.09e-2]\n",
    "gain=[5.36e-9, 5.36e-9, 5.36e-9, 5.36e-9, 3.29e-4, 3.29e-4, 3.29e-4, 3.29e-4, 8.76e-5, 8.68e-5, 8.65e-5]\n",
    "b=[1, 1, 1, 1, 1, 1, 1, 1, 5.299641744, 5.299641744, 5.299641744]\n",
    "k=[250, 1, 10, 10, 1.25, 1, 30, 0.5, 2, 2, 2]\n",
    "units=['[Pa]', '[g]', '[g]', '[g]', '[kN]', '[bar]', '[mm/s]', '[A]', '[A]', '[A]', '[A]']\n",
    "\n",
    "sensor=[0]*len(sensorADC)\n",
    "\n",
    "for i in range(len(sensorADC)):\n",
    "    sensor[i]=((sensorADC[i]*gain[i])+offset[i])*b[i]*k[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sensor=pd.read_csv(r'C:\\Users\\jugo01\\Desktop\\sensor_units.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### If you have problems with previous step, you can skip conversion into SI units by runing next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor=sensorADC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading of train and test data\n",
    "*Note: see 2_Machine_Learning_using_Best_Fourier_Coefficients.ipynb. Data were split into train and test data for k=85% \n",
    "Based on this, target_train_vector and target_test_vector were provided. These vectors will be used for FFT and DFT methods.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "train_test1= h5py.File(\"Train_test_data_split\",\"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train_vector=train_test1[\"target_train_vector\"]\n",
    "target_test_vector=train_test1[\"target_test_vector\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting arrays into data frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train_vector=pd.DataFrame(target_train_vector)\n",
    "target_test_vector=pd.DataFrame(target_test_vector)\n",
    "target=list(target_train_vector[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So, after this step main data to work on are lists: \n",
    "\n",
    "\"sensor_train\" with their class labels \"train_target\"\n",
    " \n",
    "and \n",
    " \n",
    "\"sensor_test\" with their class labels \"test_target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning data for one sensor has dimensions:  (2000, 5347) ,      ('sensor_train') \n",
      "and it's target vector has length:  (5347, 1) ,               ('target_train_vector') \n",
      "\n",
      "Testing data for one sensor has dimensions:  (2000, 944) ,      ('sensor_test') \n",
      "and it's target vector has length:  (944, 1) ,        ('target_test_vector') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sensor_train=[0]*11\n",
    "sensor_test=[0]*11\n",
    "\n",
    "for i in range(11):\n",
    "    sensor_train[i]=sensor[i].loc[:,target_train_vector.index]\n",
    "\n",
    "print(\"Traning data for one sensor has dimensions: \", sensor_train[10].shape,\",      ('sensor_train') \")\n",
    "print(\"and it's target vector has length: \", target_train_vector.shape,\",               ('target_train_vector') \\n\")\n",
    "\n",
    "for i in range(11):\n",
    "    sensor_test[i]=sensor[i].loc[:,target_test_vector.index]\n",
    "\n",
    "print(\"Testing data for one sensor has dimensions: \", sensor_test[10].shape,\",      ('sensor_test') \")\n",
    "print(\"and it's target vector has length: \", target_test_vector.shape,\",        ('target_test_vector') \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at the data from one sensor after splitting for better understanding of structure for next steps. Number of rows is 2000 and each column is one random measurement cycle. Table shows only first five samples in time (five rows) for each cycle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5337</th>\n",
       "      <th>5338</th>\n",
       "      <th>5339</th>\n",
       "      <th>5340</th>\n",
       "      <th>5341</th>\n",
       "      <th>5342</th>\n",
       "      <th>5343</th>\n",
       "      <th>5344</th>\n",
       "      <th>5345</th>\n",
       "      <th>5346</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-39063.942315</td>\n",
       "      <td>26382.866380</td>\n",
       "      <td>111982.576300</td>\n",
       "      <td>123270.310519</td>\n",
       "      <td>5677.152553</td>\n",
       "      <td>63769.945966</td>\n",
       "      <td>-3355.708400</td>\n",
       "      <td>-11744.367810</td>\n",
       "      <td>3214.094226</td>\n",
       "      <td>22705.143489</td>\n",
       "      <td>...</td>\n",
       "      <td>-131018.791877</td>\n",
       "      <td>245701.247597</td>\n",
       "      <td>157393.159350</td>\n",
       "      <td>137924.235069</td>\n",
       "      <td>37357.356543</td>\n",
       "      <td>80615.284770</td>\n",
       "      <td>106164.879171</td>\n",
       "      <td>267842.150619</td>\n",
       "      <td>120640.850337</td>\n",
       "      <td>270518.911042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10194.702045</td>\n",
       "      <td>46487.991618</td>\n",
       "      <td>55068.146065</td>\n",
       "      <td>2030.126987</td>\n",
       "      <td>34201.705127</td>\n",
       "      <td>72558.720950</td>\n",
       "      <td>40693.962606</td>\n",
       "      <td>49094.027868</td>\n",
       "      <td>211884.995913</td>\n",
       "      <td>80838.678771</td>\n",
       "      <td>...</td>\n",
       "      <td>-162996.179298</td>\n",
       "      <td>333922.058733</td>\n",
       "      <td>260720.437349</td>\n",
       "      <td>223240.938268</td>\n",
       "      <td>36031.231549</td>\n",
       "      <td>154570.342483</td>\n",
       "      <td>321749.537589</td>\n",
       "      <td>476838.443610</td>\n",
       "      <td>282414.941920</td>\n",
       "      <td>521374.626098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66179.322909</td>\n",
       "      <td>-117858.502291</td>\n",
       "      <td>12318.400034</td>\n",
       "      <td>15189.662759</td>\n",
       "      <td>67890.355293</td>\n",
       "      <td>-160840.472258</td>\n",
       "      <td>45730.518382</td>\n",
       "      <td>25558.142425</td>\n",
       "      <td>137603.745729</td>\n",
       "      <td>105958.823904</td>\n",
       "      <td>...</td>\n",
       "      <td>-275930.554523</td>\n",
       "      <td>159220.818206</td>\n",
       "      <td>58490.195520</td>\n",
       "      <td>43295.397976</td>\n",
       "      <td>-56084.843536</td>\n",
       "      <td>55139.127761</td>\n",
       "      <td>293371.890093</td>\n",
       "      <td>407325.108931</td>\n",
       "      <td>127009.541544</td>\n",
       "      <td>161337.248743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30473.015521</td>\n",
       "      <td>-61092.677988</td>\n",
       "      <td>197316.095058</td>\n",
       "      <td>67776.093548</td>\n",
       "      <td>141726.141413</td>\n",
       "      <td>51067.908648</td>\n",
       "      <td>-76087.032276</td>\n",
       "      <td>78415.348230</td>\n",
       "      <td>27924.757412</td>\n",
       "      <td>173708.531802</td>\n",
       "      <td>...</td>\n",
       "      <td>9485.618630</td>\n",
       "      <td>228713.438385</td>\n",
       "      <td>150501.084189</td>\n",
       "      <td>222896.005034</td>\n",
       "      <td>51973.964254</td>\n",
       "      <td>8814.342380</td>\n",
       "      <td>277226.063200</td>\n",
       "      <td>502323.444198</td>\n",
       "      <td>213967.458111</td>\n",
       "      <td>365980.188068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25058.467073</td>\n",
       "      <td>-32915.559673</td>\n",
       "      <td>42260.618178</td>\n",
       "      <td>16534.709886</td>\n",
       "      <td>68051.951320</td>\n",
       "      <td>-161081.305465</td>\n",
       "      <td>-109702.711669</td>\n",
       "      <td>90143.575353</td>\n",
       "      <td>116359.464423</td>\n",
       "      <td>28532.851905</td>\n",
       "      <td>...</td>\n",
       "      <td>-19899.218342</td>\n",
       "      <td>285695.180368</td>\n",
       "      <td>223312.909029</td>\n",
       "      <td>193983.151309</td>\n",
       "      <td>100914.999644</td>\n",
       "      <td>113175.019174</td>\n",
       "      <td>373612.604321</td>\n",
       "      <td>569405.884757</td>\n",
       "      <td>184366.334327</td>\n",
       "      <td>404601.150396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5347 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0              1              2              3              4     \\\n",
       "0 -39063.942315   26382.866380  111982.576300  123270.310519    5677.152553   \n",
       "1  10194.702045   46487.991618   55068.146065    2030.126987   34201.705127   \n",
       "2  66179.322909 -117858.502291   12318.400034   15189.662759   67890.355293   \n",
       "3  30473.015521  -61092.677988  197316.095058   67776.093548  141726.141413   \n",
       "4  25058.467073  -32915.559673   42260.618178   16534.709886   68051.951320   \n",
       "\n",
       "            5              6             7              8              9     \\\n",
       "0   63769.945966   -3355.708400 -11744.367810    3214.094226   22705.143489   \n",
       "1   72558.720950   40693.962606  49094.027868  211884.995913   80838.678771   \n",
       "2 -160840.472258   45730.518382  25558.142425  137603.745729  105958.823904   \n",
       "3   51067.908648  -76087.032276  78415.348230   27924.757412  173708.531802   \n",
       "4 -161081.305465 -109702.711669  90143.575353  116359.464423   28532.851905   \n",
       "\n",
       "   ...           5337           5338           5339           5340  \\\n",
       "0  ... -131018.791877  245701.247597  157393.159350  137924.235069   \n",
       "1  ... -162996.179298  333922.058733  260720.437349  223240.938268   \n",
       "2  ... -275930.554523  159220.818206   58490.195520   43295.397976   \n",
       "3  ...    9485.618630  228713.438385  150501.084189  222896.005034   \n",
       "4  ...  -19899.218342  285695.180368  223312.909029  193983.151309   \n",
       "\n",
       "            5341           5342           5343           5344           5345  \\\n",
       "0   37357.356543   80615.284770  106164.879171  267842.150619  120640.850337   \n",
       "1   36031.231549  154570.342483  321749.537589  476838.443610  282414.941920   \n",
       "2  -56084.843536   55139.127761  293371.890093  407325.108931  127009.541544   \n",
       "3   51973.964254    8814.342380  277226.063200  502323.444198  213967.458111   \n",
       "4  100914.999644  113175.019174  373612.604321  569405.884757  184366.334327   \n",
       "\n",
       "            5346  \n",
       "0  270518.911042  \n",
       "1  521374.626098  \n",
       "2  161337.248743  \n",
       "3  365980.188068  \n",
       "4  404601.150396  \n",
       "\n",
       "[5 rows x 5347 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_train[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  Fast Fourier transform\n",
    "\n",
    "###### Steps:  \n",
    "    \n",
    "- transformation into frequency domain (FFT)\n",
    "- choose amplitudes with highest average absolute value (the top 10%)\n",
    "\n",
    "\n",
    "In this method of feature extraction, data is transformed into frequency domain using FFT function for discrete Fourier transform. More detail about FFT in [1_FFT_and_Reconstruction.ipynb](1_FFT_and_Reconstruction.ipynb)\n",
    "\n",
    "This step an unsupervised extraction method (i.e. is done without knowledge of the cycle‘s group affiliation) and used is to reduce dimension for further steps.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### A function is created, which takes as input: \n",
    "- data from one sensor `sensor`,                                 \n",
    "- number of samples `n_of_samples`,                                    \n",
    "- percentage of data to choose `N`.\n",
    "\n",
    "Function does fast Fourier transform and chooses N% of sprectrum with highest average of absolute values for each sensor independently. Average of absolute values for one frequency is calculated through all cycles.                                   \n",
    "\n",
    "\n",
    "###### Function returns:\n",
    "- `freq_of_sorted_values` matrix sized [1, N% of features (amplitudes)] where elements are frequencies which are choosen and they are labels for second output from this function.\n",
    "- `sorted_values_matrix` sized [number of cycles, N% of features (amplitudes)] where row represents one cycle and columns are sorted by the average of absolute vales for each frequency (column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseAndReturnOrdered(sensor, n_of_samples, N): \n",
    "    x_measurements=range(sensor.shape[0])                 # Number of measurements samples in time period.\n",
    "    x = np.true_divide(x_measurements, n_of_samples)      # Time values, used  as real time axis.\n",
    "    freq = np.fft.rfftfreq(x.size, 0.0005)                # Frequency axis, can be used for ploting in frequency domain.\n",
    "    fft_amplitudes = np.fft.rfft(sensor,n_of_samples,0)   # Ndarray of amplitudes after fourier transform.\n",
    "    fft_matrix = pd.DataFrame(fft_amplitudes)             # Transforming amplitudes into data frame (matrix)-\n",
    "                                                          # -where one column represents amplitudes of one-\n",
    "                                                          # -cycle.\n",
    "    fft_matrix=fft_matrix.transpose()                     # Transposing to matrix where rows are cycles.\n",
    "    n_rows, n_columns = np.shape(fft_matrix)\n",
    "\n",
    "    print(\"\\nNumber of cycles is: %s, and number of features is: %s\" % (n_rows, n_columns))\n",
    "    fft_matrix.columns = freq                    # Column labels are frequencies. \n",
    "    \n",
    "    # Calculating the average of absolute vales for each frequency (column).\n",
    "    absolute_average_values_from_columns=(np.abs(fft_matrix)).mean()\n",
    "    \n",
    "    # Sorting the fft_matrix by the average of absolute vales for each frequency (column).\n",
    "    fft_matrix=fft_matrix.reindex((np.abs(fft_matrix)).mean().sort_values(ascending=False).index, axis=1)\n",
    "    \n",
    "    # Taking first N percent columns from sorted fft_matrix. \n",
    "    sorted_values_matrix=fft_matrix.iloc[:,:round((N/100.0)*len(freq))]\n",
    "    \n",
    "    n_rows, n_columns = np.shape(sorted_values_matrix)\n",
    "    print(\"\\nNumber of cycles is: %s, and number of selected features is: %s\" % (n_rows, n_columns))\n",
    "    print(np.shape(sorted_values_matrix))\n",
    "    \n",
    "    # Informations about the selected frequencies are columns in sorted data frame. \n",
    "    freq_of_sorted_values=(pd.DataFrame(sorted_values_matrix.columns)).transpose()\n",
    "    print(\"\\nFirst 10 selected frequencies are:\\n\\n %s\" % freq_of_sorted_values.values[:,:10])\n",
    "    \n",
    "    sorted_values_matrix.columns=range(round((N/100.0)*len(freq))) # Resetting the column labels.\n",
    "    print(\"---------------------------------------------------------------------------------\\n\")\n",
    "    # Output \"sorted_values_matrix\" is data frame whose rows-\n",
    "    # -are cycles and columns are selected frequencies. For example,- \n",
    "    # -value at position (i,j) is amplitude for frequency j in cycle i.\n",
    "    \n",
    "    return freq_of_sorted_values, sorted_values_matrix;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###### Function execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Instead of executing the function, results of extracting 10% of highest amplitudes by FFT can be read in the next steps. Values were obtained by using factor of splitting data into train and test from the above.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "amp_fft1= h5py.File(\"Sorted_vaules_from_all_sensors.hdf5\",\"r\")\n",
    "freq_fft1= h5py.File(\"Sorted_freq_from_all_sensors.hdf5\",\"r\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_of_sorted_values=[0]*len(sensor_train)\n",
    "sorted_values_from_all_sensors=[0]*len(sensor_train)\n",
    "for i in range(len(sensor)):\n",
    "    freq_of_sorted_values[i]=freq_fft1[\"freq_of_sorted_values\"+str(i)]\n",
    "    sorted_values_from_all_sensors[i]=amp_fft1[\"sorted_values_from_all_sensors\"+str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sensor)):\n",
    "    freq_of_sorted_values[i]=pd.DataFrame( freq_of_sorted_values[i])\n",
    "    sorted_values_from_all_sensors[i]=pd.DataFrame( sorted_values_from_all_sensors[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User is asked to define how many of features from frequency domain will be extracted in this step. Then, the function is executed for each sensor and extracted data is stored in 2 lists containing data frames mentioned above. Lists `freq_of_sorted_values` and `sorted_values_from_all_sensors` store function outputs and further selection of features is continued on list `sorted_values_from_all_sensors`. Informations about frequency are going to be used in for feature extraction from testing data, because these frequencies are pattern learned from training data and used for selecting from the testing data or some new data which need to be predicted. \n",
    "For all sensors, selected frequencies with most dominant amplitudes are listed as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal and recommended percentage of features for this dataset is 10. \n",
      "\n",
      "Enter a percentage of features: 10\n",
      "\n",
      "\n",
      "\n",
      "Sensor number 0\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Number of cycles is: 5347, and number of features is: 1001\n",
      "\n",
      "Number of cycles is: 5347, and number of selected features is: 100\n",
      "(5347, 100)\n",
      "\n",
      "First 10 selected frequencies are:\n",
      "\n",
      " [[480.   0.  85. 640. 100. 120.   1.   2.   3. 121.]]\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Sensor number 1\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Number of cycles is: 5347, and number of features is: 1001\n",
      "\n",
      "Number of cycles is: 5347, and number of selected features is: 100\n",
      "(5347, 100)\n",
      "\n",
      "First 10 selected frequencies are:\n",
      "\n",
      " [[480.  80.  79. 479.   2. 481.  78.   0. 120.  77.]]\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Sensor number 2\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Number of cycles is: 5347, and number of features is: 1001\n",
      "\n",
      "Number of cycles is: 5347, and number of selected features is: 100\n",
      "(5347, 100)\n",
      "\n",
      "First 10 selected frequencies are:\n",
      "\n",
      " [[161. 162. 120. 163. 160. 406. 819. 826. 413. 820.]]\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Sensor number 3\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Number of cycles is: 5347, and number of features is: 1001\n",
      "\n",
      "Number of cycles is: 5347, and number of selected features is: 100\n",
      "(5347, 100)\n",
      "\n",
      "First 10 selected frequencies are:\n",
      "\n",
      " [[640. 819. 823. 824. 825. 818. 821. 820. 822. 826.]]\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Sensor number 4\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Number of cycles is: 5347, and number of features is: 1001\n",
      "\n",
      "Number of cycles is: 5347, and number of selected features is: 100\n",
      "(5347, 100)\n",
      "\n",
      "First 10 selected frequencies are:\n",
      "\n",
      " [[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]]\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Sensor number 5\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Number of cycles is: 5347, and number of features is: 1001\n",
      "\n",
      "Number of cycles is: 5347, and number of selected features is: 100\n",
      "(5347, 100)\n",
      "\n",
      "First 10 selected frequencies are:\n",
      "\n",
      " [[ 0.  1.  6.  5.  7.  2.  4.  8.  3. 13.]]\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Sensor number 6\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Number of cycles is: 5347, and number of features is: 1001\n",
      "\n",
      "Number of cycles is: 5347, and number of selected features is: 100\n",
      "(5347, 100)\n",
      "\n",
      "First 10 selected frequencies are:\n",
      "\n",
      " [[  0. 640. 999. 998. 996. 997. 993. 995. 994. 992.]]\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Sensor number 7\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Number of cycles is: 5347, and number of features is: 1001\n",
      "\n",
      "Number of cycles is: 5347, and number of selected features is: 100\n",
      "(5347, 100)\n",
      "\n",
      "First 10 selected frequencies are:\n",
      "\n",
      " [[  0. 640.   1.   2. 300.   3.   4.   5. 680.   6.]]\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Sensor number 8\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Number of cycles is: 5347, and number of features is: 1001\n",
      "\n",
      "Number of cycles is: 5347, and number of selected features is: 100\n",
      "(5347, 100)\n",
      "\n",
      "First 10 selected frequencies are:\n",
      "\n",
      " [[240. 880. 400. 239.   0. 241. 238. 540. 242.  60.]]\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Sensor number 9\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Number of cycles is: 5347, and number of features is: 1001\n",
      "\n",
      "Number of cycles is: 5347, and number of selected features is: 100\n",
      "(5347, 100)\n",
      "\n",
      "First 10 selected frequencies are:\n",
      "\n",
      " [[240. 880. 400.   0. 239. 241. 238. 540.  60. 242.]]\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Sensor number 10\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Number of cycles is: 5347, and number of features is: 1001\n",
      "\n",
      "Number of cycles is: 5347, and number of selected features is: 100\n",
      "(5347, 100)\n",
      "\n",
      "First 10 selected frequencies are:\n",
      "\n",
      " [[240. 880. 400.   0. 239. 241. 238. 540. 720.  60.]]\n",
      "---------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_of_samples=np.shape(sensor_train[0])[0]\n",
    "\n",
    "N = int(input(\"Optimal and recommended percentage of features for this dataset is 10. \\n\\nEnter a percentage of features: \"))\n",
    "print(\"\\n\\n\")\n",
    "# Initialising the list woth 11 elements, which are data frames \"sorted_value_matrix\" from each sensor.\n",
    "freq_of_sorted_values=[0]*len(sensor_train)\n",
    "sorted_values_from_all_sensors=[0]*len(sensor_train)\n",
    "\n",
    "for i in range(len(sensor_train)):                     \n",
    "    print(\"Sensor number %s\" % i)\n",
    "    print(\"---------------------------------------------------------------------------------\")\n",
    "    freq_of_sorted_values[i],sorted_values_from_all_sensors[i]=chooseAndReturnOrdered(sensor_train[i], n_of_samples, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features are complex numbers, because output from the Fourier transform is resulting with amplitudes and phase shifts. For methods used here, amplitudes are more important than phase shifts, and features that will be used are absolute values of amplitudes  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Example of frequency labels for features extracted from microphone with the best Fourier coefficients method._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example. We will take first sensor, which is microphone, as an example. The most dominant frequancy for microphone is 0 Hz, and then 480 Hz. That can be seen in `freq_of_sorted_values[0]`. First two columns in `sorted_values_from_all_sensors[0]` are  amplitudes through all measurement cycles for frequencies 0 and 480 Hz, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1     2      3      4      5    6    7    8      9   ...     90  \\\n",
       "0  480.0  0.0  85.0  640.0  100.0  120.0  1.0  2.0  3.0  121.0  ...  128.0   \n",
       "\n",
       "      91     92     93    94     95     96    97    98     99  \n",
       "0  149.0  803.0  759.0  68.0  802.0  837.0  91.0  79.0  117.0  \n",
       "\n",
       "[1 rows x 100 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_of_sorted_values[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START\n",
    "### Discrete Fourier Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to include uncertainties in features extraction using BFC, the following is going to be conducted:\n",
    "    \n",
    "- transformation into frequency domain (DFT)\n",
    "- extraction of amplitudes with highest average absolute value (the top 10%), with corresponding phases and uncertainties\n",
    "\n",
    "The results of DFT are obtained by using function `Time2AmpPhase_multi`. Function is executed with uncertainties presented in sparse matrix in order to avoid memory errors during calculation for high number of cycles.The usage of sparse matrix is possible since most of covariance values are zeros. \n",
    "\n",
    "###### Function returns:\n",
    "- ` A` np.ndarray sized (M,N) where elements are amplitudes of time domain signals of length N in frequency domain for M cycles. \n",
    "- ` P` np.ndarray sized (M,N) where elements are phases of time domain signals of length N in frequency domain for M cycles. \n",
    "-  `UAP`np.ndarray sized (M, 3N) where elements are squared standard uncertainties of amplitudes and phases and their covariances for M cycles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PyDynamic.uncertainty.propagate_DFT import GUM_DFT\n",
    "from PyDynamic.uncertainty.propagate_DFT import DFT2AmpPhase\n",
    "def Time2AmpPhase_multi(x, Ux, selector=None):\n",
    "    #\"\"\"Transformation from time domain to amplitude and phase for a set of M signals of the same type\n",
    "    # Parameters\n",
    "    # x: np.ndarray of shape (M,N)\n",
    "    # M time domain signals of length N\n",
    "    # Ux: np.ndarray of shape (M,)\n",
    "    # squared standard deviations representing noise variances of the signals x\n",
    "    # selector: np.ndarray of shape (L,), optional\n",
    "    # indices of amplitude and phase values that should be returned; default is 0:N-1\n",
    "    # Returns\n",
    "    \n",
    "    # A: np.ndarray of shape (M,N)\n",
    "    # amplitude values\n",
    "    # P: np.ndarray of shape (M,N)\n",
    "    # phase values\n",
    "    # UAP: np.ndarray of shape (M, 3N)\n",
    "    # diagonals of the covariance matrices: [diag(UPP), diag(UAA), diag(UPA)]\n",
    "    \n",
    "    M, nx = x.shape\n",
    "    assert(len(Ux)==M)\n",
    "    N = nx//2+1\n",
    "    if not isinstance(selector, np.ndarray):\n",
    "        selector = np.arange(nx//2+1)\n",
    "    ns = len(selector)\n",
    "\n",
    "    A = np.zeros((M,ns))\n",
    "    P = np.zeros_like(A)\n",
    "    UAP = np.zeros((M, 3*ns))\n",
    "    CxCos = None\n",
    "    CxSin = None\n",
    "    for m in range(M):\n",
    "        F, UF, CX = GUM_DFT(x[m,:], Ux[m], CxCos, CxSin, returnC=True)\n",
    "        CxCos = CX[\"CxCos\"]\n",
    "        CxSin = CX[\"CxSin\"]\n",
    "        A_m, P_m, UAP_m = DFT2AmpPhase(F, UF, keep_sparse=True)\n",
    "        A[m,:] = A_m[selector]\n",
    "        P[m,:] = P_m[selector]\n",
    "        UAP[m,:ns] = UAP_m.data[0][:N][selector]\n",
    "        UAP[m,ns:2*ns] = UAP_m.data[1][UAP_m.offsets[1]:2*N+UAP_m.offsets[1]][selector]\n",
    "        UAP[m, 2*ns:] = UAP_m.data[0][N:][selector]\n",
    "        \n",
    "    return A, P, UAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amplitudes are sorted through all cycles and  10% of the highest ones were extracted. Phases and uncertainties are sorted in the way to follow the sorting method for amplitudes. The values are corresponding to the values of 10% chosen amplitudes.\n",
    "###### Function `chooseAndReturnOrdered_with_uncertainty` returns:\n",
    "- `freq_of_sorted_values` matrix sized [1, N% of features (amplitudes)] where elements are frequencies which are choosen and they are labels for second output from this function.\n",
    "- `sorted_values_amp` sized [number of cycles, N% of features (amplitudes)] where row represents one cycle and columns are sorted by the average of absolute values of amplitudes for each frequency (column).\n",
    "- `sorted_values_phases` - sized [number of cycles, N% of features (phases)] where row represents one cycle and columns of phases are sorted by the absolute values of amplitudes  for each frequency (column). \n",
    "- `sorted_values_uncert_aa` - sized [number of cycles, N% of features (uncertainties)] where row represents one cycle and columns of squared standard uncertainties for amplitudes are sorted by the average of absolute vales for each frequency (column). \n",
    "- `sorted_values_uncert_ap` - sized [number of cycles, N% of features (uncertainties)] where row represents one cycle and columns of covariances for amplitudes and phases are sorted by the average of absolute vales for each frequency (column). \n",
    "- `sorted_values_uncert_pp`  - sized [number of cycles, N% of features (uncertainties)] where row represents one cycle and columns of squared standard uncertainties for phases are sorted by the average of absolute vales for each frequency (column). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyDynamic.uncertainty.propagate_DFT import GUM_DFT\n",
    "from PyDynamic.uncertainty.propagate_DFT import DFT2AmpPhase\n",
    "\n",
    "def chooseAndReturnOrdered_with_uncertainty(sensor, n_of_samples, N,sigma):\n",
    "    \n",
    "    x_measurements=range(sensor.shape[0])        \n",
    "    n_of_samples=np.shape(sensor)[0]                            # number of sampling points\n",
    "    x = np.true_divide(x_measurements, n_of_samples)            # time steps \n",
    "    freq=PyDynamic.uncertainty.propagate_DFT.GUM_DFTfreq(x.size, 0.0005)\n",
    "    ux=np.ones(sensor.shape[1])*sigma**2\n",
    "    a,b,c=Time2AmpPhase_multi(sensor.values.transpose(),ux)\n",
    "    a=pd.DataFrame(a) #amplitudes (M,N)\n",
    "    b=pd.DataFrame(b) #phases (M,N)\n",
    "    c=pd.DataFrame(c) #uncertainties (M,3*N)\n",
    "    a.columns = freq                    # Column labels are frequencies. \n",
    "    n_rows, n_columns=a.shape\n",
    "    print(\"\\nNumber of cycles is: %s, and number of features is: %s\" % (n_rows, n_columns))\n",
    "    # Calculating the average of absolute vales for each frequency (column).\n",
    "    absolute_average_values_from_columns=np.abs(a.mean())\n",
    "    # Sorting column indices in amplitudes for sorting phases and uncertainties\n",
    "    sorted_columns=np.argsort(absolute_average_values_from_columns)[::-1]\n",
    "    # Uncertaintites have one dimension larger than amplitudes and phases. # Columns indices(len(a):3*len(a) to follow the sorting)\n",
    "    sorted_columns_unc_ap=(sorted_columns+a.shape[1])\n",
    "    sorted_columns_unc_pp=(sorted_columns+a.shape[1]*2)\n",
    "    sorted_columns_unc=np.concatenate((sorted_columns,sorted_columns_unc_ap,sorted_columns_unc_pp))#sorted indices for uncertainties\n",
    "    # Reindexing all matrices based on columns.\n",
    "    a=a.reindex((np.abs(a)).mean().sort_values(ascending=False).index, axis=1)\n",
    "    b=b.reindex(columns=sorted_columns)\n",
    "    c=c.reindex(columns=sorted_columns_unc)\n",
    "    # Taking first N percent columns from sorted amplitudes,phases and ucertainties. \n",
    "    sorted_values_amp=a.iloc[:,:round((N/100.0)*len(freq))]\n",
    "    sorted_values_phases=b.iloc[:,:round((N/100.0)*len(freq))] \n",
    "    sorted_values_uncert_aa=c.iloc[:,:round((N/100.0)*len(freq))]\n",
    "    sorted_values_uncert_ap=c.iloc[:,len(freq):a.shape[1]+round((N/100.0)*len(freq))]\n",
    "    sorted_values_uncert_pp=c.iloc[:,2*len(freq):a.shape[1]*2+round((N/100.0)*len(freq))]                                             \n",
    "    n_rows, n_columns = np.shape(sorted_values_amp)\n",
    "    print(\"\\nNumber of cycles is: %s, and number of selected features is: %s\" % (n_rows, n_columns))\n",
    "    print(np.shape(sorted_values_amp))\n",
    "    \n",
    "    # Informations about the selected frequencies are columns in sorted data frame. \n",
    "    freq_of_sorted_values=(pd.DataFrame(sorted_values_amp.columns)).transpose()\n",
    "    print(\"\\nFirst 10 selected frequencies are:\\n\\n %s\" % freq_of_sorted_values.values[:,:10])\n",
    "    \n",
    "    # Resetting the column labels.\n",
    "    sorted_values_amp.columns=range(round((N/100.0)*len(freq)))\n",
    "    sorted_values_phases.columns=range(round((N/100.0)*len(freq)))\n",
    "    sorted_values_uncert_aa.columns=range(round((N/100.0)*len(freq)))\n",
    "    sorted_values_uncert_ap.columns=range(round((N/100.0)*len(freq)))\n",
    "    sorted_values_uncert_pp.columns=range(round((N/100.0)*len(freq)))\n",
    "\n",
    "    print(\"---------------------------------------------------------------------------------\\n\")\n",
    "    # Output \"sorted_values_matrix\" is data frame whose rows-\n",
    "    # -are cycles and columns are selected frequencies. For example,- \n",
    "    # -value at position (i,j) is amplitude for frequency j in cycle i.\n",
    "    return freq_of_sorted_values,sorted_values_amp,sorted_values_phases,sorted_values_uncert_aa,sorted_values_uncert_ap, sorted_values_uncert_pp\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Function execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Instead of executing the function, results of extracting 10% of highest amplitudes by DFT can be read in the next steps. Values were obtained by using factor of splitting data into train and test from the above. Sigma value, representing white noise was assumed as 0.1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "amp_dft2= h5py.File(\"DFTSorted_vaules__from_all_sensors.hdf5\",\"r\")\n",
    "freq_dft2= h5py.File(\"DFTSorted_freq_from_all_sensors.hdf5\",\"r\") \n",
    "ph_dft2= h5py.File(\"DFTSorted_ph_from_all_sensors.hdf5\",\"r\")\n",
    "u_a_dft2= h5py.File(\"DFTSorted_uncer_from_all_sensors_a.hdf5\",\"r\")\n",
    "u_ap_dft2= h5py.File(\"DFTSorted_uncer_from_all_sensors_ap.hdf5\",\"r\")    \n",
    "u_pp_dft2= h5py.File(\"DFTSorted_uncer_from_all_sensors_pp.hdf5\",\"r\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_of_sorted_values=[0]*len(sensor_train)\n",
    "sorted_values__amp_from_all_sensors=[0]*len(sensor_train)\n",
    "sorted_phases_from_all_sensors=[0]*len(sensor_train)\n",
    "sorted_uncer_from_all_sensors_a=[0]*len(sensor_train)\n",
    "sorted_uncer_from_all_sensors_ap=[0]*len(sensor_train)\n",
    "sorted_uncer_from_all_sensors_pp=[0]*len(sensor_train)\n",
    "for i in range(len(sensor)):\n",
    "    freq_of_sorted_values[i]=freq_dft2[\"freq_of_sorted_values\"+str(i)]\n",
    "    sorted_values__amp_from_all_sensors[i]=amp_dft2[\"sorted_values_amp_from_all_sensors\"+str(i)]\n",
    "    sorted_phases_from_all_sensors[i]=ph_dft2[\"sorted_phases_from_all_sensors\"+str(i)]\n",
    "    sorted_uncer_from_all_sensors_a[i]=u_a_dft2[\"sorted_uncer_from_all_sensors_a\"+str(i)]\n",
    "    sorted_uncer_from_all_sensors_ap[i]=u_ap_dft2[\"sorted_uncer_from_all_sensors_ap\"+str(i)]\n",
    "    sorted_uncer_from_all_sensors_pp[i]=u_pp_dft2[\"sorted_uncer_from_all_sensors_pp\"+str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sensor)):\n",
    "    freq_of_sorted_values[i]=pd.DataFrame(freq_of_sorted_values[i])\n",
    "    sorted_values__amp_from_all_sensors[i]=pd.DataFrame(sorted_values__amp_from_all_sensors[i])\n",
    "    sorted_phases_from_all_sensors[i]=pd.DataFrame(sorted_phases_from_all_sensors[i])\n",
    "    sorted_uncer_from_all_sensors_a[i]=pd.DataFrame(sorted_uncer_from_all_sensors_a[i])\n",
    "    sorted_uncer_from_all_sensors_ap[i]=pd.DataFrame(sorted_uncer_from_all_sensors_ap[i])\n",
    "    sorted_uncer_from_all_sensors_pp[i]=pd.DataFrame(sorted_uncer_from_all_sensors_pp[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "User is asked to define how many of features from frequency domain will be extracted in this step. Then, the function is executed for each sensor and extracted data is stored in 6 lists containing data frames mentioned above. Lists:\n",
    "- freq_of_sorted_values \n",
    "- sorted_values__amp_from_all_sensors \n",
    "- sorted_phases_from_all_sensors\n",
    "- sorted_uncer_from_all_sensors_a\n",
    "- sorted_uncer_from_all_sensors_ap\n",
    "- sorted_uncer_from_all_sensors_pp\n",
    "\n",
    "store function outputs and further selection of features is continued  through loop. Informations about frequency are going to be used in for feature extraction from testing data, because these frequencies are pattern learned from training data and used for selecting from the testing data or some new data which need to be predicted. \n",
    "For all sensors, selected frequencies with most dominant amplitudes are listed as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal and recommended percentage of features for this dataset is 10. \n",
      "\n",
      "Enter a percentage of features: 10\n",
      "\n",
      "\n",
      "\n",
      "Assume standard deviation0.1\n",
      "Sensor number 0\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Number of cycles is: 5347, and number of features is: 1001\n",
      "\n",
      "Number of cycles is: 5347, and number of selected features is: 100\n",
      "(5347, 100)\n",
      "\n",
      "First 10 selected frequencies are:\n",
      "\n",
      " [[480.   0.  85. 640. 100. 120.   1.   2.   3. 121.]]\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Sensor number 1\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-aa41461a02f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sensor number %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"---------------------------------------------------------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mfreq_of_sorted_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msorted_values__amp_from_all_sensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msorted_phases_from_all_sensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msorted_uncer_from_all_sensors_a\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msorted_uncer_from_all_sensors_ap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msorted_uncer_from_all_sensors_pp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchooseAndReturnOrdered_with_uncertainty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msensor_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_of_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-3e36c149eaf4>\u001b[0m in \u001b[0;36mchooseAndReturnOrdered_with_uncertainty\u001b[1;34m(sensor, n_of_samples, N, sigma)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPyDynamic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muncertainty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpropagate_DFT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGUM_DFTfreq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0005\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mux\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTime2AmpPhase_multi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mux\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#amplitudes (M,N)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#phases (M,N)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-f2f0d3701ee2>\u001b[0m in \u001b[0;36mTime2AmpPhase_multi\u001b[1;34m(x, Ux, selector)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mCxSin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGUM_DFT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCxCos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCxSin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturnC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mCxCos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"CxCos\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mCxSin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"CxSin\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\Zema\\lib\\site-packages\\PyDynamic\\uncertainty\\propagate_DFT.py\u001b[0m in \u001b[0;36mGUM_DFT\u001b[1;34m(x, Ux, N, window, CxCos, CxSin, returnC, mask)\u001b[0m\n\u001b[0;32m    180\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[1;31m# Block cos/cos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m                                 \u001b[0mUF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkm\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mUx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mCxkc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m                                 \u001b[0mkm\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                 \u001b[0mkm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\Zema\\lib\\site-packages\\PyDynamic\\uncertainty\\propagate_DFT.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(k)\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mN\u001b[0m                         \u001b[1;31m# for simplified calculation of sensivities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         \u001b[0mCxkc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m   \u001b[1;31m# sensitivity matrix wrt cosinus part\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m         \u001b[0mCxks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# sensitivity matrix wrt sinus part\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#function execution\n",
    "n_of_samples=np.shape(sensor_train[0])[0]\n",
    "\n",
    "N = int(input(\"Optimal and recommended percentage of features for this dataset is 10. \\n\\nEnter a percentage of features: \"))\n",
    "print(\"\\n\\n\")\n",
    "sigma=float(input(\"Assume standard deviation\"))\n",
    "# Initialising the list woth 11 elements, which are data frames \"sorted_value_matrix\" from each sensor.\n",
    "                    \n",
    "freq_of_sorted_values=[0]*len(sensor_train)\n",
    "sorted_values__amp_from_all_sensors=[0]*len(sensor_train)\n",
    "sorted_phases_from_all_sensors=[0]*len(sensor_train)\n",
    "sorted_uncer_from_all_sensors_a=[0]*len(sensor_train)\n",
    "sorted_uncer_from_all_sensors_ap=[0]*len(sensor_train)\n",
    "sorted_uncer_from_all_sensors_pp=[0]*len(sensor_train)\n",
    "\n",
    "    \n",
    "for i in range(len(sensor_train)):                     \n",
    "    print(\"Sensor number %s\" % i)\n",
    "    print(\"---------------------------------------------------------------------------------\")\n",
    "    freq_of_sorted_values[i],sorted_values__amp_from_all_sensors[i],sorted_phases_from_all_sensors[i],sorted_uncer_from_all_sensors_a[i],sorted_uncer_from_all_sensors_ap[i],sorted_uncer_from_all_sensors_pp[i]=chooseAndReturnOrdered_with_uncertainty(sensor_train[i], n_of_samples, N,sigma)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_of_sorted_values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: When amplitudes are small relative to the uncertainty associated with real and imaginary parts , the GUM uncertainty propagation becomes unreliable and a Monte Carlo method is recommended instead. Consequently, GUM2DFT does raise a warning to the user and recommends using a Monte Carlo method instead whenever an element of  is below a pre-defined threshold. The default threshold in GUM2DFT is 1.0, but may be adjusted for specific applications.[7]*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview of the results:\n",
    "\n",
    "*Note: Be aware of randomness of splitting data into train and test. Results shown here are for one random split. Functions FFT and DFT were executed for the same split of data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_values__amp_from_all_sensors[0].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_uncer_from_all_sensors_a[0].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_phases_from_all_sensors[0].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_uncer_from_all_sensors_pp[0].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_uncer_from_all_sensors_ap[0].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_of_sorted_values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional: Transformation to time domain for all sensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation from amplitude and phase to time domain is demonstrated with functions `Reconstruct_time_domain` (on the basis of PyDynamic´s function AmpPhase2Time) and `Reconstruct_time_domain_idft`(on the basis of PyDynamic´s functions AmpPhase2DFT, GUM_iDFT).\n",
    "\n",
    "First, zero arrays of amplitudes, phases and uncertainties are created (A, P, UAP). Then, function copies values of N% of arguments (amplitudes, phases, u_a, u_ap, u_pp) into column indices (frequencies) of initial zero arrays. \n",
    "\n",
    "Function `Reconstruct_time_domain`creates sparse matrix from the values contained in matrices of uncertainties for amplitudes, phases and their covariances, because UAP was previously created from the sparse matrix. For each cycle, function returns:  \n",
    "- `x` (np.ndarray ) – vector of time domain values and \n",
    "- `ux` -  (np.ndarray) – covariance matrix associated with x.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.sparse import dia_matrix\n",
    "from PyDynamic.uncertainty.propagate_DFT import AmpPhase2Time\n",
    "\n",
    "def Reconstruct_time_domain(N,frequencies,amplitudes,phases,u_a,u_ap,u_pp):\n",
    "    \n",
    "    M,num=amplitudes.shape\n",
    "    length=int(amplitudes.shape[1])*N+1 \n",
    "    length_2=2*length\n",
    "    length_3=3*length \n",
    "    x=np.zeros((M, length_2-2))\n",
    "    #storing uncertainties in a list of arrays\n",
    "    ux=np.zeros((M, length_2-2))\n",
    "    #predefining A,P,UAP as zero arrays\n",
    "    A =np.zeros((M, length))\n",
    "    P= np.zeros((M, length))\n",
    "    UAP=np.zeros((M, 3*length))\n",
    "    assert(amplitudes.shape==phases.shape)\n",
    "    # Indices of columns with highest amplitudes in original matrix (resulted from DFT) are accessible from the\n",
    "    #sorted frequencies of all sensors\n",
    "    Index_amplitudes=frequencies[:,:N] \n",
    "    # Defining offsets for sparse matrix  \n",
    "    offset_UAP=[0,length,-length]\n",
    "     #indices(columns) of 10% highest amplitude values\n",
    "    Index_amplitudes=Index_amplitudes.astype(int)\n",
    "    col = np.array(Index_amplitudes[0])\n",
    "    #Values of 10% highest amplitudes(first N columns of input amplitudes) are copied in A,P,UAP in corresponding indices \n",
    "    #of columns. Other columns are zeros. \n",
    "    amp_col=np.arange(N)\n",
    "    A[:, [col]]= amplitudes[:, [amp_col]]\n",
    "    P[:, [col]]= phases[:, [amp_col]]\n",
    "    UAP[:,[col]]=u_a[:,[amp_col]]\n",
    "    UAP[:,[col+length]]=u_ap[:,[amp_col]]\n",
    "    UAP[:,[col+length_2]]=u_pp[:,[amp_col]]\n",
    "    for m in range(M): \n",
    "        # Defining diagonals for sparse matrix  \n",
    "        diag1=np.zeros(length_2)\n",
    "        diag2=np.zeros(length_2)\n",
    "        diag1[:length]=UAP[m,:length]\n",
    "        diag1[length:]=UAP[m,length_2:]\n",
    "        diag3=np.zeros(length_2)\n",
    "        diag2[offset_UAP[1]:length_2+offset_UAP[1]]=UAP[m][length:length_2] \n",
    "        diag3[offset_UAP[1]:length_2+offset_UAP[1]]=UAP[m][length:length_2]\n",
    "        diagonals =[diag1,diag2,diag3]\n",
    "        # Creating sparse matrix with three diagonals. Diag1 is the main diagonal.\n",
    "        Sparse_matr=dia_matrix((diagonals,offset_UAP),shape=((length_2, length_2)))\n",
    "        X,UX=AmpPhase2Time(A[m,:], P[m,:], Sparse_matr)\n",
    "        x[m,:] = X\n",
    "        ux[m,:]=np.diag(UX)\n",
    "  \n",
    "    return    x,ux\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `Reconstruct_time_domain_idft` gradually performs transformation from amplitudes and phases to real and imaginary parts and then to time domain, taking into account squared standard uncertainties of amplitudes and phases.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyDynamic.uncertainty.propagate_DFT import AmpPhase2DFT,GUM_iDFT\n",
    "import h5py\n",
    "def Reconstruct_time_domain_idft(N,frequencies,amplitudes,phases,u_a,u_pp):\n",
    "   \n",
    "    M,num=amplitudes.shape\n",
    "    length=int(amplitudes.shape[1])*N+1 #promijeniti index,generisati\n",
    "    length_2=2*length\n",
    "    x=np.zeros((M, length_2-2))\n",
    "    #storing uncertainties in a list of arrays\n",
    "    ux=np.zeros((M, length_2-2))\n",
    "    #predefining A,P,UAP as zero arrays\n",
    "    A =np.zeros((M, length))\n",
    "    P= np.zeros_like(A)\n",
    "    UAP=np.zeros((M, length_2)) #UAP contains squared standard uncertainties of amplitudes and phases\n",
    "    assert(amplitudes.shape==phases.shape)\n",
    "    # Indices of columns with highest amplitudes\n",
    "    Index_amplitudes=frequencies[:,:N] #promijeniti index,generisati\n",
    "    Index_amplitudes=Index_amplitudes.astype(int)\n",
    "    col = np.array(Index_amplitudes[0])\n",
    "    #indices(columns) of 10% highest amplitude values\n",
    "    #first N columns of input amplitudes\n",
    "    amp_col=np.arange(N)\n",
    "    A[:, [col]]= amplitudes[:, [amp_col]]\n",
    "    P[:, [col]]= phases[:, [amp_col]]\n",
    "    UAP[:,[col]]=u_a[:,[amp_col]]\n",
    "    UAP[:,[col+length]]=u_pp[:,[amp_col]]\n",
    "    for m in range(M):\n",
    "        F,UF=AmpPhase2DFT(A[m,:], P[m,:], UAP[m,:])\n",
    "        X,UX=GUM_iDFT(F, UF)\n",
    "        x[m,:] = X\n",
    "        ux[m,:]=np.diag(UX)\n",
    "     \n",
    "    return x,ux\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Instead of executing the function, reconstructed time domain signals obtained from  extracting 10% of highest amplitudes by DFT can be read from hdf5 files in the next steps. Sigma value, representing white noise was assumed as 0.1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading data instead of execution \n",
    "import os\n",
    "import h5py\n",
    "\n",
    "x_time1= h5py.File(\"Reconstructed-time-signals10.hdf5\",\"r\")\n",
    "ux_time1= h5py.File(\"Reconstructed-uncert-time-signals10.hdf5\",\"r\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_time=[0]*len(sensor_train)\n",
    "ux_time=[0]*len(sensor_train)\n",
    "for i in range(len(sensor)):\n",
    "    x_time[i]=x_time1[\"x_time\"+str(i)]\n",
    "    ux_time[i]=ux_time1[\"ux_time\"+str(i)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Function execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function execution\n",
    "x_time=[0]*len(sensor_train)\n",
    "ux_time=[0]*len(sensor_train)\n",
    "N=10 #percentage of amplitudes that were extracted from DFT results\n",
    "for i in range(len(sensor_train)):                     \n",
    "    print(\"Sensor number %s\" % i)\n",
    "    x_time[i],ux_time[i]=Reconstruct_time_domain(N,freq_of_sorted_values[i].values, sorted_values__amp_from_all_sensors[i].values,sorted_phases_from_all_sensors[i].values,sorted_uncer_from_all_sensors_a[i].values,sorted_uncer_from_all_sensors_ap[i].values,sorted_uncer_from_all_sensors_pp[i].values)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function execution\n",
    "x_time=[0]*len(sensor_train)\n",
    "ux_time=[0]*len(sensor_train)\n",
    "for i in range(len(sensor_train)):                     \n",
    "    print(\"Sensor number %s\" % i)\n",
    "    x_time[i],ux_time[i]=Reconstruct_time_domain_idft(N,freq_of_sorted_values[i].values, sorted_values__amp_from_all_sensors[i].values,sorted_phases_from_all_sensors[i].values,sorted_uncer_from_all_sensors_a[i].values,sorted_uncer_from_all_sensors_pp[i].values)\n",
    "       \n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of time domain signal through all cycles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c9ecfad61a46ea9029a389acfdfcf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='sensor', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), value=0), Dropdow…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_sensor(sensor, cycle)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#check abs\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "units=['[Pa]', '[g]', '[g]', '[g]', '[kN]', '[bar]', '[mm/s]', '[A]', '[A]', '[A]', '[A]']\n",
    "labels1 = ['Microphone','Vibration plain bearing','Vibration piston rod','Vibration ball bearing', 'Axial force','Pressure','Velocity','Active current','Motor current phase 1','Motor current phase 2','Motor current phase 3']\n",
    "def plot_sensor(sensor,cycle):\n",
    "   \n",
    "    plt.figure(figsize=(15,12))\n",
    "    plt.plot(np.arange(0,1,0.0005),sensor_train[sensor].values.transpose()[cycle,:],label=\"Input time values\")\n",
    "    plt.ylabel(str(units[sensor]))\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.title(str(labels1[sensor]))\n",
    "    plt.errorbar(np.arange(0,1,0.0005),x_time[sensor][cycle],yerr=np.sqrt((ux_time[sensor][cycle])),label=\"Reconstructed time values with DFT\", ecolor='orangered',\n",
    "            color='green')\n",
    "    # Adding legend to the plot    \n",
    "        \n",
    "\n",
    "interact(plot_sensor, sensor=range(10),cycle=range(sorted_values__amp_from_all_sensors[0].shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c61eea80bb24352a6c5016af9429816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='sensor', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), value=0), IntSlid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_sensor1(sensor, cycle)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "units=['[Pa]', '[g]', '[g]', '[g]', '[kN]', '[bar]', '[mm/s]', '[A]', '[A]', '[A]', '[A]']\n",
    "labels1 = ['Microphone','Vibration plain bearing','Vibration piston rod','Vibration ball bearing', 'Axial force','Pressure','Velocity','Active current','Motor current phase 1','Motor current phase 2','Motor current phase 3']\n",
    "def plot_sensor1(sensor,cycle):\n",
    "    plt.figure(figsize=(15,12))\n",
    "    plt.plot(np.arange(0,1,0.0005),sensor_train[sensor].values.transpose()[cycle,:], label=\"Input time values\")\n",
    "    plt.ylabel(str(units[sensor]))\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.title(str(labels1[sensor]))\n",
    "    plt.errorbar(np.arange(0,1,0.0005),x_time[sensor][cycle],yerr=np.sqrt((ux_time[sensor][cycle])),label=\"Reconstructed time values with DFT\", ecolor='orangered',\n",
    "            color='green')\n",
    "    # Adding legend to the plot    \n",
    "    plt.legend(loc='best', frameon=True)\n",
    "interact(plot_sensor1,sensor=range(10),cycle=widgets.IntSlider(min=0, max=sorted_values__amp_from_all_sensors[0].shape[0], step=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test1.close()\n",
    "amp_fft1.close()\n",
    "freq_fft1.close()\n",
    "amp_dft2.close()\n",
    "freq_dft2.close()\n",
    "ph_dft2.close()\n",
    "u_a_dft2.close()\n",
    "u_ap_dft2.close()\n",
    "u_pp_dft2.close() \n",
    "x_time1.close()\n",
    "ux_time1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "[1]  PTB, ZeMA, - Deep dive into the ZeMA machine learning (ppt), January 2019\n",
    "\n",
    "[2]  https://www.nti-audio.com/en/support/know-how/fast-fourier-transform-fft\n",
    "\n",
    "[3]  http://www.sthda.com/english/wiki/correlation-test-between-two-variables-in-r\n",
    "\n",
    "[4]  https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\n",
    "\n",
    "[5]  Edouard Duchesnay, Tommy Löfstedt, - Statistics and Machine Learning in Python, March 2018\n",
    "\n",
    "[6]  https://ipywidgets.readthedocs.io/en/latest/examples/Using%20Interact.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
