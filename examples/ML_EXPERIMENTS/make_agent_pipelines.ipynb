{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #option 1 : group of pipelines with 3 levels\n",
    "# ML_pipelines_A = make_agent_pipelines([PCA(), KNN()],\n",
    "#                                 [StandardScaler(),RobustScaler()],\n",
    "#                                 [LinearRegression(),ANN()], parameters)\n",
    "\n",
    "# #option 2 : multi pipelines of single level\n",
    "# ML_pipelines_B = make_agent_pipelines([CNN(),BCNN(),ANN()], parameters)\n",
    "\n",
    "# #option 3 : single pipeline\n",
    "# ML_pipeline_C = make_agent_pipeline([StandardScaler(),PCA(),ANN()], parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"F:/PhD Research/Github/develop_ml_experiments_met4fof/agentMET4FOF\"\n",
    "os.chdir(path)\n",
    "\n",
    "from agentMET4FOF.agents import AgentMET4FOF, AgentNetwork, MonitorAgent\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN():\n",
    "    def transform(self):\n",
    "        return 12333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'method'>\n",
      "<class 'method'>\n"
     ]
    }
   ],
   "source": [
    "method_pca = PCA()\n",
    "method_ann = ANN()\n",
    "\n",
    "print(str(type(method_pca.fit)))\n",
    "print(str(type(method_ann.transform)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerAgent(AgentMET4FOF):\n",
    "    def init_parameters(self,method=None):\n",
    "        self.method = method\n",
    "        \n",
    "    def on_received_message(self,message):\n",
    "        #if data is dict, with 'x' in keys\n",
    "        if type(message['data']) == dict and 'x' in message['data'].keys():\n",
    "            X= message['data']['x']\n",
    "            Y= message['data']['y']\n",
    "        else:\n",
    "            X=message['data']\n",
    "            Y=None\n",
    "            \n",
    "        #if it is train, and has fit function, then fit it first.\n",
    "        if message['channel'] == 'train':\n",
    "            if hasattr(self.method, 'fit'):\n",
    "                self.method = self.method.fit(X,Y)\n",
    "                if hasattr(self.method,'predict'):\n",
    "                    return 0\n",
    "                \n",
    "        #proceed in transforming or predicting\n",
    "        if hasattr(self.method, 'transform'):\n",
    "            results = self.method.transform(X)\n",
    "        elif hasattr(self.method, 'predict'):\n",
    "            results = self.method.predict(X)\n",
    "        else: #it is a plain function\n",
    "            results = self.method(X)\n",
    "            \n",
    "        #update chain\n",
    "        chain = self.record_chain(message)\n",
    "        \n",
    "        #send out\n",
    "        #if it is a base model, don't send out the predicted train results\n",
    "        if hasattr(self.method, 'predict'):\n",
    "            self.send_output({'x':X, 'y_true':Y, 'y_pred':results,'chain':chain},channel=message['channel'])\n",
    "        else:\n",
    "            self.send_output({'x':results, 'y':Y,'chain':chain},channel=message['channel'])\n",
    "            \n",
    "    def record_chain(self,message):\n",
    "        chain =[]\n",
    "        if type(message['data']) == dict and 'chain' in message['data'].keys():\n",
    "            chain = message['data']['chain']\n",
    "        else:\n",
    "            chain = [message['from']]\n",
    "        chain.append(self.name)\n",
    "        return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationAgent(AgentMET4FOF):\n",
    "    def init_parameters(self,method=None, **kwargs):\n",
    "        self.method = method\n",
    "        self.eval_params = kwargs\n",
    "\n",
    "    def on_received_message(self,message):\n",
    "        #only evaluate if it is not train channel\n",
    "        if message['channel'] != 'train':\n",
    "            #temporary fix\n",
    "            results = self.method(message['data']['y_true'],message['data']['y_pred'], **self.eval_params)\n",
    "            if type(message['data']) == dict and 'chain' in message['data'].keys():\n",
    "                chain = message['data']['chain']\n",
    "                agent_string = \"\"\n",
    "                for index, agent in enumerate(chain):\n",
    "                    if index !=0:\n",
    "                        agent_string = agent_string +'->'+ agent\n",
    "                    else:\n",
    "                        agent_string = agent_string+agent\n",
    "                agent_string = agent_string+'->'+self.method.__name__\n",
    "                self.send_output({agent_string:results})\n",
    "            else:\n",
    "                self.send_output({self.method.__name__:results})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataStreamAgent(AgentMET4FOF):\n",
    "    def init_parameters(self, data=None):\n",
    "        self.data = data\n",
    "        self.kf = KFold(n_splits=5,shuffle=True)\n",
    "        \n",
    "    def agent_loop(self):\n",
    "        if self.current_state == \"Running\":\n",
    "            for train_index, test_index in self.kf.split(self.data.data):\n",
    "                x_train, x_test = self.data.data[train_index], self.data.data[test_index]\n",
    "                y_train, y_test = self.data.target[train_index], self.data.target[test_index]\n",
    "                self.send_output({'x':x_train,'y':y_train},channel=\"train\")\n",
    "                self.send_output({'x':x_test,'y':y_test},channel=\"test\")\n",
    "            self.current_state = \"Stop\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentPipeline:\n",
    "    def __init__(self, agentNetwork=None,*argv):\n",
    "        agentNetwork = agentNetwork\n",
    "        self.pipeline = self.make_agent_pipelines(agentNetwork, argv)\n",
    "\n",
    "    def make_transform_agent(self,agentNetwork, pipeline_component=None):\n",
    "        if (\"function\" in type(pipeline_component).__name__) or (\"method\" in type(pipeline_component).__name__):\n",
    "            transform_agent = agentNetwork.add_agent(pipeline_component.__name__+\"_Agent\",agentType=TransformerAgent)\n",
    "            transform_agent.init_parameters(pipeline_component)\n",
    "        elif \"AgentMET4FOF\" in type(pipeline_component).__name__:\n",
    "            transform_agent = pipeline_component\n",
    "        else: #class objects with fit and transform\n",
    "            transform_agent = agentNetwork.add_agent(pipeline_component.__name__+\"_Agent\",agentType=TransformerAgent)\n",
    "            transform_agent.init_parameters(pipeline_component())\n",
    "        return transform_agent\n",
    "\n",
    "    def make_agent_pipelines(self,agentNetwork=None, argv=[]):\n",
    "        if agentNetwork is None:\n",
    "            print(\"You need to pass an agent network as parameter to add agents\")\n",
    "            return -1\n",
    "        agent_pipeline = []\n",
    "        for pipeline_level, pipeline_component in enumerate(argv):\n",
    "        #create the pipeline level, and the agents\n",
    "            #handle list type\n",
    "            agent_pipeline.append([])\n",
    "            if type(pipeline_component) == list:\n",
    "                for pipeline_function in pipeline_component:\n",
    "                    #fill up the new empty list with a new agent for every pipeline function\n",
    "                    transform_agent = self.make_transform_agent(agentNetwork,pipeline_function)\n",
    "                    agent_pipeline[-1].append(transform_agent)\n",
    "            #non list, single function, class, or agent\n",
    "            else:\n",
    "                #fill up the new empty list with a new agent for every pipeline function\n",
    "                transform_agent = self.make_transform_agent(agentNetwork,pipeline_component)\n",
    "                agent_pipeline[-1].append(transform_agent)\n",
    "\n",
    "        #now connect the agents on one level to the next levels, for every pipeline level\n",
    "        for pipeline_level, _ in enumerate(agent_pipeline):\n",
    "            if pipeline_level != (len(agent_pipeline)-1):\n",
    "                for agent in agent_pipeline[pipeline_level]:\n",
    "                    for agent_next in agent_pipeline[pipeline_level+1]:\n",
    "                        agent.bind_output(agent_next)\n",
    "        return agent_pipeline\n",
    "\n",
    "    def bind_output(self, output_agent):\n",
    "        pipeline_last_level = self.pipeline[-1]\n",
    "        if \"AgentPipeline\" in str(type(output_agent).__name__):\n",
    "            for agent in pipeline_last_level:\n",
    "                for next_agent in output_agent.pipeline[0]:\n",
    "                    agent.bind_output(next_agent)\n",
    "        elif type(output_agent) == list:\n",
    "            for agent in pipeline_last_level:\n",
    "                for next_agent in output_agent:\n",
    "                    agent.bind_output(next_agent)            \n",
    "        else:\n",
    "            for agent in pipeline_last_level:\n",
    "                agent.bind_output(output_agent)\n",
    "\n",
    "    def unbind_output(self, output_agent):\n",
    "        pipeline_last_level = self.pipeline[-1]\n",
    "        if \"AgentPipeline\" in str(type(output_agent).__name__):\n",
    "            for agent in pipeline_last_level:\n",
    "                for next_agent in output_agent.pipeline[0]:\n",
    "                    agent.unbind_output(next_agent)\n",
    "        elif type(output_agent) == list:\n",
    "            for agent in pipeline_last_level:\n",
    "                for next_agent in output_agent:\n",
    "                    agent.unbind_output(next_agent)            \n",
    "        else:\n",
    "            for agent in pipeline_last_level:\n",
    "                agent.unbind_output(output_agent)\n",
    "                \n",
    "    def agents(self):\n",
    "        agent_names = []\n",
    "        for level in self.pipeline:\n",
    "            agent_names.append([])\n",
    "            for agent in level:\n",
    "                agent_names[-1].append(agent.get_attr('name'))\n",
    "        return agent_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "agentNetwork= AgentNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastream_agent = agentNetwork.add_agent(agentType=DataStreamAgent)\n",
    "\n",
    "evaluation_agent = agentNetwork.add_agent(agentType=EvaluationAgent)\n",
    "\n",
    "monitor_agent = agentNetwork.add_agent(agentType=MonitorAgent)\n",
    "\n",
    "datastream_agent.init_parameters(datasets.load_iris())\n",
    "evaluation_agent.init_parameters(f1_score,average='micro')\n",
    "evaluation_agent.bind_output(monitor_agent)\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "ML_Agent_pipelines_A = AgentPipeline(agentNetwork, [PCA],\n",
    "                                [StandardScaler,RobustScaler],\n",
    "                                [LogisticRegression,SVC])\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "ML_Agent_pipelines_A.bind_output([evaluation_agent])\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "datastream_agent.bind_output(ML_Agent_pipelines_A)\n",
    "datastream_agent.bind_output(ML_Agent_pipelines_A.pipeline[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
